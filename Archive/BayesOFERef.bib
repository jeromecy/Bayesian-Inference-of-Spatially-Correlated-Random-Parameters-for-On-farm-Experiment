
@article{Baek2019Brief,
  ids = {Baek2019},
  title = {Brief {{Research Report}}: {{Bayesian Versus REML Estimations With Noninformative Priors}} in {{Multilevel Single}}-{{Case Data}}},
  shorttitle = {Brief {{Research Report}}},
  author = {Baek, Eunkyeng and Beretvas, S. Natasha and {Van den Noortgate}, Wim and Ferron, John M.},
  year = {2019},
  month = mar,
  pages = {1--13},
  publisher = {{Routledge}},
  issn = {0022-0973, 1940-0683},
  doi = {10.1080/00220973.2018.1527280},
  abstract = {Recently, researchers have used multilevel models for estimating intervention effects in single-case experiments that include replications across participants (e.g., multiple baseline designs) or for combining results across multiple single-case studies. Researchers estimating these multilevel models have primarily relied on restricted maximum likelihood (REML) techniques, but Bayesian approaches have also been suggested. The purpose of this Monte Carlo simulation study was to examine the impact of estimation method (REML versus Bayesian with noninformative priors) on the estimation of treatment effects (relative bias, root mean square error) and on the inferences about those effects (interval coverage) for autocorrelated multiple-baseline data. Simulated conditions varied with regard to the number of participants, series length, and distribution of the variance within and across participants. REML and Bayesian estimation led to estimates of the fixed effects that showed little to no bias but that differentially impacted the inferences about the fixed effects and the estimates of the variances. Implications for applied researchers and methodologists are discussed.},
  annotation = {ZSCC: 0000005},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Baek et al. - 2019 - Brief Research Report Bayesian Versus REML Estima.pdf},
  journal = {The Journal of Experimental Education},
  keywords = {Bayesian estimation,estimation method,multilevel modeling,noninformative priors,restricted maximum likelihood,single-case research},
  language = {English}
}

@article{Bates2015Fitting,
  title = {Fitting Linear Mixed-Effects Models Using Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Benjamin M. and Walker, Steven C.},
  year = {2015},
  volume = {67},
  issn = {15487660},
  doi = {10.18637/jss.v067.i01},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  annotation = {ZSCC: 0000031},
  archivePrefix = {arXiv},
  arxivid = {1406.5823},
  eprint = {1406.5823},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Bates et al_2015_Fitting linear mixed-effects models using lme4.pdf},
  journal = {Journal of Statistical Software},
  keywords = {Cholesky decomposition,Linear mixed models,Penalized least squares,Sparse matrix methods},
  number = {1}
}

@article{Besag1999Bayesian,
  title = {Bayesian Analysis of Agricultural Field Experiments},
  author = {Besag, J. and Higdon, D.},
  year = {1999},
  month = nov,
  volume = {61},
  pages = {691--746},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/1467-9868.00201},
  abstract = {The paper describes Bayesian analysis for agricultural field experiments, a topic that has received very little previous attention, despite a vast frequentist literature. Adoption of the Bayesian paradigm simplifies the interpretation of the results, especially in ranking and selection. Also, complex formulations can be analysed with comparative ease, by using Markov chain Monte Carlo methods. A key ingredient in the approach is the need for spatial representations of the unobserved fertility patterns. This is discussed in detail. Problems caused by outliers and by jumps in fertility are tackled via hierarchical-t formulations that may find use in other contexts. The paper includes three analyses of variety trials for yield and one example involving binary data; none is entirely straightforward. Some numerical comparisons with frequentist analyses are made.},
  annotation = {ZSCC: 0000239},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesTechnique\\Bayesian Analysis of Agricultural Field Experiments.pdf},
  journal = {J Royal Statistical Soc B},
  language = {en},
  number = {4}
}

@article{Betancourt2017Conceptual,
  ids = {Betancourt2017,Betancourt2018Conceptual,betancourt2017conceptual},
  title = {A Conceptual Introduction to {{Hamiltonian Monte Carlo}}},
  author = {Betancourt, M.},
  year = {2017},
  volume = {arXiv:1701.02434},
  annotation = {ZSCC: 0000398},
  archivePrefix = {arXiv},
  arxivid = {1701.02434},
  eprint = {1701.02434},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\666TAFRI\\1701.html},
  journal = {arXiv preprint},
  keywords = {⛔ No DOI found,Statistics - Methodology}
}

@book{Brooks2011Handbook,
  title = {Handbook of Markov Chain Monte Carlo},
  author = {Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year = {2011},
  publisher = {{CRC press}},
  annotation = {ZSCC: 0001719},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\LNAKALPB\\books.html}
}

@article{Burkner2017brms,
  title = {Brms: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul Christian},
  year = {2017},
  month = aug,
  volume = {80},
  pages = {1--28},
  publisher = {{American Statistical Association}},
  issn = {15487660},
  doi = {10.18637/jss.v080.i01},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit \textendash{} among others \textendash{} linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
  annotation = {ZSCC: NoCitationData[s1]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\brms An R Package for Bayesian Multilevel Models Using Stan.pdf},
  journal = {Journal of Statistical Software},
  keywords = {Bayesian inference,MCMC,Multilevel model,Ordinal data,R,Stan},
  number = {1}
}

@article{Burkner2018Advanced,
  ids = {burknerAdvancedBayesianMultilevel2018},
  title = {Advanced {{Bayesian}} Multilevel Modeling with the {{R}} Package Brms},
  author = {B{\"u}rkner, Paul-Christian Christian},
  year = {2018},
  volume = {10},
  pages = {395--411},
  issn = {20734859},
  doi = {10.32614/rj-2018-017},
  abstract = {The brms package allows R users to easily specify a wide range of Bayesian single-level and multilevel models which are fit with the probabilistic programming language Stan behind the scenes. Several response distributions are supported, of which all parameters (e.g., location, scale, and shape) can be predicted. Non-linear relationships may be specified using non-linear predictor terms or semi-parametric approaches such as splines or Gaussian processes. Multivariate models can be fit as well. To make all of these modeling options possible in a multilevel framework, brms provides an intuitive and powerful formula syntax, which extends the well known formula syntax of lme4. The purpose of the present paper is to introduce this syntax in detail and to demonstrate its usefulness with four examples, each showing relevant aspects of the syntax.},
  annotation = {ZSCC: 0000025},
  archivePrefix = {arXiv},
  arxivid = {1705.11123},
  eprint = {1705.11123},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Advanced Bayesian Multilevel Modeling with the R Package brms.pdf},
  journal = {R Journal},
  keywords = {bayesian inference,distributional regression,mcmc,multilevel models,r,stan},
  number = {1}
}

@article{Burkner2020Efficient,
  title = {Efficient Leave-One-out Cross-Validation for {{Bayesian}} Non-Factorized Normal and {{Student}}-t Models},
  author = {B{\"u}rkner, Paul-Christian and Gabry, Jonah and Vehtari, Aki},
  year = {2020},
  month = mar,
  abstract = {Cross-validation can be used to measure a model's predictive accuracy for the purpose of model comparison, averaging, or selection. Standard leave-one-out cross-validation (LOO-CV) requires that the observation model can be factorized into simple terms, but a lot of important models in temporal and spatial statistics do not have this property or are inefficient or unstable when forced into a factorized form. We derive how to efficiently compute and validate both exact and approximate LOO-CV for any Bayesian non-factorized model with a multivariate normal or Student-\textbackslash (t\textbackslash ) distribution on the outcome values. We demonstrate the method using lagged simultaneously autoregressive (SAR) models as a case study.},
  annotation = {ZSCC: NoCitationData[s0]},
  archivePrefix = {arXiv},
  eprint = {1810.10559},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Bürkner et al_2020_Efficient leave-one-out cross-validation for Bayesian non-factorized normal and.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\L7RSPAES\\1810.html},
  journal = {arXiv:1810.10559 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{Carpenter2017Stan,
  title = {Stan : {{A Probabilistic Programming Language}}},
  shorttitle = {Stan},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  month = jan,
  volume = {76},
  publisher = {{Columbia Univ., New York, NY (United States); Harvard Univ., Cambridge, MA (United States)}},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i01},
  abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
  annotation = {ZSCC: 0002724},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Carpenter et al_2017_Stan.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\AQM237SX\\1430202.html},
  journal = {Journal of Statistical Software},
  language = {English},
  number = {1}
}

@unpublished{Chauveau2018Testing,
  title = {Testing for Univariate Two-Component {{Gaussian}} Mixture in Practice},
  author = {Chauveau, Didier and Garel, Bernard and Mercier, Sabine},
  year = {2018},
  month = dec,
  abstract = {We consider univariate Gaussian mixtures theory and applications, and particularly the problem of testing the null hypothesis of homogeneity (one component) against two components. Several approaches have been proposed in the literature during the last decades. We focus on two different techniques, one based on the Likelihood-Ratio Test (LRT), and another one based on estimation of the parameters of the mixture grounded on some specific adaptation of the well-known EM algorithm often called the EM-test. We propose in particular a novel methodology allowing application of the LRT in actual situations, by plugging-in estimates that are assumed known in asymptotic setup. We aim to provide useful comparisons between different techniques, together with  guidelines for practitioners in order to enable them to use theoretical advances for analysing actual data of realistic sample sizes. We finally illustrate these methods in an application to real data corresponding to the number of days between two events concerning ovarian response and lambing for ewes.},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MixtureGaussian\\Chauveau et al_2018_Testing for univariate two-component Gaussian mixture in practice.pdf},
  keywords = {EM tests,Gaussian process,likelihood ratio test,Mixture models}
}

@article{Che2010Bayesian,
  ids = {Che2010},
  title = {Bayesian Data Analysis for Agricultural Experiments},
  author = {Che, X. and Xu, S.},
  year = {2010},
  month = sep,
  volume = {90},
  pages = {575--603},
  publisher = {{NRC Research Press}},
  issn = {0008-4220},
  doi = {10.4141/cjps10004},
  abstract = {Data collected in agricultural experiments can be analyzed in many different ways using different models. The most commonly used models are the linear model and the generalized linear model. The ma..., Les donn\'ees issues des exp\'eriences agricoles peuvent \^etre analys\'ees de nombreuses mani\`eres avec diff\'erents mod\`eles. Les plus couramment employ\'es sont le mod\`ele lin\'eaire et le mod\`ele lin\'eaire g\'en\'era...},
  annotation = {ZSCC: 0000011},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Che_Xu_2010_Bayesian data analysis for agricultural experiments.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\HPUNDK39\\CJPS10004.html},
  journal = {Can. J. Plant Sci.},
  keywords = {2010,analyse baye,bayesian method,che,et xu,generalized linear model,markov chain monte carlo,s,sas,winbugs,x},
  number = {5}
}

@article{Chen2012Robust,
  title = {A Robust Method of Thin Plate Spline and Its Application to {{DEM}} Construction},
  author = {Chen, Chuanfa and Li, Yanyan},
  year = {2012},
  month = nov,
  volume = {48},
  pages = {9--16},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2012.05.018},
  abstract = {In order to avoid the ill-conditioning problem of thin plate spline (TPS), the orthogonal least squares (OLS) method was introduced, and a modified OLS (MOLS) was developed. The MOLS of TPS (TPS-M) can not only select significant points, termed knots, from large and dense sampling data sets, but also easily compute the weights of the knots in terms of back-substitution. For interpolating large sampling points, we developed a local TPS-M, where some neighbor sampling points around the point being estimated are selected for computation. Numerical tests indicate that irrespective of sampling noise level, the average performance of TPS-M can advantage with smoothing TPS. Under the same simulation accuracy, the computational time of TPS-M decreases with the increase of the number of sampling points. The smooth fitting results on lidar-derived noise data indicate that TPS-M has an obvious smoothing effect, which is on par with smoothing TPS. The example of constructing a series of large scale DEMs, located in Shandong province, China, was employed to comparatively analyze the estimation accuracies of the two versions of TPS and the classical interpolation methods including inverse distance weighting (IDW), ordinary kriging (OK) and universal kriging with the second-order drift function (UK). Results show that regardless of sampling interval and spatial resolution, TPS-M is more accurate than the classical interpolation methods, except for the smoothing TPS at the finest sampling interval of 20m, and the two versions of kriging at the spatial resolution of 15m. In conclusion, TPS-M, which avoids the ill-conditioning problem, is considered as a robust method for DEM construction.},
  annotation = {ZSCC: 0000039},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Chen_Li_2012_A robust method of thin plate spline and its application to DEM construction.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\JV2KPV4G\\S0098300412001744.html},
  journal = {Computers \& Geosciences},
  keywords = {DEM,Interpolation,Kriging,Orthogonal least squares,Thin plate spline},
  language = {en}
}

@article{Chen2019Simple,
  title = {A Simple and Parsimonious Generalised Additive Model for Predicting Wheat Yield in a Decision Support Tool},
  author = {Chen, Kefei and O'Leary, Rebecca A. and Evans, Fiona H.},
  year = {2019},
  volume = {173},
  pages = {140--150},
  publisher = {{Elsevier}},
  issn = {0308521X},
  doi = {10.1016/j.agsy.2019.02.009},
  abstract = {Yield prediction is a major determinant of many management decisions for crop production. Farmers and their advisors want user-friendly decision support tools for predicting yield. Simulation models can be used to accurately predict yield, but they are complex and difficult to parameterise. The goal of this study is to build a simple and parsimonious model for predicting wheat yields that can be implemented in a decision tool to be used by farmers at a paddock level. A large yield data set accumulated from trials on commonly grown varieties in Western Australia is used to build and validate a generalised additive model (GAM) for predicting wheat yield. Explanatory variables tested included weather data and derivatives, geolocation, soil type, land capability, and wheat varieties. Model selection followed a forward stepwise approach in combination with cross-validation to select the smallest set of explanatory variables. The predictive performance is also evaluated using independent data. The final model uses seasonal water availability, location and year to predict wheat yield. Because the GAM model has minimal inputs, it can be easily employed in a decision tool to predict yield throughout the growing season using rainfall data up to the prediction date and either climatological averages or seasonal forecasts of rainfall for the remainder of the growing season. It also has the potential to be used as an input to agronomic models that predict the effect on yield of various management choices for fertiliser, pest, weed and disease management.},
  annotation = {ZSCC: 0000005},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Chen et al_2019_A simple and parsimonious generalised additive model for predicting wheat yield.pdf},
  journal = {Agricultural Systems},
  keywords = {Crop modelling,Crop water relations,Decision support,Precision farming,Waterlogging,Yield prediction},
  number = {August 2018}
}

@article{Cheng2019Anadditive,
  title = {An Additive {{Gaussian}} Process Regression Model for Interpretable Non-Parametric Analysis of Longitudinal Data},
  author = {Cheng, Lu and Ramchandran, Siddharth and Vatanen, Tommi and Lietz{\'e}n, Niina and Lahesmaa, Riitta and Vehtari, Aki and L{\"a}hdesm{\"a}ki, Harri},
  year = {2019},
  month = dec,
  volume = {10},
  pages = {1--11},
  publisher = {{Springer US}},
  issn = {20411723},
  doi = {10.1038/s41467-019-09785-8},
  abstract = {Biomedical research typically involves longitudinal study designs where samples from individuals are measured repeatedly over time and the goal is to identify risk factors (covariates) that are associated with an outcome value. General linear mixed effect models are the standard workhorse for statistical analysis of longitudinal data. However, analysis of longitudinal data can be complicated for reasons such as difficulties in modelling correlated outcome values, functional (time-varying) covariates, nonlinear and non-stationary effects, and model inference. We present LonGP, an additive Gaussian process regression model that is specifically designed for statistical analysis of longitudinal data, which solves these commonly faced challenges. LonGP can model time-varying random effects and non-stationary signals, incorporate multiple kernel learning, and provide interpretable results for the effects of individual covariates and their interactions. We demonstrate LonGP's performance and accuracy by analysing various simulated and real longitudinal -omics datasets.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\An additive Gaussian process regression model for interpretable non-parametric analysis of longitudinal data.pdf},
  journal = {Nat. Commun.},
  number = {1}
}

@book{Congdon2019Bayesian,
  title = {Bayesian {{Hierarchical Models}}: {{With Applications Using R}}, {{Second Edition}}},
  shorttitle = {Bayesian {{Hierarchical Models}}},
  author = {Congdon, Peter D.},
  year = {2019},
  month = sep,
  edition = {Second},
  publisher = {{CRC Press}},
  abstract = {An intermediate-level treatment of Bayesian hierarchical models and their applications, this book demonstrates the advantages of a Bayesian approach to data sets involving inferences for collections of related units or variables, and in methods where parameters can be treated as random collections. Through illustrative data analysis and attention to statistical computing, this book facilitates practical implementation of Bayesian hierarchical methods.  The new edition is a revision of the book Applied Bayesian Hierarchical Methods. It maintains a focus on applied modelling and data analysis, but now using entirely R-based Bayesian computing options. It has been updated with a new chapter on regression for causal effects, and one on computing options and strategies. This latter chapter is particularly important, due to recent advances in Bayesian computing and estimation, including the development of rjags and rstan. It also features updates throughout with new examples.  The examples exploit and illustrate the broader advantages of the R computing environment, while allowing readers to explore alternative likelihood assumptions, regression structures, and assumptions on prior densities.  Features:   Provides a comprehensive and accessible overview of applied Bayesian hierarchical modelling   Includes many real data examples to illustrate different modelling topics   R code (based on rjags, jagsUI, R2OpenBUGS, and rstan) is integrated into the book, emphasizing implementation   Software options and coding principles are introduced in new chapter on computing   Programs and data sets available on the book's website},
  annotation = {ZSCC: NoCitationData[s0]},
  googlebooks = {NRGwDwAAQBAJ},
  isbn = {978-1-4987-8591-4},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {English}
}

@article{Cook2013Onfarm,
  title = {On-Farm Experimentation},
  author = {Cook, Simon and Cock, James and Oberth{\"u}r, Thomas and Fisher, Myles},
  year = {2013},
  volume = {97},
  pages = {17--20},
  annotation = {ZSCC: 0000021},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\OFEandPA\\Simon Cook, James Cock - 2013 - On-Farm Experimentation.pdf},
  journal = {Better Crop. Plant Food},
  keywords = {⛔ No DOI found},
  series = {4}
}

@article{cordero2019Spatial,
  title = {Spatial Management Strategies for Nitrogen in Maize Production Based on Soil and Crop Data},
  author = {Cordero, Eleonora and Longchamps, Louis and Khosla, Raj and Sacco, Dario},
  year = {2019},
  month = dec,
  volume = {697},
  pages = {133854},
  issn = {0048-9697},
  doi = {10.1016/j.scitotenv.2019.133854},
  abstract = {Nitrogen (N) fertilisation determines maize grain yield (MGY). Precision agriculture (PA) allows matching crop N requirements in both space and time. Two approaches have been suggested for precision N management, i.e. management zones (MZ) delineation and crop remote and proximal sensing (PS). Several studies have demonstrated separately the advantages of these approaches for precision N application. This study evaluated their convenient integration, considering the influence of different PA techniques on MGY, N use efficiency (NUE), and farmer's net return, then providing a practical tool for choosing the fertilisation strategy that best applies in each agro-environment. A multi-site-year experiment was conducted between 2014 and 2016 in Colorado, USA. The trial compared four N management practices: uniform N rate, variable N rate based on MZ (VR-MZ), variable N rate based on PS (VR-PS), and variable N rate based on both PS and MZ (VR-PSMZ), based on their effect on MGY, partial factor productivity (PFPN), and net return above N fertiliser cost (RANC). Maize grain yield and PFPN maximisation conflicted in several situations. Hence, a compromise between obtaining high yield and increasing NUE is needed to enhance the overall sustainability of maize cropping systems. Maximisation of RANC allowed defining the best N fertilisation practice in terms of profitability. The spatial range in MGY is a practical tool for identifying the best N management practice. Uniform N supply was suitable where no spatial pattern was detected. If a high spatial range ({$>$}100 m) existed, VR-MZ was the best approach. Conversely, VR-PS performed better when a shorter spatial range ({$<$}16 m) was detected, and when maximum variability in crop vigour was observed across the field (range of variation = 0.597) leading to a larger difference in MGY (range of variation = 13.9 Mg ha-1). Results indicated that VR-PSMZ can further improve maize fertilisation for intermediate spatial structures (43 m).},
  annotation = {ZSCC: 0000006},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Cordero et al_2019_Spatial management strategies for nitrogen in maize production based on soil.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\AJK44FAA\\S0048969719338021.html},
  journal = {Science of The Total Environment},
  keywords = {Data fusion,Management zones,Precision fertilisation,Proximal crop sensing,Variable rate N application},
  language = {en}
}

@inproceedings{Damianou2013Deep,
  title = {Deep {{Gaussian Processes}}},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Damianou, Andreas and Lawrence, Neil},
  year = {2013},
  month = apr,
  pages = {207--215},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief network based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inpu...},
  annotation = {ZSCC: 0000622},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Damianou_Lawrence_2013_Deep Gaussian Processes.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\73JZ8264\\damianou13a.html},
  language = {en}
}

@article{Datta2016Hierarchical,
  title = {Hierarchical {{Nearest}}-{{Neighbor Gaussian Process Models}} for {{Large Geostatistical Datasets}}},
  author = {Datta, Abhirup and Banerjee, Sudipto and Finley, Andrew O. and Gelfand, Alan E.},
  year = {2016},
  month = apr,
  volume = {111},
  pages = {800--812},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2015.1044091},
  abstract = {Spatial process models for analyzing geostatistical data entail computations that become prohibitive as the number of spatial locations become large. This article develops a class of highly scalable nearest-neighbor Gaussian process (NNGP) models to provide fully model-based inference for large geostatistical datasets. We establish that the NNGP is a well-defined spatial process providing legitimate finite-dimensional Gaussian densities with sparse precision matrices. We embed the NNGP as a sparsity-inducing prior within a rich hierarchical modeling framework and outline how computationally efficient Markov chain Monte Carlo (MCMC) algorithms can be executed without storing or decomposing large matrices. The floating point operations (flops) per iteration of this algorithm is linear in the number of spatial locations, thereby rendering substantial scalability. We illustrate the computational and inferential benefits of the NNGP over competing methods using simulation studies and also analyze forest biomass from a massive U.S. Forest Inventory dataset at a scale that precludes alternative dimension-reducing methods. Supplementary materials for this article are available online.},
  annotation = {ZSCC: 0000277},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\P3UKE6C7\\Datta et al. - 2016 - Hierarchical Nearest-Neighbor Gaussian Process Mod.pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {514}
}

@book{dipakdey2005Bayesian,
  ids = {rao2005Bayesiana,rao2005Bayesianb},
  title = {Bayesian {{Thinking}}, {{Modeling}} and {{Computation}}},
  editor = {{Dipak Dey} and {C.R. Rao}},
  year = {2005},
  month = nov,
  edition = {1st},
  volume = {25},
  publisher = {{Elsevier}},
  abstract = {This volume describes how to develop Bayesian thinking, modelling and computation both from philosophical, methodological and application point of view. It further describes parametric and nonparametric Bayesian methods for modelling and how to use modern computational methods to summarize inferences using simulation. The book covers wide range of topics including objective and subjective Bayesian inferences with a variety of applications in modelling categorical, survival, spatial, spatiotemporal, Epidemiological, software reliability, small area and micro array data. The book concludes with a chapter on how to teach Bayesian thoughts to nonstatisticians.Critical thinking on causal effectsObjective Bayesian philosophyNonparametric Bayesian methodologySimulation based computing techniquesBioinformatics and Biostatistics},
  annotation = {ZSCC: 0000011},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\9IK8VIBB\\reader.html;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\KP3KTF59\\reader.html},
  googlebooks = {TAOL4NIkg1oC},
  isbn = {978-0-08-046117-5},
  keywords = {Mathematics / Probability \& Statistics / General,Nonparametric statistics},
  language = {en}
}

@article{Duane1987Hybrid,
  ids = {duane1987hybrid},
  title = {Hybrid {{Monte Carlo}}},
  author = {Duane, Simon and Kennedy, Anthony D. and Pendleton, Brian J. and Roweth, Duncan},
  year = {1987},
  volume = {195},
  pages = {216--222},
  publisher = {{Elsevier}},
  doi = {10.1016/0370-2693(87)91197-x},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Duane et al_1987_Hybrid Monte Carlo.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\ZLKRG82L\\037026938791197X.html},
  journal = {Physics letters B},
  number = {2}
}

@article{DunlopHow,
  title = {How {{Deep Are Deep Gaussian Processes}}?},
  author = {Dunlop, Matthew M and Girolami, Mark A and Stuart, Andrew M and Teckentrup, Aretha L},
  pages = {46},
  abstract = {Recent research has shown the potential utility of deep Gaussian processes. These deep structures are probability distributions, designed through hierarchical construction, which are conditionally Gaussian. In this paper, the current published body of work is placed in a common framework and, through recursion, several classes of deep Gaussian processes are defined. The resulting samples generated from a deep Gaussian process have a Markovian structure with respect to the depth parameter, and the effective depth of the resulting process is interpreted in terms of the ergodicity, or non-ergodicity, of the resulting Markov chain. For the classes of deep Gaussian processes introduced, we provide results concerning their ergodicity and hence their effective depth. We also demonstrate how these processes may be used for inference; in particular we show how a Metropolis-within-Gibbs construction across the levels of the hierarchy can be used to derive sampling tools which are robust to the level of resolution used to represent the functions on a computer. For illustration, we consider the effect of ergodicity in some simple numerical examples.},
  annotation = {ZSCC: 0000046},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CKH3C53R\\Dunlop et al. - How Deep Are Deep Gaussian Processes.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{Edmondson2014Agridat,
  title = {Agridat},
  author = {Edmondson, R. N.},
  year = {2014},
  month = feb,
  volume = {152},
  pages = {2--2},
  publisher = {{Cambridge University Press}},
  issn = {0021-8596, 1469-5146},
  doi = {10.1017/S0021859613000920},
  abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0021859613000920/resource/name/firstPage-S0021859613000920a.jpg},
  annotation = {ZSCC: 0000001},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Edmondson_2014_Agridat.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\LRW39TUP\\CD87ABAC864526B683587B762EFDDC2B.html},
  journal = {The Journal of Agricultural Science},
  language = {en},
  number = {1}
}

@article{FDormann2007Methods,
  title = {Methods to Account for Spatial Autocorrelation in the Analysis of Species Distributional Data: {{A}} Review},
  author = {F. Dormann, Carsten and M. McPherson, Jana and B. Ara{\'u}jo, Miguel and Bivand, Roger and Bolliger, Janine and Carl, Gudrun and G. Davies, Richard and Hirzel, Alexandre and Jetz, Walter and Daniel Kissling, W. and K{\"u}hn, Ingolf and Ohlem{\"u}ller, Ralf and {R. Peres-Neto}, Pedro and Reineking, Bj{\"o}rn and Schr{\"o}der, Boris and M. Schurr, Frank and Wilson, Robert},
  year = {2007},
  volume = {30},
  pages = {609--628},
  issn = {09067590},
  doi = {10.1111/j.2007.0906-7590.05171.x},
  abstract = {Species distributional or trait data based on range map (extent-of-occurrence) or atlas survey data often display spatial autocorrelation, i.e. locations close to each other exhibit more similar values than those further apart. If this pattern remains present in the residuals of a statistical model based on such data, one of the key assumptions of standard statistical analyses, that residuals are independent and identically distributed (i.i.d), is violated. The violation of the assumption of i.i.d. residuals may bias parameter estimates and can increase type I error rates (falsely rejecting the null hypothesis of no effect). While this is increasingly recognised by researchers analysing species distribution data, there is, to our knowledge, no comprehensive overview of the many available spatial statistical methods to take spatial autocorrelation into account in tests of statistical significance. Here, we describe six different statistical approaches to infer correlates of species' distributions, for both presence/absence (binary response) and species abundance data (poisson or normally distributed response), while accounting for spatial autocorrelation in model residuals: autocovariate regression; spatial eigenvector mapping; generalised least squares; (conditional and simultaneous) autoregressive models and generalised estimating equations. A comprehensive comparison of the relative merits of these methods is beyond the scope of this paper. To demonstrate each method's implementation, however, we undertook preliminary tests based on simulated data. These preliminary tests verified that most of the spatial modeling techniques we examined showed good type I error control and precise parameter estimates, at least when confronted with simplistic simulated data containing spatial autocorrelation in the errors. However, we found that for presence/absence data the results and conclusions were very variable between the different methods. This is likely due to the low information content of binary maps. Also, in contrast with previous studies, we found that autocovariate methods consistently underestimated the effects of environmental controls of species distributions. Given their widespread use, in particular for the modelling of species presence/absence data (e.g. climate envelope models), we argue that this warrants further study and caution in their use. To aid other ecologists in making use of the methods described, code to implement them in freely available software is provided in an electronic appendix. \textcopyright{} Ecography.},
  annotation = {ZSCC: NoCitationData[s1]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\F. Dormann et al_2007_Methods to account for spatial autocorrelation in the analysis of species.pdf},
  journal = {Ecography},
  number = {5}
}

@article{Gabry2016Rstanarm,
  title = {Rstanarm: {{Bayesian}} Applied Regression Modeling via Stan},
  booktitle = {R Package Version},
  author = {Gabry, Jonah and Goodrich, Ben},
  year = {2016},
  abstract = {Estimates pre-compiled regression models using the 'rstan' package, which provides the R interface to the Stan C++ library for Bayesian estimation. Users specify models via the customary R syntax with a formula and data.frame plus some additional arguments for priors.},
  annotation = {ZSCC: 0000080},
  keywords = {⛔ No DOI found}
}

@article{gabry2019Visualization,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  volume = {182},
  pages = {389--402},
  issn = {1467-985X},
  doi = {10.1111/rssa.12378},
  abstract = {Bayesian data analysis is about more than just computing a posterior distribution, and Bayesian visualization is about more than trace plots of Markov chains. Practical Bayesian data analysis, like all data analysis, is an iterative process of model building, inference, model checking and evaluation, and model expansion. Visualization is helpful in each of these stages of the Bayesian workflow and it is indispensable when drawing inferences from the types of modern, high dimensional models that are used by applied researchers.},
  annotation = {ZSCC: 0000147  \_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssa.12378},
  copyright = {\textcopyright{} 2019 Royal Statistical Society},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Visualization in Bayesian workﬂow.pdf},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  keywords = {Bayesian data analysis,Statistical graphics,Statistical workflow},
  language = {en},
  number = {2}
}

@article{Gelfand1990Samplingbased,
  title = {Sampling-Based Approaches to Calculating Marginal Densities},
  author = {Gelfand, Alan E. and Smith, Adrian FM},
  year = {1990},
  volume = {85},
  pages = {398--409},
  publisher = {{Taylor \& Francis Group}},
  doi = {10.1080/01621459.1990.10476213},
  annotation = {ZSCC: 0008432},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Gelfand_Smith_1990_Sampling-based approaches to calculating marginal densities.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\XKTEL3EN\\01621459.1990.html},
  journal = {Journal of the American statistical association},
  number = {410}
}

@article{Gelfand2005Bayesian,
  title = {Bayesian {{Nonparametric Spatial Modeling With Dirichlet Process Mixing}}},
  author = {Gelfand, Alan E. and Kottas, Athanasios and MacEachern, Steven N.},
  year = {2005},
  month = sep,
  volume = {100},
  pages = {1021--1035},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1198/016214504000002078},
  abstract = {Customary modeling for continuous point-referenced data assumes a Gaussian process that is often taken to be stationary. When such models are fitted within a Bayesian framework, the unknown parameters of the process are assumed to be random, so a random Gaussian process results. Here we propose a novel spatial Dirichlet process mixture model to produce a random spatial process that is neither Gaussian nor stationary. We first develop a spatial Dirichlet process model for spatial data and discuss its properties. Because of familiar limitations associated with direct use of Dirichlet process models, we introduce mixing by convolving this process with a pure error process. We then examine properties of models created through such Dirichlet process mixing. In the Bayesian framework, we implement posterior inference using Gibbs sampling. Spatial prediction raises interesting questions, but these can be handled. Finally, we illustrate the approach using simulated data, as well as a dataset involving precipitation measurements over the Languedoc-Roussillon region in southern France.},
  annotation = {ZSCC: 0000395  \_eprint: https://doi.org/10.1198/016214504000002078},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Gelfand et al_2005_Bayesian Nonparametric Spatial Modeling With Dirichlet Process Mixing.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\D34UC3IG\\016214504000002078.html},
  journal = {Journal of the American Statistical Association},
  keywords = {Dependent Dirichlet process,Dirichlet process mixture models,Gaussian process,Markov chain Monte Carlo,Nonstationarity,Point-referenced spatial data,Random distribution},
  number = {471}
}

@article{Gelfand2016Spatial,
  title = {Spatial Statistics and {{Gaussian}} Processes: {{A}} Beautiful Marriage},
  shorttitle = {Spatial Statistics and {{Gaussian}} Processes},
  author = {Gelfand, Alan E. and Schliep, Erin M.},
  year = {2016},
  month = nov,
  volume = {18},
  pages = {86--104},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2016.03.006},
  abstract = {Spatial analysis has grown at a remarkable rate over the past two decades. Fueled by sophisticated GIS software and inexpensive and fast computation, collection of data with spatially referenced information has increased. Recognizing that such information can improve data analysis has led to an explosion of modeling and model fitting. The contribution of this paper is to illustrate how Gaussian processes have emerged as, arguably, the most valuable tool in the toolkit for geostatistical modeling. Apart from the simplest versions, geostatistical modeling can be viewed as a hierarchical specification with Gaussian processes introduced appropriately at different levels of the specification. This naturally leads to adopting a Bayesian framework for inference and suitable Gibbs sampling/Markov chain Monte Carlo for model fitting. Here, we review twenty years of modeling work spanning multivariate spatial analysis, gradient analysis, Bayesian nonparametric spatial ideas, directional data, extremes, data fusion, and large spatial and spatio-temporal datasets. We demonstrate that Gaussian processes are the key ingredients in all of this work. Most of the content is focused on modeling with examples being limited due to length constraints for the article. Altogether, we are able to conclude that spatial statistics and Gaussian processes do, indeed, make a beautiful marriage.},
  annotation = {ZSCC: 0000053},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Gelfand_Schliep_2016_Spatial statistics and Gaussian processes.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\ELTFPLQA\\S2211675316300033.html},
  journal = {Spatial Statistics},
  keywords = {Data fusion,Directional data,Hierarchical model,Multivariate processes,Spatial Dirichlet processes,Spatial gradients},
  language = {en},
  series = {Spatial {{Statistics Avignon}}: {{Emerging Patterns}}}
}

@article{gelman2003Bayesian,
  title = {A {{Bayesian Formulation}} of {{Exploratory Data Analysis}} and {{Goodness}}-of-Fit {{Testing}}},
  author = {Gelman, Andrew},
  year = {2003},
  volume = {71},
  pages = {369--382},
  issn = {1751-5823},
  doi = {10.1111/j.1751-5823.2003.tb00203.x},
  abstract = {Exploratory data analysis (EDA) and Bayesian inference (or, more generally, complex statistical modeling)\textemdash which are generally considered as unrelated statistical paradigms\textemdash can be particularly effective in combination. In this paper, we present a Bayesian framework for EDA based on posterior predictive checks. We explain how posterior predictive simulations can be used to create reference distributions for EDA graphs, and how this approach resolves some theoretical problems in Bayesian data analysis. We show how the generalization of Bayesian inference to include replicated data yrep and replicated parameters \texttheta rep follows a long tradition of generalizations in Bayesian theory. On the theoretical level, we present a predictive Bayesian formulation of goodness-of-fit testing, distinguishing between p-values (posterior probabilities that specified antisymmetric discrepancy measures will exceed 0) and u-values (data summaries with uniform sampling distributions). We explain that p-values, unlike u-values, are Bayesian probability statements in that they condition on observed data. Having reviewed the general theoretical framework, we discuss the implications for statistical graphics and exploratory data analysis, with the goal being to unify exploratory data analysis with more formal statistical methods based on probability models. We interpret various graphical displays as posterior predictive checks and discuss how Bayesian inference can be used to determine reference distributions. The goal of this work is not to downgrade descriptive statistics, or to suggest they be replaced by Bayesian modeling, but rather to suggest how exploratory data analysis fits into the probability-modeling paradigm. We conclude with a discussion of the implications for practical Bayesian inference. In particular, we anticipate that Bayesian software can be generalized to draw simulations of replicated data and parameters from their posterior predictive distribution, and these can in turn be used to calibrate EDA graphs.},
  annotation = {ZSCC: 0000228  \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1751-5823.2003.tb00203.x},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Gelman_2003_A Bayesian Formulation of Exploratory Data Analysis and Goodness-of-fit Testing.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\HB2UBAIX\\j.1751-5823.2003.tb00203.html},
  journal = {International Statistical Review},
  keywords = {“p-value”,“u-value”,Bootstrap,Fisher's exact test,Graphics,Graphiques,Mixture model,Model checking,Modéles de mèlange,Multiple imputation,p-value,Posterior predictive check,Prior predictive check,u-value,Vérification de modéle,Vérification prédictive a posteriori,Vérification prédictive antérieur},
  language = {en},
  number = {2}
}

@article{gelman2004Exploratory,
  title = {Exploratory {{Data Analysis}} for {{Complex Models}}},
  author = {Gelman, Andrew},
  year = {2004},
  month = dec,
  volume = {13},
  pages = {755--779},
  issn = {1061-8600, 1537-2715},
  doi = {10.1198/106186004x11435},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\444BDVTV\\Gelman - 2004 - Exploratory Data Analysis for Complex Models.pdf},
  journal = {Journal of Computational and Graphical Statistics},
  language = {en},
  number = {4}
}

@article{Gelman2006Prior,
  ids = {Gelman2006,gelman2006prior,gelmanPriorDistributionsVariance2006},
  title = {Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by {{Browne}} and {{Draper}})},
  author = {Gelman, Andrew and others},
  year = {2006},
  volume = {1},
  pages = {515--534},
  publisher = {{International Society for \{B\}ayesian Analysis}},
  doi = {10.1214/06-BA117A},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Gelman - 2006 - Prior distributions for variance parameters in hierarchical models (Comment on Article by Browne and Draper).pdf},
  isbn = {9781139460934},
  journal = {Bayesian analysis},
  keywords = {Bayesian inference,Conditional conjugacy,Folded-noncentral-t distribution,Half-t distribution,Hierarchical model,Multilevel model,Noninformative prior distribution,Weakly informative prior distribution},
  number = {3},
  owner = {zcao},
  timestamp = {2017.10.27}
}

@book{Gelman2013Bayesian,
  ids = {Gelman2014},
  title = {Bayesian {{Data Analysis}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  year = {2013},
  month = nov,
  edition = {Third Edition},
  publisher = {{CRC Press}},
  abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors\textemdash all leaders in the statistics community\textemdash introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book's web page.},
  annotation = {ZSCC: 0000014},
  googlebooks = {ZXL6AQAAQBAJ},
  isbn = {978-1-4398-4095-5},
  keywords = {Computers / Mathematical \& Statistical Software,Mathematics / Probability \& Statistics / General,Psychology / Research \& Methodology},
  language = {English},
  series = {Chapman \& {{Hall CRC Texts}} in {{Statistical Science}}}
}

@article{gelman2017Prior,
  title = {The {{Prior Can Often Only Be Understood}} in the {{Context}} of the {{Likelihood}}},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  year = {2017},
  month = oct,
  volume = {19},
  pages = {555},
  issn = {1099-4300},
  doi = {10.3390/e19100555},
  abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys' priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
  annotation = {ZSCC: 0000145},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\The Prior Can Often Only Be Understood in the Context of the Likelihood.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\XEPITSXJ\\Gelman et al. - 2017 - The Prior Can Often Only Be Understood in the Cont.pdf},
  journal = {Entropy},
  language = {en},
  number = {10}
}

@article{Gelman2019Rsquared,
  ids = {Gelman2019Rsquareda},
  title = {R-Squared for Bayesian Regression Models},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  year = {2019},
  volume = {73},
  pages = {307--309},
  publisher = {{Taylor \& Francis}},
  issn = {15372731},
  doi = {10.1080/00031305.2018.1549100},
  abstract = {The usual definition of R2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian fits, as the numerator can be larger than the denominator. We propose an alternative definition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the expected variance of the errors.},
  annotation = {ZSCC: 0000127},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\MG67EWR4\\R-squared for Bayesian Regression Models.pdf},
  journal = {American Statistician},
  keywords = {Bayesian methods,R-squared,Regression},
  number = {3}
}

@article{Geman1984Stochastic,
  ids = {geman1984stochastic},
  title = {Stochastic Relaxation, {{Gibbs}} Distributions, and the {{Bayesian}} Restoration of Images},
  author = {Geman, Stuart and Geman, Donald},
  year = {1984},
  volume = {6},
  pages = {721--741},
  publisher = {{IEEE}},
  doi = {10.1109/tpami.1984.4767596},
  annotation = {ZSCC: 0024024},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Geman_Geman_1984_Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\G9YJ32MT\\4767596.html},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {Additive noise,Annealing,Bayesian methods,Deformable models,Degradation,Energy states,Gibbs distribution,image restoration,Image restoration,line process,MAP estimate,Markov random field,Markov random fields,relaxation,scene modeling,spatial degradation,Stochastic processes,Temperature distribution},
  number = {6},
  owner = {zcao},
  timestamp = {2017.10.27}
}

@article{Gilmour1997Accounting,
  title = {Accounting for Natural and Extraneous Variation in the Analysis of Field Experiments},
  author = {Gilmour, Arthur R. and Cullis, Brian R. and Verbyla, Arunas P.},
  year = {1997},
  volume = {2},
  pages = {269--293},
  issn = {10857117},
  doi = {10.2307/1400446},
  abstract = {We identify three major components of spatial variation in plot errors from field experiments and extend the two-dimensional spatial procedures of Cullis and Gleeson (1991) to account for them. The components are nonstationary, large-scale (global) variation across the field, stationary variation within the trial (natural variation or local trend), and extraneous variation that is often induced by experimental procedures and is predominantly aligned with rows and columns. We present a strategy for identifying a model for the plot errors that uses a trellis plot of residuals, a perspective plot of the sample variogram and, where possible, likelihood ratio tests to identify which components are present We demonstrate the strategy using two illustrative examples. We conclude that although there is no one model that adequately fits all field experiments, the separable autoregressive model is dominant. However, there is often additional identifiable variation present.},
  annotation = {ZSCC: 0000641},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Gilmour et al_1997_Accounting for natural and extraneous variation in the analysis of field.pdf},
  journal = {Journal of Agricultural, Biological, and Environmental Statistics},
  keywords = {Field experiments,REML,Spatial analysis,Variogram},
  number = {3}
}

@article{Girolami2011Riemann,
  ids = {Girolami2011,girolami2011Riemann,girolami2011riemann},
  title = {Riemann Manifold Langevin and Hamiltonian {{Monte Carlo}} Methods},
  author = {Girolami, Mark and Calderhead, Ben},
  year = {2011},
  volume = {73},
  pages = {123--214},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/j.1467-9868.2010.00765.x},
  annotation = {ZSCC: 0001223},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Girolami_Calderhead_2011_Riemann manifold langevin and hamiltonian monte carlo methods.pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {Bayesian inference,Geometry in statistics,Hamiltonian Monte Carlo methods,Langevin diffusion,Markov chain Monte Carlo methods,Riemann manifolds},
  number = {2}
}

@article{Griffin2008Spatial,
  title = {Spatial Analysis of Yield Monitor Data: {{Case}} Studies of on-Farm Trials and Farm Management Decision Making},
  author = {Griffin, Terry W. and Dobbins, Craig L. and Vyn, Tony J. and Florax, Raymond J.G.M. G M and {Lowenberg-Deboer}, James M.},
  year = {2008},
  volume = {9},
  pages = {269--283},
  issn = {13852256},
  doi = {10.1007/s11119-008-9072-2},
  abstract = {A 3-year case study was undertaken of how North American farmers use yield monitors for on-farm trials in farm management decision making. Case study methods were used because relatively few farmers quantitatively analyze yield monitor data. At this early research stage, insufficient farm management information about the data was available to ask the right questions in a large-scale survey. In addition to the formal case study of farmers experienced at using yield monitors to collect on-farm trial data, the study evaluated the effect of yield monitor data quality on farm decisions. Two levels of yield data quality included standard output where the default settings of farm-level mapping software were accepted and where filtering of the data was undertaken. Results indicated that yield data quality affects farm management decisions. In addition, farmers receiving a spatial analysis of their on-farm trial data tended to use split-field designs instead of replicated split-planter designs. They were also more confident in their decisions than before participation in the spatial analysis project, and made decisions more quickly. \textcopyright 2008 Springer Science+Business Media, LLC.},
  annotation = {ZSCC: 0000052},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Griffin et al_2008_Spatial analysis of yield monitor data.pdf},
  journal = {Precis. Agric.},
  keywords = {Data quality,Decision-making,On-farm testing,Spatial analysis,Yield monitor}
}

@article{Guan2017Estimation,
  title = {Estimation of Genetic Parameters for Growth Trait of Turbot Using {{Bayesian}} and {{REML}} Approaches},
  author = {Guan, Jiantao and Wang, Weiji and Hu, Yulong and Wang, Mosang and Tian, Tao and Kong, Jie},
  year = {2017},
  month = jun,
  volume = {36},
  pages = {47--51},
  issn = {0253-505X, 1869-1099},
  doi = {10.1007/s13131-017-1034-y},
  abstract = {Bayesian and restricted maximum likelihood (REML) approaches were used to estimate the genetic parameters in a cultured turbot Scophthalmus maximus stock. The data set consisted of harvest body weight from 2 462 progenies (17 months old) from 28 families that were produced through artificial insemination using 39 parent fish. An animal model was applied to partition each weight value into a fixed effect, an additive genetic effect, and a residual effect. The average body weight of each family, which was measured at 110 days post-hatching, was considered as a covariate. For Bayesian analysis, heritability and breeding values were estimated using both the posterior mean and mode from the joint posterior conditional distribution. The results revealed that for additive genetic variance, the posterior mean estimate ({$\frac{3}{4}$}a2 =9 320) was highest but with the smallest residual variance, REML estimates ({$\frac{3}{4}$}a2 =8 088) came second and the posterior mode estimate ({$\frac{3}{4}$}a2 =7 849) was lowest. The corresponding three heritability estimates followed the same trend as additive genetic variance and they were all high. The Pearson correlations between each pair of the three estimates of breeding values were all high, particularly that between the posterior mean and REML estimates (0.996 9). These results reveal that the differences between Bayesian and REML methods in terms of estimation of heritability and breeding values were small. This study provides another feasible method of genetic parameter estimation in selective breeding programs of turbot.},
  annotation = {ZSCC: 0000002},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\DKEGH7RQ\\Guan et al. - 2017 - Estimation of genetic parameters for growth trait .pdf},
  journal = {Acta Oceanol. Sin.},
  language = {en},
  number = {6}
}

@article{guttman1967Use,
  title = {The {{Use}} of the {{Concept}} of a {{Future Observation}} in {{Goodness}}-{{Of}}-{{Fit Problems}}},
  author = {Guttman, Irwin},
  year = {1967},
  volume = {29},
  pages = {83--100},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1967.tb00676.x},
  abstract = {An attack on the problem of goodness of fit is made by combining a Bayesian and sampling argument; the Bayesian part is effected by using the distribution of a future observation, while the sampling argument concerns itself with the distribution of a ``chi-squared like'' statistic, which measures discrepancies of observed frequencies from those predicted by the distribution of the future observation. Examples are given for the case of sampling from the binomial, Poisson and normal distributions. An interesting application arising from the above approach is a procedure for estimating the degree of a polynomial response function.},
  annotation = {ZSCC: 0000248  \_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1967.tb00676.x},
  copyright = {\textcopyright{} 1967 The Authors},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\39JHU33D\\j.2517-6161.1967.tb00676.html},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  language = {en},
  number = {1}
}

@article{Hartman2008Fast,
  title = {Fast Kriging of Large Data Sets with {{Gaussian Markov}} Random Fields},
  author = {Hartman, Linda and H{\"o}ssjer, Ola},
  year = {2008},
  month = jan,
  volume = {52},
  pages = {2331--2349},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2007.09.018},
  abstract = {Spatial data sets are analysed in many scientific disciplines. Kriging, i.e. minimum mean squared error linear prediction, is probably the most widely used method of spatial prediction. Computation time and memory requirement can be an obstacle for kriging for data sets with many observations. Calculations are accelerated and memory requirements decreased by using a Gaussian Markov random field on a lattice as an approximation of a Gaussian field. The algorithms are well suited also for nonlattice data when exploiting a bilinear interpolation at nonlattice locations.},
  annotation = {ZSCC: 0000085},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Hartman_Hössjer_2008_Fast kriging of large data sets with Gaussian Markov random fields.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\PTYFBUC5\\S0167947307003568.html},
  journal = {Computational Statistics \& Data Analysis},
  keywords = {Bilinear interpolation,Markov random field,Nonlattice data,Spatial interpolation},
  language = {en},
  number = {5}
}

@article{Hastings1970Monte,
  ids = {hastings1970monte},
  title = {Monte {{Carlo}} Sampling Methods Using {{Markov}} Chains and Their Applications},
  author = {Hastings, W. Keith},
  year = {1970},
  volume = {57},
  pages = {97--109},
  publisher = {{Biometrika Trust}},
  doi = {10.1093/biomet/57.1.97},
  annotation = {ZSCC: 0015568},
  journal = {Biometrika},
  number = {1},
  owner = {zcao},
  timestamp = {2017.10.23}
}

@book{Hinkelmann2012Design,
  title = {Design and Analysis of Experiments},
  author = {Hinkelmann, Klaus},
  year = {2012},
  volume = {3},
  publisher = {{John Wiley \& Sons, Inc}},
  issn = {0964-1998},
  doi = {10.1002/9781118147634},
  abstract = {Design and Analysis of Experiments, Volume 3: Special Designs and Applications continues building upon the philosophical foundations of experimental design by providing important, modern applications of experimental design to the many fields that utilize them. The book also presents optimal and efficient designs for practice and covers key topics in current statistical research. Featuring contributions from leading researchers and academics, the book demonstrates how the presented concepts are used across various fields from genetics and medicinal and pharmaceutical research to manufacturing, engineering, and national security. Each chapter includes an introduction followed by the historical background as well as in-depth procedures that aid in the construction and analysis of the discussed designs. Topical coverage includes: \textbullet{} Genetic cross experiments, microarray experiments, and variety trials \textbullet{} Clinical trials, group-sequential designs, and adaptive designs \textbullet{} Fractional factorial and search, choice, and optimal designs for generalized linear models \textbullet{} Computer experiments with applications to homeland security \textbullet{} Robust parameter designs and split-plot type response surface designs \textbullet{} Analysis of directional data experiments. Throughout the book, illustrative and numerical examples utilize SAS\textregistered, JMP\textregistered, and R software programs to demonstrate the discussed techniques. Related data sets and software applications are available on the book's related FTP site. Design and Analysis of Experiments, Volume 3 is an ideal textbook for graduate courses in experimental design and also serves as a practical, hands-on reference for statisticians and researchers across a wide array of subject areas, including biological sciences, engineering, medicine, and business.},
  annotation = {ZSCC: 0000071},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Hinkelmann_2012_Design and analysis of experiments.pdf},
  isbn = {978-0-470-53068-9},
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}}
}

@article{Hoef2018Spatial,
  title = {Spatial Autoregressive Models for Statistical Inference from Ecological Data},
  author = {Hoef, Jay M. Ver and Peterson, Erin E. and Hooten, Mevin B. and Hanks, Ephraim M. and Fortin, Marie-Jos{\`e}e},
  year = {2018},
  month = feb,
  volume = {88},
  pages = {36--59},
  issn = {00129615},
  doi = {10.1002/ecm.1283},
  abstract = {Ecological data often exhibit spatial pattern, which can be modeled as autocorrelation. Conditional autoregressive (CAR) and simultaneous autoregressive (SAR) models are network-based models (also known as graphical models) specifically designed to model spatially autocorrelated data based on neighborhood relationships. We identify and discuss six different types of practical ecological inference using CAR and SAR models, including: (1) model selection, (2) spatial regression, (3) estimation of autocorrelation, (4) estimation of other connectivity parameters, (5) spatial prediction, and (6) spatial smoothing. We compare CAR and SAR models, showing their development and connection to partial correlations. Special cases, such as the intrinsic autoregressive model (IAR), are described. Conditional autoregressive and SAR models depend on weight matrices, whose practical development uses neighborhood definition and row-standardization. Weight matrices can also include ecological covariates and connectivity structures, which we emphasize, but have been rarely used. Trends in harbor seals (Phoca vitulina) in southeastern Alaska from 463 polygons, some with missing data, are used to illustrate the six inference types. We develop a variety of weight matrices and CAR and SAR spatial regression models are fit using maximum likelihood and Bayesian methods. Profile likelihood graphs illustrate inference for covariance parameters. The same data set is used for both prediction and smoothing, and the relative merits of each are discussed. We show the nonstationary variances and correlations of a CAR model and demonstrate the effect of row-standardization. We include several take-home messages for CAR and SAR models, including (1) choosing between CAR and IAR models, (2) modeling ecological effects in the covariance matrix, (3) the appeal of spatial smoothing, and (4) how to handle isolated neighbors. We highlight several reasons why ecologists will want to make use of autoregressive models, both directly and in hierarchical models, and not only in explicit spatial settings, but also for more general connectivity models.},
  annotation = {ZSCC: 0000057},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\86EAUYWK\\Spatial autoregressive models for statistical inference from ecological data.pdf},
  journal = {Ecol Monogr},
  language = {en},
  number = {1}
}

@article{Hoffman2014NoUturn,
  title = {The {{No}}-{{U}}-Turn Sampler: Adaptively Setting Path Lengths in {{Hamiltonian Monte Carlo}}},
  shorttitle = {The {{No}}-{{U}}-Turn Sampler},
  author = {Hoffman, Matthew D. and Gelman, Andrew},
  year = {2014},
  month = jan,
  volume = {15},
  pages = {1593--1623},
  issn = {1532-4435},
  abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size {$\epsilon$} and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as efficiently as (and sometimes more effciently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter {$\epsilon$} on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" samplers.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Homan_Gelman_2014_The No-U-turn sampler.pdf},
  journal = {J. Mach. Learn. Res.},
  keywords = {adaptive Monte Carlo,Bayesian inference,dual averaging,Hamiltonian Monte Carlo,Markov chain Monte Carlo},
  number = {1}
}

@article{Hong2005Spatial,
  title = {Spatial Analysis of Precision Agriculture Treatments in Randomized Complete Blocks: {{Guidelines}} for Covariance Model Selection},
  author = {Hong, Nan and White, Jeffrey G. and Gumpertz, Marcia L. and Weisz, Randy},
  year = {2005},
  volume = {97},
  pages = {1082--1096},
  issn = {0002-1962},
  doi = {10.2134/agronj2004.0130},
  abstract = {Failure to account for spatially correlated errors when present in the classical randomized complete block (RCB) analysis may cause inefficient estimation of treatment significance. Covariance model selection is a necessary component for spatial adjustment to estimate treatment significance. We discuss methods for selecting a covariance model in RCB analyses in the presence of spatial correlation and demonstrate one procedure in detail. The procedure uses three models: the randomized complete block with independent and identically distributed errors (RCBiid), RCB with correlated errors, and models with correlated errors but no block effects. The semivariogram of the residuals from fitting a model with just fixed effects, the likelihood ratio test, and Akaike Information Criterion are used for model selection. To illustrate the procedure, we analyzed winter wheat (Triticum aestivum L.) forage and corn (Zea mays L.) grain yield in the presence of spatial heterogeneity within blocks from a site-specific N management study. We compared the selected covariance models to the RCBiid models and to other spatial models with respect to the estimation of treatment significance. The procedure can be extended to any experiment with fixed effects, or with both fixed and random effects, and which may potentially have spatially correlated errors. The procedure is systematic and readily implemented; however, it remains difficult to evaluate whether an adequate covariance model has been selected.},
  annotation = {ZSCC: 0000037},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Hong et al_2005_Spatial analysis of precision agriculture treatments in randomized complete.pdf},
  journal = {Agronomy Journal},
  number = {4}
}

@article{Hurley2004Estimating,
  title = {Estimating Site-Specific Nitrogen Crop Response Functions: {{A}} Conceptual Framework and Geostatistical Model},
  author = {Hurley, T. M. and Malzer, G. L. and Kilian, B.},
  year = {2004},
  volume = {96},
  pages = {1331--1343},
  issn = {00021962},
  doi = {10.2134/agronj2004.1331},
  abstract = {Confirming the precision agriculture hypothesis for variable-rate N applications (VRAs) is challenging. To confront this challenge, researchers have used increasingly sophisticated statistical models to estimate and compare site-specific crop response functions (SSCRFs). While progress has been made, it has been hampered by the lack of a conceptual framework to guide the development of appropriate statistical models. This paper provides such a framework and demonstrates its utility by developing a heteroscedastic, fixed and random effects, geostatistical model to test if VRA can increase N returns. The novelty of the model is the inclusion of site, spatial, treatment, and treatment strip heteroscedasticity and correlation. Applied to data collected in 1995 from two corn (Zea mays L.) N response experiments in south-central Minnesota, results demonstrate the importance of including site, spatial, treatment, and treatment strip effects in the estimation of SSCRFs. Results also indicate a significant potential for VRA to increase N returns and that these potential returns increase as the area of the management unit decreases. At one location, there was greater than a 95\% chance that VRA could have increased profitability if the cost of implementing VRA was less than \$14.5 ha -1. At the other location, if implementation costs were less than \$48.3 ha-1, there was greater than a 95\% chance of increased profitability.},
  annotation = {ZSCC: 0000058},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Hurley et al_2004_Estimating site-specific nitrogen crop response functions.pdf},
  journal = {Agronomy Journal},
  number = {5}
}

@article{Jadaliha2018Fully,
  title = {Fully {{Bayesian Prediction Algorithms}} for {{Mobile Robotic Sensors}} under {{Uncertain Localization Using Gaussian Markov Random Fields}}},
  author = {Jadaliha, Mahdi and Jeong, Jinho and Xu, Yunfei and Choi, Jongeun and Kim, Junghoon},
  year = {2018},
  month = aug,
  volume = {18},
  issn = {1424-8220},
  doi = {10.3390/s18092866},
  abstract = {In this paper, we present algorithms for predicting a spatio-temporal random field measured by mobile robotic sensors under uncertainties in localization and measurements. The spatio-temporal field of interest is modeled by a sum of a time-varying mean function and a Gaussian Markov random field (GMRF) with unknown hyperparameters. We first derive the exact Bayesian solution to the problem of computing the predictive inference of the random field, taking into account observations, uncertain hyperparameters, measurement noise, and uncertain localization in a fully Bayesian point of view. We show that the exact solution for uncertain localization is not scalable as the number of observations increases. To cope with this exponentially increasing complexity and to be usable for mobile sensor networks with limited resources, we propose a scalable approximation with a controllable trade-off between approximation error and complexity to the exact solution. The effectiveness of the proposed algorithms is demonstrated by simulation and experimental results.},
  annotation = {ZSCC: 0000001},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Jadaliha et al_2018_Fully Bayesian Prediction Algorithms for Mobile Robotic Sensors under Uncertain.pdf},
  journal = {Sensors (Basel)},
  number = {9},
  pmcid = {PMC6164902},
  pmid = {30200257}
}

@article{Juarez2010ModelBased,
  title = {Model-{{Based Clustering}} of {{Non}}-{{Gaussian Panel Data Based}} on {{Skew}}- {\emph{t}} {{Distributions}}},
  author = {Ju{\'a}rez, Miguel A. and Steel, Mark F. J.},
  year = {2010},
  month = jan,
  volume = {28},
  pages = {52--66},
  issn = {0735-0015, 1537-2707},
  doi = {10.1198/jbes.2009.07145},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CVFIFKXK\\jbes.2009.pdf},
  journal = {Journal of Business \& Economic Statistics},
  language = {en},
  number = {1}
}

@article{Kass2006Adefault,
  title = {A Default Conjugate Prior for Variance Components in Generalized Linear Mixed Models ({{Comment}} on {{Article}} by {{Browne}} and {{Draper}})},
  author = {Kass, Robert E. and Natarajan, Ranjini},
  year = {2006},
  volume = {1},
  pages = {535--542},
  issn = {19360975},
  doi = {10.1214/06-ba117b},
  abstract = {For a scalar random-effect variance, Browne and Draper (2005) have found that the uniform prior works well. It would be valuable to know more about the vector case, in which a second-stage prior on the random effects variance matrix D is needed. We suggest consideration of an inverse Wishart prior for D where the scale matrix is determined from the first-stage variance. \textcopyright{} 2006 International Society for Bayesian Analysis ba0003.},
  annotation = {ZSCC: 0000071},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Kass_Natarajan_2006_A default conjugate prior for variance components in generalized linear mixed.pdf},
  journal = {Bayesian Analysis},
  keywords = {Choice of prior,Hierarchical models,Noninformative priors,Random effects},
  number = {3}
}

@book{Lanczos1950Iteration,
  title = {An Iteration Method for the Solution of the Eigenvalue Problem of Linear Differential and Integral Operators},
  author = {Lanczos, Cornelius},
  year = {1950},
  publisher = {{United States Governm. Press Office Los Angeles, CA}},
  annotation = {ZSCC: 0005007},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Lanczos_1950_An iteration method for the solution of the eigenvalue problem of linear.pdf}
}

@book{lawson2013Statistical,
  title = {Statistical {{Methods}} in {{Spatial Epidemiology}}},
  author = {Lawson, Andrew B.},
  year = {2013},
  publisher = {{John Wiley \& Sons}},
  annotation = {ZSCC: 0000786},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\BS2WWKGS\\books.html},
  isbn = {978-0-470-01484-4}
}

@article{Leong2017Amodification,
  title = {A Modification to Geographically Weighted Regression},
  author = {Leong, Yin Yee and Yue, Jack C.},
  year = {2017},
  volume = {16},
  pages = {1--18},
  publisher = {{BioMed Central}},
  issn = {1476072X},
  doi = {10.1186/s12942-017-0085-9},
  abstract = {Background: Geographically weighted regression (GWR) is a modelling technique designed to deal with spatial non-stationarity, e.g., the mean values vary by locations. It has been widely used as a visualization tool to explore the patterns of spatial data. However, the GWR tends to produce unsmooth surfaces when the mean parameters have considerable variations, partly due to that all parameter estimates are derived from a fixed- range (bandwidth) of observations. In order to deal with the varying bandwidth problem, this paper proposes an alternative approach, namely Conditional geographically weighted regression (CGWR). Methods: The estimation of CGWR is based on an iterative procedure, analogy to the numerical optimization problem. Computer simulation, under realistic settings, is used to compare the performance between the traditional GWR, CGWR, and a local linear modification of GWR. Furthermore, this study also applies the CGWR to two empirical datasets for evaluating the model performance. The first dataset consists of disability status of Taiwan's elderly, along with some social-economic variables and the other is Ohio's crime dataset. Results: Under the positively correlated scenario, we found that the CGWR produces a better fit for the response surface. Both the computer simulation and empirical analysis support the proposed approach since it significantly reduces the bias and variance of data fitting. In addition, the response surface from the CGWR reviews local spatial characteristics according to the corresponded variables. Conclusions: As an explanatory tool for spatial data, producing accurate surface is essential in order to provide a first look at the data. Any distorted outcomes would likely mislead the following analysis. Since the CGWR can generate more accurate surface, it is more appropriate to use it exploring data that contain suspicious variables with varying characteristics.},
  annotation = {ZSCC: 0000034},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Leong_Yue_2017_A modification to geographically weighted regression.pdf},
  isbn = {1294201700},
  journal = {International Journal of Health Geographics},
  keywords = {Computer simulation,Cross validation,Generalized additive model,Geographically weighted regression,Modifiable areal unit problem (MAUP)},
  number = {1}
}

@article{Lindgren2011Explicit,
  title = {An Explicit Link between {{Gaussian}} Fields and {{Gaussian Markov}} Random Fields: The Stochastic Partial Differential Equation Approach},
  shorttitle = {An Explicit Link between {{Gaussian}} Fields and {{Gaussian Markov}} Random Fields},
  author = {Lindgren, Finn and Rue, H{\aa}vard and Lindstr{\"o}m, Johan},
  year = {2011},
  volume = {73},
  pages = {423--498},
  issn = {1467-9868},
  doi = {10.1111/j.1467-9868.2011.00777.x},
  abstract = {Summary. Continuously indexed Gaussian fields (GFs) are the most important ingredient in spatial statistical modelling and geostatistics. The specification through the covariance function gives an intuitive interpretation of the field properties. On the computational side, GFs are hampered with the big n problem, since the cost of factorizing dense matrices is cubic in the dimension. Although computational power today is at an all time high, this fact seems still to be a computational bottleneck in many applications. Along with GFs, there is the class of Gaussian Markov random fields (GMRFs) which are discretely indexed. The Markov property makes the precision matrix involved sparse, which enables the use of numerical algorithms for sparse matrices, that for fields in only use the square root of the time required by general algorithms. The specification of a GMRF is through its full conditional distributions but its marginal properties are not transparent in such a parameterization. We show that, using an approximate stochastic weak solution to (linear) stochastic partial differential equations, we can, for some GFs in the Mat\'ern class, provide an explicit link, for any triangulation of , between GFs and GMRFs, formulated as a basis function representation. The consequence is that we can take the best from the two worlds and do the modelling by using GFs but do the computations by using GMRFs. Perhaps more importantly, our approach generalizes to other covariance functions generated by SPDEs, including oscillating and non-stationary GFs, as well as GFs on manifolds. We illustrate our approach by analysing global temperature data with a non-stationary model defined on a sphere.},
  annotation = {ZSCC: 0000002  \_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2011.00777.x},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Lindgren et al_2011_An explicit link between Gaussian fields and Gaussian Markov random fields.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\QZWMIGEG\\j.1467-9868.2011.00777.html},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {Approximate Bayesian inference,Covariance functions,Gaussian fields,Gaussian Markov random fields,Latent Gaussian models,Sparse matrices,Stochastic partial differential equations},
  language = {en},
  number = {4}
}

@article{Loecke2017Weather,
  title = {Weather Whiplash in Agricultural Regions Drives Deterioration of Water Quality},
  author = {Loecke, Terrance D. and Burgin, Amy J. and {Riveros-Iregui}, Diego A. and Ward, Adam S. and Thomas, Steven A. and Davis, Caroline A. and Clair, Martin A. St.},
  year = {2017},
  month = mar,
  volume = {133},
  pages = {7--15},
  issn = {1573-515X},
  doi = {10.1007/s10533-017-0315-z},
  abstract = {Excess nitrogen (N) impairs inland water quality and creates hypoxia in coastal ecosystems. Agriculture is the primary source of N; agricultural management and hydrology together control aquatic ecosystem N loading. Future N loading will be determined by how agriculture and hydrology intersect with climate change, yet the interactions between changing climate and water quality remain poorly understood. Here, we show that changing precipitation patterns, resulting from climate change, interact with agricultural land use to deteriorate water quality. We focus on the 2012\textendash 2013 Midwestern U.S. drought as a ``natural experiment''. The transition from drought conditions in 2012 to a wet spring in 2013 was abrupt; the media dubbed this ``weather whiplash''. We use recent (2010\textendash 2015) and historical data (1950\textendash 2015) to connect weather whiplash (drought-to-flood transitions) to increases in riverine N loads and concentrations. The drought likely created highly N-enriched soils; this excess N mobilized during heavy spring rains (2013), resulting in a 34\% increase (10.5 vs. 7.8~mg~N~L-1) in the flow-weighted mean annual nitrate concentration compared to recent years. Furthermore, we show that climate change will likely intensify weather whiplash. Increased weather whiplash will, in part, increase the frequency of riverine N exceeding E.P.A. drinking water standards. Thus, our observations suggest increased climatic variation will amplify negative trends in water quality in a region already grappling with severe impairments.},
  annotation = {ZSCC: 0000051},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Loecke et al_2017_Weather whiplash in agricultural regions drives deterioration of water quality.pdf},
  journal = {Biogeochemistry},
  language = {en},
  number = {1}
}

@article{Ludwig2020Splinebased,
  title = {On Spline-Based Approaches to Spatial Linear Regression for Geostatistical Data},
  author = {Ludwig, Guilherme and Zhu, Jun and Reyes, Perla and Chen, Chun-Shu and Conley, Shawn P.},
  year = {2020},
  month = jun,
  volume = {27},
  pages = {175--202},
  issn = {1352-8505, 1573-3009},
  doi = {10.1007/s10651-020-00441-9},
  abstract = {For spatial linear regression, the traditional approach to capture spatial dependence is to use a parametric linear mixed-effects model. Spline surfaces can be used as an alternative to capture spatial variability, giving rise to a semiparametric method that does not require the specification of a parametric covariance structure. The spline component in such a semiparametric method, however, impacts the estimation of the regression coefficients. In this paper, we investigate such an impact in spatial linear regression with spline-based spatial effects. Statistical properties of the regression coefficient estimators are established under the model assumptions of the traditional spatial linear regression. Further, we examine the empirical properties of the regression coefficient estimators under spatial confounding via a simulation study. A data example in precision agriculture research regarding soybean yield in relation to field conditions is presented for illustration.},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\YRI9EDIB\\On spline-based approaches to spatial linear regression for geostatistical data.pdf},
  journal = {Environ Ecol Stat},
  language = {en},
  number = {2}
}

@incollection{Luttinen2012Efficient,
  title = {Efficient {{Gaussian Process Inference}} for {{Short}}-{{Scale Spatio}}-{{Temporal Modeling}}},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Luttinen, Jaakko and Ilin, Alexander},
  year = {2012},
  pages = {741--750},
  abstract = {This paper presents an efficient Gaussian process inference scheme for modeling shortscale phenomena in spatio-temporal datasets. Our model uses a sum of separable, compactly supported covariance functions, which yields a full covariance matrix represented in terms of small sparse matrices operating either on the spatial or temporal domain. The proposed inference procedure is based on Gibbs sampling, in which samples from the conditional distribution of the latent function values are obtained by applying a simple linear transformation to samples drawn from the joint distribution of the function values and the observations. We make use of the proposed model structure and the conjugate gradient method to compute the required transformation. In the experimental part, the proposed algorithm is compared to the standard approach using the sparse Cholesky decomposition and it is shown to be much faster and computationally feasible for 100\textendash 1000 times larger datasets. We demonstrate the advantages of the proposed method in the problem of reconstructing sea surface temperature, which requires processing of a real-world dataset with 106 observations.},
  annotation = {ZSCC: 0000026},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\APQLA22A\\Luttinen and Ilin - Eﬃcient Gaussian Process Inference for Short-Scale.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@book{MacKay2003Information,
  ids = {mackay2003information,mackayInformationTheoryInference2003a},
  title = {Information Theory, Inference and Learning Algorithms},
  author = {MacKay, David JC},
  year = {2003},
  publisher = {{Cambridge university press}},
  annotation = {ZSCC: 0011087},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MacKay_Mac Kay_2003_Information theory, inference and learning algorithms.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\6YXA4MTK\\books.html}
}

@article{Madar2015Direct,
  title = {Direct Formulation to {{Cholesky}} Decomposition of a General Nonsingular Correlation Matrix},
  author = {Madar, Vered},
  year = {2015},
  volume = {103},
  pages = {142--147},
  publisher = {{Elsevier B.V.}},
  issn = {01677152},
  doi = {10.1016/j.spl.2015.03.014},
  abstract = {We present two novel and explicit parametrizations of Cholesky factor of a nonsingular correlation matrix. One that uses semi-partial correlation coefficients, and a second that utilizes differences between the successive ratios of two determinants. To each, we offer a useful application.},
  annotation = {ZSCC: 0000014},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Madar_2015_Direct formulation to Cholesky decomposition of a general nonsingular.pdf},
  isbn = {2163684814},
  journal = {Statistics and Probability Letters},
  keywords = {Cholesky factor,Correlation matrix,Generating random correlation matrix,Partial and semi-partial correlation coefficient},
  number = {1},
  pmid = {28363838}
}

@article{Mariel2018More,
  title = {A {{More Flexible Model}} or {{Simply More Effort}}? {{On}} the {{Use}} of {{Correlated Random Parameters}} in {{Applied Choice Studies}}},
  shorttitle = {A {{More Flexible Model}} or {{Simply More Effort}}?},
  author = {Mariel, Petr and Meyerhoff, J{\"u}rgen},
  year = {2018},
  month = dec,
  volume = {154},
  pages = {419--429},
  issn = {0921-8009},
  doi = {10.1016/j.ecolecon.2018.08.020},
  abstract = {The random parameter logit model has become the dominating model for analyzing stated choice data in environmental valuation. The unrestricted version of the model with correlated random parameters, however, is rarely applied. An important advantage of this specification is that the correlations between the parameters are not restricted to zero. These correlations can arise due to a behavioural phenomena or scale heterogeneity. One consequence of this might be that derived willingness-to-pay or to-accept estimates are under- or overestimated, providing decision makers with incorrect estimates. We compare both model specifications using data from a study about farmers' willingness to accept compensation for implementing agri-environmental measures in Brandenburg, Germany. For this data both model specifications - with and without correlated random parameters - provide similar willing-to-accept estimates, but the model with correlations performs better despite the higher number of parameters. As our findings could be case study specific, we want to encourage especially applied researchers to estimate also specifications with correlated random parameters. Applying only models with uncorrelated random parameters can result in biased estimates and thus provide incorrect information to decision makers.},
  annotation = {ZSCC: 0000010},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Mariel_Meyerhoff_2018_A More Flexible Model or Simply More Effort.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\S76LP9IU\\S0921800918306189.html},
  journal = {Ecological Economics},
  keywords = {Agri-environmental measures,Choice experiment,Correlated parameters,Random parameter logit model},
  language = {en}
}

@article{martinez-casasnovas2018Use,
  title = {Use of {{Farmer Knowledge}} in the {{Delineation}} of {{Potential Management Zones}} in {{Precision Agriculture}}: {{A Case Study}} in {{Maize}} ({{Zea}} Mays {{L}}.)},
  shorttitle = {Use of {{Farmer Knowledge}} in the {{Delineation}} of {{Potential Management Zones}} in {{Precision Agriculture}}},
  author = {{Mart{\'i}nez-Casasnovas}, Jos{\'e} and Escol{\`a}, Alexandre and Arn{\'o}, Jaume},
  year = {2018},
  month = jun,
  volume = {8},
  pages = {84},
  issn = {2077-0472},
  doi = {10.3390/agriculture8060084},
  abstract = {One of the fields of research in precision agriculture (PA) is the delineation of potential management zones (PMZs, also known as site-specific management zones, or simply management zones). To delineate PMZs, cluster analysis is the main used and recommended methodology. For cluster analysis, mainly yield maps, remote sensing multispectral indices, apparent soil electrical conductivity (ECa), and topography data are used. Nevertheless, there is still no accepted protocol or guidelines for establishing PMZs, and different solutions exist. In addition, the farmer's expert knowledge is not usually taken into account in the delineation process. The objective of the present work was to propose a methodology to delineate potential management zones for differential crop management that expresses the productive potential of the soil within a field. The Management Zone Analyst (MZA) software, which implements a fuzzy c-means algorithm, was used to create different alternatives of PMZ that were validated with yield data in a maize (Zea mays L.) field. The farmers' expert knowledge was then taken into account to improve the resulting PMZs that best fitted to the yield spatial variability pattern. This knowledge was considered highly valuable information that could be also very useful for deciding management actions to be taken to reduce within-field variability.},
  annotation = {ZSCC: NoCitationData[s1]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\WXPXPXDR\\Martínez-Casasnovas et al. - 2018 - Use of Farmer Knowledge in the Delineation of Pote.pdf},
  journal = {Agriculture},
  language = {en},
  number = {6}
}

@book{McElreath2015Statistical,
  title = {Statistical Rethinking: {{A}} Bayesian Course with Examples in {{R}} and Stan},
  author = {McElreath, Richard},
  year = {2015},
  month = dec,
  edition = {First},
  volume = {122},
  publisher = {{CRC Press LLC}},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds readers' knowledge of and confidence in statistical modeling. Reflecting the need for even minor programming in today's model-based statistics, the book pushes readers to perform step-by-step calculations that are usually automated. This unique computational approach ensures that readers understand enough of the details to make reasonable choices and interpretations in their own modeling work. The text presents generalized linear multilevel models from a Bayesian perspective, relying on a simple logical interpretation of Bayesian probability and maximum entropy. It covers from the basics of regression to multilevel models. The author also discusses measurement error, missing data, and Gaussian process models for spatial and network autocorrelation. By using complete R code examples throughout, this book provides a practical foundation for performing statistical inference. Designed for both PhD students and seasoned professionals in the natural and social sciences, it prepares them for more advanced or specialized statistical modeling. Web Resource The book is accompanied by an R package (rethinking) that is available on the author's website and GitHub. The two core functions (map and map2stan) of this package allow a variety of statistical models to be constructed from standard model formulas.},
  isbn = {978-1-4822-5346-7},
  language = {English},
  series = {Chapman and {{Hall}}/{{CRC Texts}} in {{Statistical Science Ser}}.}
}

@article{Metropolis1953Equation,
  ids = {metropolis1953equation},
  title = {Equation of State Calculations by Fast Computing Machines},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  year = {1953},
  volume = {21},
  pages = {1087--1092},
  publisher = {{AIP}},
  doi = {10.1063/1.1699114},
  annotation = {ZSCC: 0042597},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\DSAM39UR\\Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing M.pdf},
  journal = {The Journal of Chemical Physics},
  number = {6},
  owner = {zcao},
  timestamp = {2017.10.23}
}

@article{Moeyaert2017,
  title = {Multilevel Modeling of Single-Case Data: {{A}} Comparison of Maximum Likelihood and Bayesian Estimation},
  author = {Moeyaert, Mariola and Rindskopf, David and Onghena, Patrick and Noortgate, Wim Van Den},
  year = {2017},
  volume = {22},
  pages = {760--778},
  issn = {1082989X},
  doi = {10.1037/met0000136},
  abstract = {The focus of this article is to describe Bayesian estimation, including construction of prior distributions, and to compare parameter recovery under the Bayesian framework (using weakly informative priors) and the maximum likelihood (ML) framework in the context of multilevel modeling of single-case experimental data. Bayesian estimation results were found similar to ML estimation results in terms of the treatment effect estimates, regardless of the functional form and degree of information included in the prior specification in the Bayesian framework. In terms of the variance component estimates, both the ML and Bayesian estimation procedures result in biased and less precise variance estimates when the number of participants is small (i.e., 3). By increasing the number of participants to 5 or 7, the relative bias is close to 5\% and more precise estimates are obtained for all approaches, except for the inverse-Wishart prior using the identity matrix. When a more informative prior was added, more precise estimates for the fixed effects and random effects were obtained, even when only 3 participants were included.},
  journal = {Psychol. Methods},
  keywords = {2-level modeling,Bayesian statistics,maximum likelihood,single-case designs,weakly informative prior},
  number = {4}
}

@article{Monnahan2017Faster,
  title = {Faster Estimation of {{Bayesian}} Models in Ecology Using {{Hamiltonian Monte Carlo}}},
  author = {Monnahan, Cole C. and Thorson, James T. and Branch, Trevor A.},
  year = {2017},
  volume = {8},
  pages = {339--348},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12681},
  abstract = {Bayesian inference is a powerful tool to better understand ecological processes across varied subfields in ecology, and is often implemented in generic and flexible software packages such as the widely used BUGS family (BUGS, WinBUGS, OpenBUGS and JAGS). However, some models have prohibitively long run times when implemented in BUGS. A relatively new software platform called Stan uses Hamiltonian Monte Carlo (HMC), a family of Markov chain Monte Carlo (MCMC) algorithms which promise improved efficiency and faster inference relative to those used by BUGS. Stan is gaining traction in many fields as an alternative to BUGS, but adoption has been slow in ecology, likely due in part to the complex nature of HMC. Here, we provide an intuitive illustration of the principles of HMC on a set of simple models. We then compared the relative efficiency of BUGS and Stan using population ecology models that vary in size and complexity. For hierarchical models, we also investigated the effect of an alternative parameterization of random effects, known as non-centering. For small, simple models there is little practical difference between the two platforms, but Stan outperforms BUGS as model size and complexity grows. Stan also performs well for hierarchical models, but is more sensitive to model parameterization than BUGS. Stan may also be more robust to biased inference caused by pathologies, because it produces diagnostic warnings where BUGS provides none. Disadvantages of Stan include an inability to use discrete parameters, more complex diagnostics and a greater requirement for hands-on tuning. Given these results, Stan is a valuable tool for many ecologists utilizing Bayesian inference, particularly for problems where BUGS is prohibitively slow. As such, Stan can extend the boundaries of feasible models for applied problems, leading to better understanding of ecological processes. Fields that would likely benefit include estimation of individual and population growth rates, meta-analyses and cross-system comparisons and spatiotemporal models.},
  annotation = {ZSCC: 0000086  \_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12681},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Monnahan et al_2017_Faster estimation of Bayesian models in ecology using Hamiltonian Monte Carlo.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\LMMQXS5K\\2041-210X.html},
  journal = {Methods in Ecology and Evolution},
  keywords = {Bayesian inference,hierarchical modelling,Markov chain Monte Carlo,no-U-turn sampler,Stan},
  language = {en},
  number = {3}
}

@article{Montesinos-Lopez2018Multivariate,
  ids = {Montesinos-Lopez2019},
  title = {Multivariate {{Bayesian Analysis}} of {{On}}-{{Farm Trials}} with {{Multiple}}-{{Trait}} and {{Multiple}}-{{Environment Data}}},
  author = {Montesinos-L{\'o}pez, Osval A. and Montesinos-L{\'o}pez, Abelardo and Hern{\'a}ndez, Mateo Vargas and Ortiz-Monasterio, Iv{\'a}n and P{\'e}rez-Rodr{\'i}guez, Paulino and Burgue{\~n}o, Juan and Crossa, Jos{\'e}},
  year = {2018},
  month = nov,
  volume = {111},
  pages = {2658--2669},
  issn = {0002-1962, 1435-0645},
  doi = {10.2134/agronj2018.06.0362},
  abstract = {Multivariate analysis is preferred over univariate analysis in plant breeding studies because it can exploit correlated traits and environments, whereas Bayesian analysis provides a natural way to incorporate prior knowledge and inferences that are conditional on the observed data. The objective of this paper is to show how to use multivariate Bayesian analysis for estimating random effects of genotype \texttimes{} environment and genotype \texttimes{} environment \texttimes{} trait combinations, and for computing genotypic and phenotypic correlations among traits and environments. Data were collected from on-farm trials conducted by the International Maize and Wheat Improvement Center (CIMMYT) to evaluate bread and durum wheat lines in the Yaqui Valley of southern Sonora, M\'exico, during three crop seasons (2012, 2013, and 2015). The Bayesian multi-trait and multienvironment model with Gibbs sampler provides an analytic solution that can be used as an alternative for analyzing on-farm multiple-trait and multiple-environment data because it allows making parsimonious, precise and simultaneous estimations of random effects, genetic correlations (of traits and environments) and residual correlations of traits. The multivariate Bayesian model successfully fitted three of the four data sets (2012, 2015, and combined cropping seasons), but did not fit well the data of crop season 2013. For three out of five traits under study in this crop season, the correlations between the observed and predicted phenotypic values were lower than 0.6, suggesting that the predicted values were not very close to the observed values.},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\OFEandPA\\Montesinos‐López et al. - 2018 - Multivariate Bayesian Analysis of On‐Farm Trials w.pdf},
  journal = {Agron.j.},
  language = {en},
  number = {6}
}

@article{Ngombe2020Are,
  title = {``{{Are They Aware}}, and {{Why}}?'' {{Bayesian Analysis}} of {{Predictors}} of {{Smallholder Farmers}}' {{Awareness}} of {{Climate Change}} and {{Its Risks}} to {{Agriculture}}},
  shorttitle = {``{{Are They Aware}}, and {{Why}}?},
  author = {Ng'ombe, John N. and Tembo, Moses C. and Masasi, Blessing},
  year = {2020},
  month = mar,
  volume = {10},
  pages = {376},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/agronomy10030376},
  abstract = {While climate change threatens global food security, health, and nutrition outcomes, Africa is more vulnerable because its economies largely depend on rain-fed agriculture. Thus, there is need for agricultural producers in Africa to employ robust adaptive measures that withstand the risks of climate change. However, the success of adaptation measures to climate change primarily depends on the communities' knowledge or awareness of climate change and its risks. Nonetheless, existing empirical research is still limited to illuminate farmers' awareness of the climate change problem. This study employs a Bayesian hierarchical logistic model, estimated using Hamiltonian Monte Carlo (HMC) methods, to empirically determine drivers of smallholder farmers' awareness of climate change and its risks to agriculture in Zambia. The results suggest that on average, 77\% of farmers in Zambia are aware of climate change and its risks to agriculture. We find socio-demographics, climate change information sources, climate change adaptive factors, and climate change impact-related shocks as predictors of the expression of climate change awareness. We suggest that farmers should be given all the necessary information about climate change and its risks to agriculture. Most importantly, the drivers identified can assist policymakers to provide the effective extension and advisory services that would enhance the understanding of climate change among farmers in synergy with appropriate farm-level climate-smart agricultural practices.},
  annotation = {ZSCC: NoCitationData[s0]},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Ng’ombe et al_2020_“Are They Aware, and Why.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\DI2TH9ED\\376.html},
  journal = {Agronomy},
  keywords = {climate change,climate change awareness,climate-smart technologies,Hamiltonian Monte Carlo,Zambia},
  language = {en},
  number = {3}
}

@article{Nishio2019Performance,
  title = {Performance of {{Hamiltonian Monte Carlo}} and {{No}}-{{U}}-{{Turn Sampler}} for Estimating Genetic Parameters and Breeding Values},
  author = {Nishio, Motohide and Arakawa, Aisaku},
  year = {2019},
  month = dec,
  volume = {51},
  pages = {73},
  issn = {1297-9686},
  doi = {10.1186/s12711-019-0515-1},
  abstract = {Background:\hspace{0.6em} Hamiltonian Monte Carlo is one of the algorithms of the Markov chain Monte Carlo method that uses Hamiltonian dynamics to propose samples that follow a target distribution. The method can avoid the random walk behavior to achieve a more effective and consistent exploration of the probability space and sensitivity to correlated parameters, which are shortcomings that plague many Markov chain Monte Carlo methods. However, the performance of Hamiltonian Monte Carlo is highly sensitive to two hyperparameters. The No-U-Turn Sampler, an extension of Hamiltonian Monte Carlo, was recently introduced to automate the tuning of these hyperparameters. Thus, this study compared the performances of Gibbs sampling, Hamiltonian Monte Carlo, and the No-U-Turn Sampler for estimating genetic parameters and breeding values as well as sampling qualities in both simulated and real pig data. For all datasets, we used a pedigree-based univariate linear mixed model. Results:\hspace{0.6em} For all datasets, the No-U-Turn Sampler and Gibbs sampling performed comparably regarding the estimation of heritabilities and accuracies of breeding values. Compared with Gibbs sampling, the estimates of effective sample sizes for simulated and pig data with the No-U-Turn Sampler were 3.2 to 22.6 and 3.5 to 5.9 times larger, respectively. Autocorrelations decreased more quickly with the No-U-Turn Sampler than with Gibbs sampling. When true heritability was low in the simulated data, the skewness of the marginal posterior distributions with the No-UTurn Sampler was smaller than that with Gibbs sampling. The performance of Hamiltonian Monte Carlo for sampling quality was inferior to that of No-U-Turn Sampler in the simulated data. Moreover, Hamiltonian Monte Carlo could not estimate genetic parameters because of difficulties with the hyperparameter settings with pig data. Conclusions:\hspace{0.6em} The No-U-Turn Sampler is a promising sampling method for animal breeding because of its good sampling qualities: large effective sample sizes, low autocorrelations, and low skewness of marginal posterior distributions, particularly when heritability is low. Meanwhile, Hamiltonian Monte Carlo failed to converge with a simple univariate model for pig data. Thus, it might be difficult to use Hamiltonian Monte Carlo for usual complex models in animal breeding.},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Performance of Hamiltonian Monte Carlo and No-U-Turn Sampler for estimating genetic parameters and breeding values.pdf},
  journal = {Genet Sel Evol},
  language = {en},
  number = {1}
}

@article{Omer2015Bayesian,
  title = {Bayesian Estimation of Genotype-by-Environment Interaction in Sorghum Variety Trials},
  author = {Omer, Siraj Osman and Abdalla, Abdel Wahab Hassan and Mohammed, Mohammed Hamza and Singh, Murari},
  year = {2015},
  volume = {10},
  pages = {82--95},
  annotation = {ZSCC: 0000012},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Omer et al_2015_Bayesian estimation of genotype-by-environment interaction in sorghum variety.pdf},
  journal = {Communications in Biometry and Crop Science},
  keywords = {⛔ No DOI found}
}

@article{Omer2017Comparing,
  title = {Comparing {{Bayesian}} and {{Frequentist Approaches}} for {{GGE Bi}}-Plot {{Analysis}} in {{Multi}}-{{Environment Trials}} in {{Sorghum}}},
  author = {Omer, S. O. and Singh, M.},
  year = {2017},
  volume = {7},
  pages = {40},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Omer_Singh_2017_Comparing Bayesian and Frequentist Approaches for GGE Bi-plot Analysis in.pdf},
  journal = {Eur Exp Biol},
  keywords = {⛔ No DOI found},
  number = {6}
}

@article{Onofri2019Analysing,
  ids = {Onofri2019},
  title = {Analysing Censored Data in Agricultural Research: {{A}} Review with Examples and Software Tips},
  shorttitle = {Analysing Censored Data in Agricultural Research},
  author = {Onofri, Andrea and Piepho, Hans-Peter and Kozak, Marcin},
  year = {2019},
  volume = {174},
  pages = {3--13},
  issn = {1744-7348},
  doi = {10.1111/aab.12477},
  abstract = {Metric data are usually assessed on a continuous scale with good precision, but sometimes agricultural researchers cannot obtain precise measurements of a variable. Values of such a variable cannot then be expressed as real numbers (e.g., 1.51 or 2.56), but often can be represented by intervals into which the values fall (e.g., from 1 to 2 or from 2 to 3). In this situation, statisticians talk about censoring and censored data, as opposed to missing data, where no information is available at all. Traditionally, in agriculture and biology, three methods have been used to analyse such data: (a) when intervals are narrow, some form of imputation (e.g., mid-point imputation) is used to replace the interval and traditional methods for continuous data are employed (such as analyses of variance [ANOVA] and regression); (b) for time-to-event data, the cumulative proportions of individuals that experienced the event of interest are analysed, instead of the individual observed times-to-event; (c) when intervals are wide and many individuals are collected, non-parametric methods of data analysis are favoured, where counts are considered instead of the individual observed value for each sample element. In this paper, we show that these methods may be suboptimal: The first one does not respect the process of data collection, the second leads to unreliable standard errors (SEs), while the third does not make full use of all the available information. As an alternative, methods of survival analysis for censored data can be useful, leading to reliable inferences and sound hypotheses testing. These methods are illustrated using three examples from plant and crop sciences.},
  annotation = {ZSCC: 0000007  \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/aab.12477},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Onofri et al_2019_Analysing censored data in agricultural research.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\FLWD2KQ8\\aab.html},
  journal = {Annals of Applied Biology},
  keywords = {Bayesian model,censored data,interval data,R,SAS,survival analysis,time-to-event data},
  language = {en},
  number = {1}
}

@article{OSullivan2003Geographically,
  title = {Geographically Weighted Regression: {{The}} Analysis of Spatially Varying Relationships (Review)},
  author = {O'Sullivan, David},
  year = {2003},
  volume = {35},
  pages = {272--275},
  issn = {1538-4632},
  doi = {10.1353/geo.2003.0008},
  abstract = {applicability for this approach.},
  annotation = {ZSCC: NoCitationData[s1]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\O'Sullivan_2003_Geographically weighted regression.pdf},
  journal = {Geographical Analysis},
  number = {3}
}

@incollection{Paciorek2004Nonstationary,
  title = {Nonstationary {{Covariance Functions}} for {{Gaussian Process Regression}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 16},
  author = {Paciorek, Christopher J. and Schervish, Mark J.},
  editor = {Thrun, S. and Saul, L. K. and Sch{\"o}lkopf, B.},
  year = {2004},
  pages = {273--280},
  publisher = {{MIT Press}},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Paciorek_Schervish_2004_Nonstationary Covariance Functions for Gaussian Process Regression.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\RRVXC85H\\2350-nonstationary-covariance-functions-for-gaussian-process-regression.html}
}

@article{Piepho2008Nearest,
  title = {Nearest Neighbour Adjustment and Linear Variance Models in Plant Breeding Trials},
  booktitle = {Biometrical Journal},
  author = {Piepho, Hans-Peter and Richter, Christel and Williams, Emlyn},
  year = {2008},
  volume = {50},
  pages = {164--189},
  issn = {03233847},
  doi = {10.1002/bimj.200710414},
  abstract = {This paper reviews methods for nearest neighbour analysis that adjust for local trend in one dimension. Such methods are commonly used in plant breeding and variety testing. The focus is on simple differencing methods, including first differences and the Papadakis method. We discuss mixed model representations of these methods on the scale of the observed data. Modelling observed data has a number of practical advantages compared to differencing, for example the facility to conveniently compute adjusted cultivar means. Most models considered involve a linear variance-covariance structure and can be represented as state-space models. The reviewed methods and models are exemplified using three datasets. \textcopyright 2008 Wiley-VCH Verlag GmbH \& Co. KGaA.},
  annotation = {ZSCC: 0000060},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Piepho et al_2008_Nearest neighbour adjustment and linear variance models in plant breeding trials.pdf},
  journal = {Biometrical Journal},
  keywords = {Field trials,Geostatistics,Linear variance,Mixed model,Spatial model,Statespace model},
  number = {2}
}

@article{Piepho2011Onestimation,
  title = {On Estimation of Genotypic Correlations and Their Standard Errors by Multivariate {{REML}} Using the {{MIXED}} Procedure of the {{SAS System}}},
  author = {Piepho, Hans-Peter and M{\"o}hring, Jens},
  year = {2011},
  volume = {51},
  pages = {2449--2454},
  issn = {0011183X},
  doi = {10.2135/cropsci2011.02.0088},
  abstract = {This paper explains a simple strategy to develop code for multivariate (multitrait) mixed-model analysis using the MIXED procedure of the SAS System, when the corresponding univariate model has a simple variance components form. Such models are needed for estimating genotypic and phenotypic correlation among traits in plant breeding experiments, and they provide best linear unbiased predictions (BLUP) of genetic effects which may be more accurate than univariate BLUP. We give some hints how to speed up computations, and it is shown how to obtain asymptotic standard errors of correlation estimates with little effort. \textcopyright{} Crop Science Society of America.},
  annotation = {ZSCC: 0000024},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Piepho_Möhring_2011_On estimation of genotypic correlations and their standard errors by.pdf},
  journal = {Crop Science},
  number = {6}
}

@article{Piepho2011Statistical,
  title = {Statistical Aspects of On-Farm Experimentation},
  author = {Piepho, Hans-Peter and Richter, Christel and Spilke, Joachim and Hartung, Karin and Kunick, Arndt},
  year = {2011},
  volume = {62},
  pages = {721--735},
  doi = {10.1071/cp11175},
  annotation = {ZSCC: 0000035},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Piepho et al_2011_Statistical aspects of on-farm experimentation.pdf},
  journal = {Crop \& Pasture Science}
}

@article{Piepho2015Problems,
  title = {Problems in Parameter Estimation for Power and {{AR}}(1) Models of Spatial Correlation in Designed Field Experiments},
  author = {Piepho, Hans-Peter and M{\"o}hring, Jens and Pflugfelder, Markus and Hermann, Winfried and Williams, Emlyn R},
  year = {2015},
  volume = {10},
  pages = {3--16},
  annotation = {ZSCC: 0000017},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\AF7KZC4S\\Piepho et al. - Problems in parameter estimation for power and AR(.pdf},
  journal = {Communications in Biometry \& Crop Science},
  keywords = {⛔ No DOI found},
  language = {en},
  number = {1}
}

@article{Piepho2018Tutorial,
  ids = {Piepho2018a,Piepho2018b},
  title = {A Tutorial on the Statistical Analysis of Factorial Experiments with Qualitative and Quantitative Treatment Factor Levels},
  author = {Piepho, H. P. and Edmondson, R. N.},
  year = {2018},
  volume = {204},
  pages = {429--455},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/jac.12267},
  annotation = {ZSCC: 0000021},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\A tutorial on the statistical analysis of factorial experiments with qualitative and quantitative treatment factor levels.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CX4T9LAT\\jac.html},
  journal = {Journal of Agronomy and Crop Science},
  keywords = {factorial analysis,linear mixed models,polynomial regression,R,repeated-measures analysis,response surface models,SAS,split-plot analysis},
  number = {5}
}

@article{Rakshit2020Novel,
  ids = {Rakshit2020Novela},
  title = {Novel Approach to the Analysis of Spatially-Varying Treatment Effects in on-Farm Experiments},
  author = {Rakshit, Suman and Baddeley, Adrian and Stefanova, Katia and Reeves, Karyn and Chen, Kefei and Cao, Zhanglong and Evans, Fiona and Gibberd, Mark},
  year = {2020},
  volume = {255},
  pages = {107783},
  publisher = {{Elsevier}},
  issn = {0378-4290},
  doi = {10/gg2vv7},
  abstract = {{$<$}p{$>$}With increasing interest in on-farm experiments, there is a pressing need to develop rigorous statistical methods for analysing these experiments. The adoption of advanced technologies such as yield monitors and variable-rate fertilizer applicators has enabled farmers and researchers to collect biophysical data linked to spatial information at a scale which allows them to investigate the role of spatial variability in the development of optimum management practices. A relevant topic for investigation could be: "what are the optimum rates of nitrogen and how/why do these differ across the field"? Although it has been recently understood that traditional statistical methods that are appropriate for analysing small-plot experiments are inappropriate for answering these questions, a unifying approach to inference for on-farm experiments is still missing and this limits the adoption of the technique. In this paper we propose a unifying approach to the analysis of on-farm strip experiments adapting the core ideas of local likelihood or geographically weighted regression. We propose a statistical model that allows spatial nonstationarity in modelled relationships and estimates spatially-varying parameters governing these relationships. A crucial step is bandwidth selection in implementing these models, and we develop bandwidth selection methods for two important scenarios relevant to the modelling of yield monitor data in on-farm experiments. Local {$<$}em{$>$}t{$<$}/em{$>$}-scores have been introduced for inferential purposes and the associated problem of multiple testing has been described in the context of analysing on-farm experiments. We demonstrate in this paper how local {$<$}em{$>$}p{$<$}/em{$>$}-values can be adjusted to overcome this problem. To illustrate the applicability of our proposed method, we analysed two publicly available datasets. Graphical displays are created to guide practitioners to make informed decisions on optimal management practices.{$<$}/p{$>$}},
  annotation = {ZSCC: NoCitationData[s2]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Rakshit et al_2020_Novel approach to the analysis of spatially-varying treatment effects in on-farm experiments.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\6USWQ45W\\S0378429019317368.html},
  journal = {Field Crops Research},
  keywords = {Bandwidth selection,Contour maps,Geographically weighted regression,Local likelihood,Precision agriculture,Spatial nonstationarity},
  number = {October 2019}
}

@book{Rasmussen2006Gaussian,
  ids = {rasmussen2006gaussian,rasmussenGaussianProcessesMachine2006a},
  title = {Gaussian {{Processes}} for {{Machine Learning}}},
  author = {Rasmussen, C. E. and Williams, C. K. I.},
  year = {2006},
  publisher = {{The MIT Press}},
  annotation = {ZSCC: 0000909}
}

@article{Ritter2008AnOnfarm,
  title = {An On-Farm Approach to Quantify Yield Variation and to Derive Decision Rules for Site-Specific Weed Management},
  author = {Ritter, C. and Dicke, D. and Weis, M. and Oebel, H. and Piepho, H. P. and B{\"u}chse, A. and Gerhards, R.},
  year = {2008},
  issn = {13852256},
  doi = {10.1007/s11119-008-9061-5},
  abstract = {Grain yield often varies within agricultural fields as a result of the variation in soil characteristics, competition from weeds, management practices and their causal interactions. To implement appropriate management decisions, yield variability needs to be explained and quantified. A new experimental design was established and tested in a field experiment to detect yield variation in relation to the variation in soil quality, the heterogeneity of weed distribution and weed control within a field. Weed seedling distribution and density, apparent soil electrical conductivity (ECa) and grain yield were recorded and mapped in a 3.5 ha winter wheat field during 2005 and 2006. A linear mixed model with an anisotropic spatial correlation structure was used to estimate the effect of soil characteristics, weed competition and herbicide treatment on crop yield. The results showed that all properties had a strong effect on grain yield. By adding herbicide costs and current grain price into the model, thresholds of weed density were derived for site-specific weed control. This experimental approach enables the variation of yield within agricultural fields to be explained, and an understanding of the effects on yield of the factors that affect it and their causal interactions to be gained. The approach can be applied to improve decision algorithms for the patch spraying of weeds. \textcopyright{} 2008 Springer Science+Business Media, LLC.},
  annotation = {ZSCC: 0000048},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Ritter et al_2008_An on-farm approach to quantify yield variation and to derive decision rules.pdf},
  journal = {Precision Agriculture},
  keywords = {Geostatistics,Herbicide injury,Soil variation,Weed control thresholds,Weed distribution}
}

@article{Roy2020Convergence,
  title = {Convergence {{Diagnostics}} for {{Markov Chain Monte Carlo}}},
  author = {Roy, Vivekananda},
  year = {2020},
  volume = {7},
  pages = {387--412},
  doi = {10.1146/annurev-statistics-031219-041300},
  abstract = {Markov chain Monte Carlo (MCMC) is one of the most useful approaches to scientific computing because of its flexible construction, ease of use, and generality. Indeed, MCMC is indispensable for performing Bayesian analysis. Two critical questions that MCMC practitioners need to address are where to start and when to stop the simulation. Although a great amount of research has gone into establishing convergence criteria and stopping rules with sound theoretical foundation, in practice, MCMC users often decide convergence by applying empirical diagnostic tools. This review article discusses the most widely used MCMC convergence diagnostic tools. Some recently proposed stopping rules with firm theoretical footing are also presented. The convergence diagnostics and stopping rules are illustrated using three detailed examples.},
  annotation = {ZSCC: 0000004  \_eprint: https://doi.org/10.1146/annurev-statistics-031219-041300},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Roy_2020_Convergence Diagnostics for Markov Chain Monte Carlo.pdf},
  journal = {Annual Review of Statistics and Its Application},
  number = {1}
}

@article{rushing2019Modeling,
  title = {Modeling Spatially and Temporally Complex Range Dynamics When Detection Is Imperfect},
  author = {Rushing, Clark S. and Royle, J. Andrew and Ziolkowski, David J. and Pardieck, Keith L.},
  year = {2019},
  month = sep,
  volume = {9},
  pages = {12805},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-48851-5},
  abstract = {Species distributions are determined by the interaction of multiple biotic and abiotic factors, which produces complex spatial and temporal patterns of occurrence. As habitats and climate change due to anthropogenic activities, there is a need to develop species distribution models that can quantify these complex range dynamics. In this paper, we develop a dynamic occupancy model that uses a spatial generalized additive model to estimate non-linear spatial variation in occupancy not accounted for by environmental covariates. The model is flexible and can accommodate data from a range of sampling designs that provide information about both occupancy and detection probability. Output from the model can be used to create distribution maps and to estimate indices of temporal range dynamics. We demonstrate the utility of this approach by modeling long-term range dynamics of 10 eastern North American birds using data from the North American Breeding Bird Survey. We anticipate this framework will be particularly useful for modeling species' distributions over large spatial scales and for quantifying range dynamics over long temporal scales.},
  annotation = {ZSCC: 0000003},
  copyright = {2019 The Author(s)},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Rushing et al_2019_Modeling spatially and temporally complex range dynamics when detection is.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\NAR7H5PD\\s41598-019-48851-5.html},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{Schmidt2018More,
  ids = {Schmidt2018,Schmidt2018a},
  title = {More, Larger, Simpler: {{How}} Comparable Are on-Farm and on-Station Trials for Cultivar Evaluation?},
  author = {Schmidt, P. and M{\"o}hring, J. and Koch, R. J. and Piepho, H. P.},
  year = {2018},
  volume = {58},
  pages = {1508--1518},
  publisher = {{Routledge}},
  issn = {14350653},
  doi = {10.2135/cropsci2017.09.0555},
  abstract = {Traditionally, cultivar evaluation trials have been conducted as replicated small-plot, on-station trials at multiple locations and years. To this day, this is the method of choice for cultivar registration trials conducted by official federal institutes. Given a different purpose (e.g., marketing), cultivar evaluation may also be done as on-farm trials with single replicates and fewer plots laid out as large strips. Such trials are often conducted at a larger number of locations. It is not clear how comparable these two trial systems are. Our objective therefore was to compare the precision and accuracy of these two systems using yield data from both on-farm trials and from official on-station trials for winter oilseed rape (Brassica napus L.) across 8 yr. We set up multivariate mixed models to analyze the combined dataset of both trial systems and estimate heterogeneous variance components. Furthermore, based on 23 hybrid genotypes common to both datasets, we investigated the genetic correlation between systems and tested for genotype \texttimes{} system interaction effects. The results suggest that on-farm trials are comparable with on-station trials in terms of precision of a single plot, but that there are genotype \texttimes{} system interaction effects prohibiting the comparison of yield estimates for genotypes between systems. One potential explanation for this difference was identified as the system-specific group effect of semidwarf vs. long-strawed genotypes. \textcopyright{} Crop Science Society of America | 5585 Guilford Rd., Madison, WI 53711 USA All rights reserved.},
  annotation = {ZSCC: 0000006},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Schmidt et al_2018_More, larger, simpler.pdf},
  journal = {Crop Science},
  keywords = {2-level modeling,Bayesian confirmatory factor analysis,Bayesian estimation,Bayesian statistics,Challenges,estimation method,Iran,maximum likelihood,multilevel modeling,noninformative priors,Precision agriculture (PA),restricted maximum likelihood,single-case designs,single-case research,Sustainable agriculture,weakly informative prior},
  number = {4}
}

@article{Selle2019Flexible,
  title = {Flexible Modelling of Spatial Variation in Agricultural Field Trials with the {{R}} Package {{INLA}}},
  author = {Selle, Maria Lie and Steinsland, Ingelin and Hickey, John M. and Gorjanc, Gregor},
  year = {2019},
  volume = {132},
  pages = {3277--3293},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {14322242},
  doi = {10.1007/s00122-019-03424-y},
  abstract = {Key message: Established spatial models improve the analysis of agricultural field trials with or without genomic data and can be fitted with the open-source R package INLA. Abstract: The objective of this paper was to fit different established spatial models for analysing agricultural field trials using the open-source R package INLA. Spatial variation is common in field trials, and accounting for it increases the accuracy of estimated genetic effects. However, this is still hindered by the lack of available software implementations. We compare some established spatial models and show possibilities for flexible modelling with respect to field trial design and joint modelling over multiple years and locations. We use a Bayesian framework and for statistical inference the integrated nested Laplace approximations (INLA) implemented in the R package INLA. The spatial models we use are the well-known independent row and column effects, separable first-order autoregressive (AR 1 {$\otimes$} AR 1) models and a Gaussian random field (Mat\'ern) model that is approximated via the stochastic partial differential equation approach. The Mat\'ern model can accommodate flexible field trial designs and yields interpretable parameters. We test the models in a simulation study imitating a wheat breeding programme with different levels of spatial variation, with and without genome-wide markers and with combining data over two locations, modelling spatial and genetic effects jointly. The results show comparable predictive performance for both the AR 1 {$\otimes$} AR 1 and the Mat\'ern models. We also present an example of fitting the models to a real wheat breeding data and simulated tree breeding data with the Nelder wheel design to show the flexibility of the Mat\'ern model and the R package INLA.},
  annotation = {ZSCC: 0000005},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Flexible modelling of spatial variation in agricultural feld trials with the R package INLA.pdf},
  isbn = {0012201903424},
  journal = {Theoretical and Applied Genetics},
  number = {12}
}

@article{Smid2020Bayesian,
  title = {Bayesian {{Versus Frequentist Estimation}} for {{Structural Equation Models}} in {{Small Sample Contexts}}: {{A Systematic Review}}},
  shorttitle = {Bayesian {{Versus Frequentist Estimation}} for {{Structural Equation Models}} in {{Small Sample Contexts}}},
  author = {Smid, Sanne C. and McNeish, Daniel and Mio{\v c}evi{\'c}, Milica and van de Schoot, Rens},
  year = {2020},
  month = jan,
  volume = {27},
  pages = {131--161},
  publisher = {{Routledge}},
  issn = {1070-5511},
  doi = {10.1080/10705511.2019.1577140},
  abstract = {In small sample contexts, Bayesian estimation is often suggested as a viable alternative to frequentist estimation, such as maximum likelihood estimation. Our systematic literature review is the first study aggregating information from numerous simulation studies to present an overview of the performance of Bayesian and frequentist estimation for structural equation models with small sample sizes. We conclude that with small samples, the use of Bayesian estimation with diffuse default priors can result in severely biased estimates \textendash{} the levels of bias are often even higher than when frequentist methods are used. This bias can only be decreased by incorporating prior information. We therefore recommend against naively using Bayesian estimation when samples are small, and encourage researchers to make well-considered decisions about all priors. For this purpose, we provide recommendations on how to construct thoughtful priors.},
  annotation = {\_eprint: https://doi.org/10.1080/10705511.2019.1577140},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Smid et al_2020_Bayesian Versus Frequentist Estimation for Structural Equation Models in Small.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CXU685IH\\10705511.2019.html},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  keywords = {informative priors,Small samples,structural equation models,systematic review},
  number = {1}
}

@book{Sorensen2007Likelihood,
  ids = {sorensen2007likelihood},
  title = {Likelihood, {{Bayesian}}, and {{MCMC}} Methods in Quantitative Genetics},
  author = {Sorensen, Daniel and Gianola, Daniel},
  year = {2007},
  publisher = {{Springer Science \& Business Media}},
  annotation = {ZSCC: 0001048},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\7SJPNXTD\\books.html}
}

@article{Sorensen2016Bayesian,
  ids = {Sorensen2016},
  title = {Bayesian Linear Mixed Models Using {{Stan}}: {{A}} Tutorial for Psychologists, Linguists, and Cognitive Scientists},
  author = {Sorensen, Tanner and Hohenstein, Sven and Vasishth, Shravan},
  year = {2016},
  volume = {12},
  pages = {175--200},
  issn = {2292-1354},
  doi = {10.20982/tqmp.12.3.p175},
  abstract = {With the arrival of the R packages nlme and lme4, linear mixed models (LMMs) have come to be widely used in experimentally-driven areas like psychology, linguistics, and cognitive science. This tutorial provides a practical introduction to fitting LMMs in a Bayesian framework using the probabilistic programming language Stan. We choose Stan (rather than WinBUGS or JAGS) because it provides an elegant and scalable framework for fitting models in most of the standard applications of LMMs. We ease the reader into fitting increasingly complex LMMs, first using a two-condition repeated measures self-paced reading study, followed by a more complex \$22\$ repeated measures factorial design that can be generalized to much more complex designs.},
  annotation = {ZSCC: NoCitationData[s1]},
  archivePrefix = {arXiv},
  arxivid = {1506.06201},
  eprint = {1506.06201},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Sorensen et al_2016_Bayesian linear mixed models using Stan.pdf},
  journal = {The Quantitative Methods for Psychology},
  keywords = {bayesian data analysis,bayesian linear mixed models,jags,linear mixed models,stan,tools},
  number = {3}
}

@book{Stan2019Stan,
  title = {Stan {{Modeling Language}}: {{User}}'s {{Guide}} and {{Reference Manual}}},
  author = {Stan, Development Team},
  year = {2019},
  edition = {2.23},
  abstract = {Stan reference manual specifying the syntax and semantics of the Stan programming language.},
  annotation = {ZSCC: 0000028},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\3AVDPGG5\\reference-manual.html}
}

@article{sun2015Thin,
  title = {Thin Plate Spline Regression Model Used at Early Stages of Soybean Breeding to Control Field Spatial Variation},
  author = {Sun, M. and Goggi, S. A. and Matson, K. and Palmer, R. G. and Moore, K. and Cianzio, S. R.},
  year = {2015},
  volume = {29},
  pages = {333--352},
  publisher = {{Taylor \& Francis}},
  issn = {15427536},
  doi = {10.1080/15427528.2015.1026623},
  abstract = {Yield variation observed in soybean (Glycine max) progeny-row yield trial (PRYT) is the final result of line genotypic merit, field spatial pattern, and experimental error. The spatial variation in field tests could confound the estimates of genetic merits. The objectives of this research were to: i) quantify non-genetic yield variation in a soybean breeding PRYT, and ii) determine efficiency of the thin plate spline regression (TPSR) model in adjusting yield because of variation caused by field spatial pattern. The third objective was to evaluate if the use of TPSR model could improve the selection accuracy of PRYT un-replicated yield tests. Uniformity study, early generation test, and confirmation study were conducted. Our results indicated that large spatial variations in soybean PRYT field could be present as evaluated by the Uniformity Study conducted with two commercial lines. In this experiment, the use of the TPSR proved to be effective in reducing the error variance and the coefficient of variability, with an improvement in relative efficiency (IRE) of 37.9\%. In early generation tests, 2565 lines were evaluated within test-sets along with three checks. The TPSR model also was effective in the early-generation tests; the IRE was 40.4\%. The correlation coefficients calculated between yield estimates obtained in two-year early generation tests and confirmation study improved by 0.21 points compared with results from non-TPSR experiments. The results indicated that use of TPSR model was effective in accounting for some of the spatial variation in field tests.},
  annotation = {ZSCC: 0000003},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Sun et al_2015_Thin plate spline regression model used at early stages of soybean breeding to.pdf},
  journal = {Journal of Crop Improvement},
  keywords = {best linear unbiased prediction,genetic gain,Progeny-row yield trial,soybean breeding,two-dimensional thin plate spline regression},
  number = {3}
}

@article{Sundararajan2001Predictive,
  title = {Predictive {{Approaches}} for {{Choosing Hyperparameters}} in {{Gaussian Processes}}},
  author = {Sundararajan, S. and Keerthi, S. S.},
  year = {2001},
  month = may,
  volume = {13},
  pages = {1103--1118},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/08997660151134343},
  abstract = {Gaussian Processes are powerful regression models specified by parametrized mean and covariance functions. Standard approaches to estimate these parameters (known by the name Hyperparameters) are Maximum Likelihood (ML) and Maximum APosterior (MAP) approaches. In this paper, we propose and investigate predictive approaches, namely, maximization of Geisser's Surrogate Predictive Probability (GPP) and minimization of mean square error with respect to GPP (referred to as Geisser's Predictive mean square Error (GPE)) to estimate the hyperparameters. We also derive results for the standard Cross-Validation (CV) error and make a comparison. These approaches are tested on a number of problems and experimental results show that these approaches are strongly competitive to existing approaches.},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\F7GVDJXT\\Sundararajan and Keerthi - 2001 - Predictive Approaches for Choosing Hyperparameters.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {5}
}

@article{Theobald2002Bayesian,
  title = {A Bayesian Approach to Regional and Local-Area Prediction from Crop Variety Trials},
  author = {Theobald, Chris M. and Talbot, Mike and Nabugoomu, Fabian},
  year = {2002},
  month = sep,
  volume = {7},
  pages = {403--419},
  issn = {1085-7117, 1537-2693},
  doi = {10.1198/108571102230},
  annotation = {ZSCC: 0000037},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesTechnique\\A bayesian approach to regional and local-area prediction from crop variety trials.pdf},
  journal = {JABES},
  language = {en},
  number = {3}
}

@article{Tobler1970AComputer,
  title = {A Computer Movie Simulating Urban Growth in the Detroit Region},
  author = {Tobler, W R},
  year = {1970},
  volume = {46},
  pages = {234},
  issn = {00130095},
  doi = {10.2307/143141},
  abstract = {Work units, called danwei, are one of the principal territorial forms used to organize China's urban population. These enclosed spaces are the socio-spatial units in which the livelihood and domestic and social activities of its members are carried out. The danwei are described by considering: (1) the origins of the concept, (2) phenomenological meanings in contemporary society, (3) socio- economic-political characteristics, and (4) their spatial implications in the trans- formation of Chinese society. How},
  annotation = {ZSCC: 0008085},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Tobler_1970_A computer movie simulating urban growth in the detroit region.pdf},
  journal = {Econ. Geogr.}
}

@article{Troyer2009Heterosis,
  title = {Heterosis Decreasing in Hybrids: {{Yield}} Test Inbreds},
  author = {Troyer, A. Forrest and Wellin, Eric J.},
  year = {2009},
  volume = {49},
  pages = {1969--1976},
  issn = {0011183X},
  doi = {10.2135/cropsci2009.04.0170},
  abstract = {Yield testing fi nished inbreds to replace preliminary single-cross corn (Zea mays L.) yield tests will increase rate of commercial hybrid yield gains. Studies have shown that heterosis decreased 25\%/50 yr, 10\%/60 yr, and 35\%/100 yr. Natural selection and artifi cial selection by plant breeders for adaptedness have increased parental inbred and hybrid seed yields, whereas percentage heterosis decreased. Four studies have shown inbred yields increased 1.9 to 3.5 times faster than heterosis yields. Pioneer HiBred generates 700 new inbreds tested in 6000 single-cross hybrids at 15 to 20 locations annually. Predicted, untested, newer hybrids are then made and tested extensively with commercial hybrids. Parental inbred yield testing is the next to last of several steps in hybrid development. Commercial hybrid development costs have increased logarithmically, whereas performance has increased linearly. Replacing preliminary testcross trials with fi nished-inbred yield trials is more effi cient. About 12,000 new fi nished inbreds can be evaluated annually with no testers and at least 50\% fewer locations per inbred with the same testing effort as 700 new inbreds with testers. A calendar year per breeding cycle and annual production costs for 6000 hybrids will be saved. Corn yield trials detect stress susceptibility, which is more apparent in inbreds than in hybrids. Evaluation of more new inbreds will be conducive to increased genetic diversity that produces higher-yielding hybrids. \textcopyright{} Crop Science Society of America.},
  annotation = {ZSCC: 0000083},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Troyer_Wellin_2009_Heterosis decreasing in hybrids.pdf},
  journal = {Crop Science},
  number = {6}
}

@article{Vasconcelos2020New,
  title = {A New Regression Model for Bimodal Data and Applications in Agriculture},
  author = {Vasconcelos, Julio Cezar Souza and Cordeiro, Gauss Moutinho and Ortega, Edwin Moises Marcos and de Rezende, {\'E}dila Maria},
  year = {2020},
  month = feb,
  volume = {0},
  pages = {1--24},
  publisher = {{Taylor \& Francis}},
  issn = {0266-4763},
  doi = {10.1080/02664763.2020.1723503},
  abstract = {We define the odd log-logistic exponential Gaussian regression with two systematic components, which extends the heteroscedastic Gaussian regression and it is suitable for bimodal data quite common in the agriculture area. We estimate the parameters by the method of maximum likelihood. Some simulations indicate that the maximum-likelihood estimators are accurate. The model assumptions are checked through case deletion and quantile residuals. The usefulness of the new regression model is illustrated by means of three real data sets in different areas of agriculture, where the data present bimodality.},
  annotation = {ZSCC: 0000001  \_eprint: https://doi.org/10.1080/02664763.2020.1723503},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MixtureGaussian\\Vasconcelos et al_2020_A new regression model for bimodal data and applications in agriculture.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\W43C9B6D\\02664763.2020.html},
  journal = {Journal of Applied Statistics},
  keywords = {Agriculture data,bimodal data,exponential Gaussian distribution,regression model,simulation study},
  number = {0}
}

@article{Vehtari2017Practical,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  volume = {27},
  pages = {1413--1432},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  annotation = {ZSCC: 0001232},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf},
  journal = {Stat Comput},
  language = {en},
  number = {5}
}

@article{Verbyla1999Analysis,
  title = {The Analysis of Designed Experiments and Longitudinal Data by Using Smoothing Splines},
  author = {Verbyla, Ar{\textbackslash}barunas P and Cullis, Brian R and Kenward, Michael G and Welham, Sue J},
  year = {1999},
  volume = {48},
  pages = {269--311},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/1467-9876.00154},
  annotation = {ZSCC: 0000688},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Verbyla et al_1999_The analysis of designed experiments and longitudinal data by using smoothing.pdf},
  journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  number = {3}
}

@article{Vilasa2017Global,
  title = {Global Soil Moisture Bimodality in Satellite Observations and Climate Models},
  author = {Vilasa, L. and Miralles, D. G. and de Jeu, R. A. M. and Dolman, A. J.},
  year = {2017},
  volume = {122},
  pages = {4299--4311},
  issn = {2169-8996},
  doi = {10.1002/2016JD026099},
  abstract = {A new diagnostic metric based on soil moisture bimodality is developed in order to examine and compare soil moisture from satellite observations and Earth System Models. The methodology to derive this diagnostic is based on maximum likelihood estimator encoded into an iterative algorithm, which is applied to the soil moisture probability density function. This metric is applied to satellite data from the Advanced Microwave Scanning Radiometer for the Earth Observing System and global climate models data from the Coupled Model Intercomparison Project Phase 5 (CMIP5). Results show high soil moisture bimodality in transitional climate areas and high latitudes, potentially associated with land-atmosphere feedback processes. When comparing satellite versus climate models, a clear difference in their soil moisture bimodality is observed, with systematically higher values in the case of CMIP5 models. These differences appear related to areas where land-atmospheric feedback may be overestimated in current climate models.},
  annotation = {ZSCC: 0000007  \_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2016JD026099},
  copyright = {\textcopyright 2017. The Authors.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MixtureGaussian\\Vilasa et al_2017_Global soil moisture bimodality in satellite observations and climate models.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\3F873TE4\\2016JD026099.html},
  journal = {Journal of Geophysical Research: Atmospheres},
  keywords = {bimodality,climate models,CMIP5,land-atmosphere interactions,satellite soil moisture,soil moisture},
  language = {en},
  number = {8}
}

@article{Vollert2019,
  title = {Robust Additive {{Gaussian}} Process Models Using Reference Priors and Cut-off-Designs},
  author = {Vollert, Natalie and Ortner, Michael and Pilz, J{\"u}rgen},
  year = {2019},
  volume = {65},
  pages = {586--596},
  publisher = {{Elsevier Inc.}},
  issn = {0307904X},
  doi = {10.1016/j.apm.2018.07.050},
  abstract = {When powerful numerical tools like the finite element method encounter their limits for the evaluation of physical systems it is very common to use surrogate models as an approximation. There are many possible choices concerning the model approach, among which Gaussian process models are the most popular ones due to their clear statistical basis. A very desirable attribute of such surrogates is a high flexibility for making them applicable to a great class of underlying problems while obtaining interpretable results. To achieve this Gaussian processes are used as basis functions of an additive model in this work. Another important property of a surrogate is stability, which can be especially challenging when it comes to the estimation of the correlation parameters. To solve this we use a Bayesian approach where a reference prior is assigned to each component of the additive model assuring robust correlation matrices. Due to the additive structure of the model a simplified parameter estimation process is proposed that reduces the usually high-dimensional optimization problem to a few sub-routines of low dimension. Finally, we demonstrate this concept by modeling the magnetic field of a magnetic linear position detection system.},
  journal = {Appl. Math. Model.},
  keywords = {Additive models,Computer experiments,Gaussian process models,Reference prior,Robust estimation}
}

@article{Waldmann2006Comparison,
  title = {Comparison of {{REML}} and {{Gibbs}} Sampling Estimates of Multi-Trait Genetic Parameters in {{Scots}} Pine},
  author = {Waldmann, Patrik and Ericsson, Tore},
  year = {2006},
  volume = {112},
  pages = {1441--1451},
  issn = {00405752},
  doi = {10.1007/s00122-006-0246-x},
  abstract = {Multi-trait (co)variance estimation is an important topic in plant and animal breeding. In this study we compare estimates obtained with restricted maximum likelihood (REML) and Bayesian Gibbs sampling of simulated data and of three traits (diameter, height and branch angle) from a 26-year-old partial diallel progeny test of Scots pine (Pinus sylvestris L.). Based on the results from the simulated data we can conclude that the REML estimates are accurate but the mode of posterior distributions from the Gibbs sampling can be overestimated depending on the level of the heritability. The mean and median of the posteriors were considerably higher than the expected values of the heritabilities. The confidence intervals calculated with the delta method were biased downwardly. The highest probability density (HPD) interval provides a better interval estimate, but could be slightly biased at the lower level. Similar differences between REML and Gibbs sampling estimates were found for the Scots pine data. We conclude that further simulation studies are needed in order to evaluate the effect of different priors on (co)variance components in the genetic individual model. \textcopyright{} Springer-Verlag 2006.},
  annotation = {ZSCC: 0000042},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\HTC3JWWM\\Comparison of REML and Gibbs sampling estimates of multi-trait genetic parameters in Scots pine.pdf},
  journal = {Theor. Appl. Genet.},
  number = {8}
}

@article{Wall2004Acloselook,
  title = {A Close Look at the Spatial Structure Implied by the {{CAR}} and {{SAR}} Models},
  author = {Wall, Melanie M.},
  year = {2004},
  volume = {121},
  pages = {311--324},
  issn = {03783758},
  doi = {10.1016/s0378-3758(03)00111-3},
  abstract = {Modeling spatial interactions that arise in spatially referenced data is commonly done by incorporating the spatial dependence into the covariance structure either explicitly or implicitly via an autoregressive model. In the case of lattice (regional summary) data, two common autoregressive models used are the conditional autoregressive model (CAR) and the simultaneously autoregressive model (SAR). Both of these models produce spatial dependence in the covariance structure as a function of a neighbor matrix W and often a fixed unknown spatial correlation parameter. This paper examines in detail the correlation structures implied by these models as applied to an irregular lattice in an attempt to demonstrate their many counterintuitive or impractical results. A data example is used for illustration where US statewide average SAT verbal scores are modeled and examined for spatial structure using different spatial models. \textcopyright{} 2003 Elsevier B.V. All rights reserved.},
  annotation = {ZSCC: 0000399},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\A close look at the spatial structure implied by the CAR and SAR models.pdf},
  journal = {Journal of Statistical Planning and Inference},
  keywords = {Lattice data,Spatial autoregression,Spatial interaction},
  number = {2}
}

@article{weiss2016Pediatric,
  title = {Pediatric {{Pain}}, {{Predictive Inference}}, and {{Sensitivity Analysis}}:},
  shorttitle = {Pediatric {{Pain}}, {{Predictive Inference}}, and {{Sensitivity Analysis}}},
  author = {Weiss, Robert},
  year = {2016},
  month = jul,
  publisher = {{Sage PublicationsSage CA: Thousand Oaks, CA}},
  doi = {10.1177/0193841x9401800601},
  abstract = {The understanding, prevention, and treatment of pain is of great importance to medical science. Children were asked to immerse their hands in cold water until t...},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Weiss_2016_Pediatric Pain, Predictive Inference, and Sensitivity Analysis.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\XD737NHW\\0193841X9401800601.html},
  journal = {Evaluation Review},
  language = {en}
}

@article{Wood2003Thin,
  title = {Thin Plate Regression Splines},
  author = {Wood, Simon N.},
  year = {2003},
  month = feb,
  volume = {65},
  pages = {95--114},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/1467-9868.00374},
  abstract = {I discuss the production of low rank smoothers for d {$>$} 1 dimensional data, which can be fitted by regression or penalized regression methods. The smoothers are constructed by a simple transformation and truncation of the basis that arises from the solution of the thin plate spline smoothing problem and are optimal in the sense that the truncation is designed to result in the minimum possible perturbation of the thin plate spline smoothing problem given the dimension of the basis used to construct the smoother. By making use of Lanczos iteration the basis change and truncation are computationally efficient. The smoothers allow the use of approximate thin plate spline models with large data sets, avoid the problems that are associated with 'knot placement' that usually complicate modelling with regression splines or penalized regression splines, provide a sensible way of modelling interaction terms in generalized additive models, provide low rank approximations to generalized smoothing spline models, appropriate for use with large data sets, provide a means for incorporating smooth functions of more than one variable into non-linear models and improve the computational efficiency of penalized likelihood models incorporating thin plate splines. Given that the approach produces spline-like models with a sparse basis, it also provides a natural way of incorporating unpenalized spline-like terms in linear and generalized linear models, and these can be treated just like any other model terms from the point of view of model selection, inference and diagnostics.},
  annotation = {ZSCC: 0001493},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\SX8CCDDT\\Wood - 2003 - Thin plate regression splines.pdf},
  journal = {J Royal Statistical Soc B},
  language = {en},
  number = {1}
}

@article{Wood2011Fast,
  ids = {Wood2011,wood2011fast},
  title = {Fast Stable Restricted Maximum Likelihood and Marginal Likelihood Estimation of Semiparametric Generalized Linear Models},
  author = {Wood, Simon N},
  year = {2011},
  volume = {73},
  pages = {3--36},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/j.1467-9868.2010.00749.x},
  annotation = {ZSCC: 0003212},
  file = {/Users/jeromecao/Library/Application Support/Mendeley Desktop/Downloaded/Wood - 2011 - Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models.pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {adaptive smoothing,computation,gam,gamm,gcv,marginal likelihood,model selection,penalized glm,penalized regression splines,reml,scalar on function regression,stable},
  number = {1}
}

@article{Wu2016Comparison,
  title = {A Comparison of Spatial Interpolation Methods for Soil Temperature over a Complex Topographical Region},
  author = {Wu, Wei and Tang, Xiao-Ping and Ma, Xue-Qing and Liu, Hong-Bin},
  year = {2016},
  month = aug,
  volume = {125},
  pages = {657--667},
  issn = {1434-4483},
  doi = {10.1007/s00704-015-1531-x},
  abstract = {Soil temperature variability data provide valuable information on understanding land-surface ecosystem processes and climate change. This study developed and analyzed a spatial dataset of monthly mean soil temperature at a depth of 10~cm over a complex topographical region in southwestern China. The records were measured at 83 stations during the period of 1961\textendash 2000. Nine approaches were compared for interpolating soil temperature. The accuracy indicators were root mean square error (RMSE), modelling efficiency (ME), and coefficient of residual mass (CRM). The results indicated that thin plate spline with latitude, longitude, and elevation gave the best performance with RMSE varying between 0.425 and 0.592~\textdegree C, ME between 0.895 and 0.947, and CRM between -0.007 and 0.001. A spatial database was developed based on the best model. The dataset showed that larger seasonal changes of soil temperature were from autumn to winter over the region. The northern and eastern areas with hilly and low-middle mountains experienced larger seasonal changes.},
  annotation = {ZSCC: 0000006},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Wu et al_2016_A comparison of spatial interpolation methods for soil temperature over a.pdf},
  journal = {Theor Appl Climatol},
  language = {en},
  number = {3}
}

@article{Xu2010Hypothesis,
  ids = {Xu2010Hypothesisa},
  title = {Hypothesis {{Tests}} on {{Mixture Model Components}} with {{Applications}} in {{Ecology}} and {{Agriculture}}},
  author = {Xu, Ling and Hanson, Timothy and Bedrick, Edward J. and Restrepo, Carla},
  year = {2010},
  volume = {15},
  pages = {308--326},
  publisher = {{[International Biometric Society, Springer]}},
  issn = {1085-7117},
  doi = {10.1007/s13253-010-0020-z},
  abstract = {Multiple comparisons are widely used to compare gross features of distributions across populations. However, often a scientific hypothesis is more easily couched in terms of more focused null and alternative statistical hypotheses. For example, among distributions exhibiting clusters of continuous measurements across strata, are there clusters of measurements similar in terms of location, spread, or weight? We propose testing such hypotheses using a sequence of nested finite mixture models. Reasonable, data-driven priors are suggested based on estimates of the sample spreads and mid-points. Formal hypothesis testing is carried out through the computation of Bayes factors. The method is illustrated on Holling's (Ecological Monographs 62:447-502, 1992) forest and prairie bird body mass data, and data on the time-to-abortion in dairy cows. Supplemental simulations are available online.},
  annotation = {ZSCC: 0000012},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MixtureGaussian\\Xu et al_2010_Hypothesis Tests on Mixture Model Components with Applications in Ecology and.pdf},
  journal = {Journal of Agricultural, Biological, and Environmental Statistics},
  number = {3}
}

@article{Yan2002Onfarm,
  title = {On-Farm Strip Trials vs. Replicated Performance Trials for Cultivar Evaluation},
  author = {Yan, Weikai and Hunt, L. A. and Johnson, Peter and Stewart, Gregory and Lu, Xuewen},
  year = {2002},
  volume = {42},
  pages = {385--392},
  issn = {0011183X},
  doi = {10.2135/cropsci2002.0385},
  abstract = {A systematic comparison between two cultivar evaluation and recommendation systems, i.e., the balanced and replicated performance trials conducted in small plots at a small number of locations, and the unbalanced and non-replicated on-farm trials conducted in large strips on many farms, is lacking. This study was initiated to investigate the usefulness of the two contrasting systems in cultivar evaluation and the relationships between them. Yield data from Ontario winter wheat (Triticum aestivum L.) strip trials and performance trials for 1998 to 2000 were analyzed by mixed models. For all 3 yr, results from the two systems were highly correlated, both in terms of the best linear unbiased predictors (BLUP) and for the t-values of BLUP. Cultivars judged to be superior (or inferior) by one system were never judged to be inferior (or superior) by the other. Thus, both on-farm strip trials and replicated small-plot trials provide valid data for effective cultivar evaluation. On the basis of t-statistics, which measure cultivar reliability, cultivars can be classified into superior (t {$\geq$} 2), inferior (t {$\leq$} -2), and intermediate or inadequately tested (-2 {$<$} t {$<$} 2). Two cultivars can be regarded as different in reliability if their t-values differ by {$\geq$}3. The evaluation power of strip trials for a cultivar depends on the number of trials in which the cultivar is tested; a cultivar may not be adequately evaluated if it is tested in fewer than 20 trials.},
  annotation = {ZSCC: 0000054},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Yan et al_2002_On-farm strip trials vs.pdf},
  journal = {Crop Science},
  number = {2}
}

@article{You2017Deep,
  title = {Deep {{Gaussian Process}} for {{Crop Yield Prediction Based}} on {{Remote Sensing Data}}},
  author = {You, Jiaxuan and Li, Xiaocheng and Low, Melvin and Lobell, David and Ermon, Stefano},
  year = {2017},
  pages = {7},
  abstract = {Agricultural monitoring, especially in developing countries, can help prevent famine and support humanitarian efforts. A central challenge is yield estimation, i.e., predicting crop yields before harvest.},
  annotation = {ZSCC: 0000147},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\IMWJTWZG\\You et al. - Deep Gaussian Process for Crop Yield Prediction Ba.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{Zhang2006Sampling,
  title = {Sampling {{Correlation Matrices}} in {{Bayesian Models With Correlated Latent Variables}}},
  author = {Zhang, Xiao and Boscardin, W. John and Belin, Thomas R.},
  year = {2006},
  month = dec,
  volume = {15},
  pages = {880--896},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1198/106186006X160050},
  abstract = {Hierarchical model specifications using latent variables are frequently used to reflect correlation structure in data. Motivated by the structure of a Bayesian multivariate probit model, we demonstrate a parameter-extended Metropolis-Hastings algorithm for sampling from the posterior distribution of a correlation matrix. Our sampling algorithms lead directly to two readily interpretable families of prior distributions for a correlation matrix. The methodology is illustrated through a simulation study and through an application with repeated binary outcomes on individuals from a study of a suicide prevention intervention.},
  annotation = {ZSCC: 0000059  \_eprint: https://doi.org/10.1198/106186006X160050},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Zhang et al_2006_Sampling Correlation Matrices in Bayesian Models With Correlated Latent.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\5I9ZHVYH\\106186006X160050.html},
  journal = {Journal of Computational and Graphical Statistics},
  keywords = {Metropolis-Hastings algorithm,Multivariate probit model},
  number = {4}
}

@article{Zhang2013Kronecker,
  title = {On the {{Kronecker Products}} and {{Their Applications}}},
  author = {Zhang, Huamin and Ding, Feng},
  year = {2013},
  volume = {2013},
  pages = {1--8},
  issn = {1110-757X, 1687-0042},
  doi = {10.1155/2013/296185},
  abstract = {This paper studies the properties of the Kronecker product related to the mixed matrix products, the vector operator, and the vec-permutation matrix and gives several theorems and their proofs. In addition, we establish the relations between the singular values of two matrices and their Kronecker product and the relations between the determinant, the trace, the rank, and the polynomial matrix of the Kronecker products.},
  annotation = {ZSCC: NoCitationData[s1]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\GAVVRPX2\\Zhang and Ding - 2013 - On the Kronecker Products and Their Applications.pdf},
  journal = {Journal of Applied Mathematics},
  language = {en}
}


