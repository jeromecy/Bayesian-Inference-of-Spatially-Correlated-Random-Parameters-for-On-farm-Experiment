
@book{Abramowitz1974Handbook,
  title = {Handbook of {{Mathematical Functions}}, {{With Formulas}}, {{Graphs}}, and {{Mathematical Tables}},},
  author = {Abramowitz, Milton},
  year = {1974},
  publisher = {{Dover Publications, Inc.}},
  address = {{USA}},
  annotation = {ZSCC: 0000001},
  isbn = {978-0-486-61272-0}
}

@article{lambert2004comparison,
  title={A comparison of four spatial regression models for yield monitor data: A case study from Argentina},
  author={Lambert, Dayton M and Lowenberg-Deboer, James and Bongiovanni, Rodolfo},
  journal={Precision Agriculture},
  volume={5},
  number={6},
  pages={579--600},
  year={2004},
  publisher={Springer},
  doi = { 10.1007/s11119-004-6344-3}
}

@article{Adegboye2018Analysis,
  title = {Analysis of Spatial Data with a Nested Correlation Structure},
  author = {Adegboye, Oyelola A. and Leung, Denis H. Y. and Wang, You-Gan},
  year = {2018},
  volume = {67},
  pages = {329--354},
  issn = {1467-9876},
  doi = {10.1111/rssc.12230},
  abstract = {Spatial statistical analyses are often used to study the link between environmental factors and the incidence of diseases. In modelling spatial data, the existence of spatial correlation between observations must be considered. However, in many situations, the exact form of the spatial correlation is unknown. This paper studies environmental factors that might influence the incidence of malaria in Afghanistan. We assume that spatial correlation may be induced by multiple latent sources. Our method is based on a generalized estimating equation of the marginal mean of disease incidence, as a function of the geographical factors and the spatial correlation. Instead of using one set of generalized estimating equations, we embed a series of generalized estimating equations, each reflecting a particular source of spatial correlation, into a larger system of estimating equations. To estimate the spatial correlation parameters, we set up a supplementary set of estimating equations based on the correlation structures that are induced from the various sources. Simultaneous estimation of the mean and correlation parameters is performed by alternating between the two systems of equations.},
  annotation = {ZSCC: 0000007  \_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssc.12230},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Adegboye et al_2018_Analysis of spatial data with a nested correlation structure.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\SXI9R8G7\\rssc.html},
  journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  keywords = {Generalized estimating equations,Generalized method of moments,Malaria,Poisson model,Spatial correlation},
  language = {en},
  number = {2}
}

@article{Aftab2019SpatioTemporal,
  title = {Spatio-{{Temporal Gaussian Process Models}} for {{Extended}} and {{Group Object Tracking With Irregular Shapes}}},
  author = {Aftab, Waqas and Hostettler, Roland and De Freitas, Allan and Arvaneh, Mahnaz and Mihaylova, Lyudmila},
  year = {2019},
  month = mar,
  volume = {68},
  pages = {2137--2151},
  issn = {1939-9359},
  doi = {10.1109/TVT.2019.2891006},
  abstract = {Extended object tracking has become an integral part of many autonomous systems during the last two decades. For the first time, this paper presents a generic spatio-temporal Gaussian process (STGP) for tracking an irregular and non-rigid extended object. The complex shape is represented by key points and their parameters are estimated both in space and time. This is achieved by a factorization of the power spectral density function of the STGP covariance function. A new form of the temporal covariance kernel is derived with the theoretical expression of the filter likelihood function. Solutions to both the filtering and the smoothing problems are presented. A thorough evaluation of the performance in a simulated environment shows that the proposed STGP approach outperforms the state-of-the-art GP extended Kalman filter approach [N. Wahlstrom and E. Ozkan, ``Extended target tracking using Gaussian processes, IEEE Transactions on Signal Processing,'' vol. 63, no. 16, pp. 4165-4178, Aug. 2015] with up to 90\% improvement in the accuracy in position, 95\% in velocity and 7\% in the shape, while tracking a simulated asymmetric non-rigid object. The tracking performance improvement for a non-rigid irregular real object is up to 43\% in position, 68\% in velocity, 10\% in the recall, and 115\% in the precision measures.},
  annotation = {ZSCC: 0000011},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Aftab et al_2019_Spatio-Temporal Gaussian Process Models for Extended and Group Object Tracking.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\4IF6QLKF\\8601344.html},
  journal = {IEEE Transactions on Vehicular Technology},
  keywords = {autonomous systems,complex shape,covariance analysis,Extended object tracking,filter likelihood function,filtering problems,filtering theory,Gaussian processes,GP extended Kalman filter approach,group object tracking,irregular extended object tracking,irregular shapes,Kalman filters,Kernel,Kinematics,Noise measurement,nonlinear filters,nonrigid irregular real object tracking,object tracking,Object tracking,power spectral density function,Radar tracking,Rauch-Tung-Streibel smoother,Shape,smoothing problems,spatio-temporal Gaussian process,spatio-temporal Gaussian process models,STGP approach,STGP covariance function,target tracking,temporal covariance kernel,tracking performance improvement},
  number = {3}
}

@article{Airola2018Fast,
  title = {Fast {{Kronecker Product Kernel Methods}} via {{Generalized Vec Trick}}},
  author = {Airola, Antti and Pahikkala, Tapio},
  year = {2018},
  month = aug,
  volume = {29},
  pages = {3374--3387},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2017.2727545},
  abstract = {Kronecker product kernel provides the standard approach in the kernel methods' literature for learning from graph data, where edges are labeled and both start and end vertices have their own feature representations. The methods allow generalization to such new edges, whose start and end vertices do not appear in the training data, a setting known as zero-shot or zero-data learning. Such a setting occurs in numerous applications, including drug-target interaction prediction, collaborative filtering, and information retrieval. Efficient training algorithms based on the so-called vec trick that makes use of the special structure of the Kronecker product are known for the case where the training data are a complete bipartite graph. In this paper, we generalize these results to noncomplete training graphs. This allows us to derive a general framework for training Kronecker product kernel methods, as specific examples we implement Kronecker ridge regression and support vector machine algorithms. Experimental results demonstrate that the proposed approach leads to accurate models, while allowing order of magnitude improvements in training and prediction time.},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Airola_Pahikkala_2018_Fast Kronecker Product Kernel Methods via Generalized Vec Trick.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\ZJUWKNKB\\7999226.html},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  keywords = {Bipartite graph,Bipartite graph learning,Kernel,kernel methods,Kronecker product kernel,Learning systems,ridge regression,Standards,support vector machine (SVM),Support vector machines,Training,Training data,transfer learning,zero-shot learning},
  number = {8}
}

@article{Alesso2019Experimental,
  title = {Experimental {{Designs}} and {{Estimation Methods}} for {{On}}-{{Farm Research}}: {{A Simulation Study}} of {{Corn Yields}} at {{Field Scale}}},
  shorttitle = {Experimental {{Designs}} and {{Estimation Methods}} for {{On}}-{{Farm Research}}},
  author = {Alesso, Carlos Agust{\'i}n and Cipriotti, Pablo Ariel and Bollero, Germ{\'a}n Alberto and Martin, Nicolas Federico},
  year = {2019},
  volume = {111},
  pages = {2724--2735},
  issn = {1435-0645},
  doi = {10.2134/agronj2019.03.0142},
  abstract = {On-farm experimentation using Precision Agriculture technology enables farmers to make decisions based on data from their fields. Results from on-farm experiments depend on the experimental design and statistical analyses performed. Detailed information about the accuracy of the treatment effect estimates, and Type I error rates of hypothesis testing under different spatial structure scenarios attained by alternative experimental designs and analysis is required to improve on-farm research experiments. Three thousand yield data sets were drawn from 15 random fields simulated by unconditional Gaussian geostatistical simulation technique and were modeled by applying 10 experimental designs and three estimation methods with experimental units ranging from 138 to 9969 m2. No effect of spatial structure, experimental design, and estimation methods was observed on overall mean yield and treatment bias. Unaddressed changes of nugget/sill ratio and range of variogram had a significant effect on estimator efficiency and accuracy with Type I error rates above the nominal rate, which increased with higher spatial autocorrelation. Spatial methods were robust to changes in spatial structure regardless of the design. Randomization of treatment increased the uncertainty of model estimators. In general, the accuracy of treatment effect estimates increased with the number of replications of smaller size. The opposite trend was observed between those estimates and the size of the plots. Analyses showed that the best designs for testing the overall treatment effect in two-treatment experiments would be split-planter, strip-plots, and chessboard because of their size and number of experimental units. Core Ideas Spatial autocorrelation increases grand mean estimator variance in any design or method. Spatial autocorrelation reduces treatment effect estimator efficiency if not modeled. Spatial autocorrelation increases Type I error if not modeled. Designs with small experimental units (strip plots or chessboard) performed better.},
  annotation = {ZSCC: 0000005  \_eprint: https://acsess.onlinelibrary.wiley.com/doi/pdf/10.2134/agronj2019.03.0142},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Alesso et al_2019_Experimental Designs and Estimation Methods for On-Farm Research.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\SMMG3NUS\\agronj2019.03.html},
  journal = {Agronomy Journal},
  language = {en},
  number = {6}
}

@article{Baek2019Brief,
  ids = {Baek2019},
  title = {Brief {{Research Report}}: {{Bayesian Versus REML Estimations With Noninformative Priors}} in {{Multilevel Single}}-{{Case Data}}},
  shorttitle = {Brief {{Research Report}}},
  author = {Baek, Eunkyeng and Beretvas, S. Natasha and {Van den Noortgate}, Wim and Ferron, John M.},
  year = {2019},
  month = mar,
  pages = {1--13},
  publisher = {{Routledge}},
  issn = {0022-0973, 1940-0683},
  doi = {10.1080/00220973.2018.1527280},
  abstract = {Recently, researchers have used multilevel models for estimating intervention effects in single-case experiments that include replications across participants (e.g., multiple baseline designs) or for combining results across multiple single-case studies. Researchers estimating these multilevel models have primarily relied on restricted maximum likelihood (REML) techniques, but Bayesian approaches have also been suggested. The purpose of this Monte Carlo simulation study was to examine the impact of estimation method (REML versus Bayesian with noninformative priors) on the estimation of treatment effects (relative bias, root mean square error) and on the inferences about those effects (interval coverage) for autocorrelated multiple-baseline data. Simulated conditions varied with regard to the number of participants, series length, and distribution of the variance within and across participants. REML and Bayesian estimation led to estimates of the fixed effects that showed little to no bias but that differentially impacted the inferences about the fixed effects and the estimates of the variances. Implications for applied researchers and methodologists are discussed.},
  annotation = {ZSCC: 0000005},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Baek et al. - 2019 - Brief Research Report Bayesian Versus REML Estima.pdf},
  journal = {The Journal of Experimental Education},
  keywords = {Bayesian estimation,estimation method,multilevel modeling,noninformative priors,restricted maximum likelihood,single-case research},
  language = {English}
}

@book{Banerjee2004Hierarchical,
  title = {Hierarchical Modeling and Analysis for Spatial Data},
  author = {Banerjee, Sudipto and Carlin, Bradley P. and Gelfand, Alan E.},
  year = {2004},
  publisher = {{Chapman \& Hall/CRC}},
  address = {{Boca Raton, Fla}},
  annotation = {ZSCC: 0000007},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\ASAN66RU\\Banerjee et al. - 2004 - Hierarchical modeling and analysis for spatial dat.pdf},
  isbn = {978-1-58488-410-1},
  keywords = {Mathematical models,Spatial analysis (Statistics)},
  language = {en},
  lccn = {QA278.2 .B36 2004},
  number = {101},
  series = {Monographs on Statistics and Applied Probability}
}

@article{Bates2015Fitting,
  title = {Fitting Linear Mixed-Effects Models Using Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Benjamin M. and Walker, Steven C.},
  year = {2015},
  volume = {67},
  issn = {15487660},
  doi = {10.18637/jss.v067.i01},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  annotation = {ZSCC: 0000031},
  archiveprefix = {arXiv},
  arxivid = {1406.5823},
  eprint = {1406.5823},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Bates et al_2015_Fitting linear mixed-effects models using lme4.pdf},
  journal = {Journal of Statistical Software},
  keywords = {Cholesky decomposition,Linear mixed models,Penalized least squares,Sparse matrix methods},
  number = {1}
}

@article{Besag1999Bayesian,
  ids = {Besag1999Bayesiana},
  title = {Bayesian Analysis of Agricultural Field Experiments},
  author = {Besag, J. and Higdon, D.},
  year = {1999},
  month = nov,
  volume = {61},
  pages = {691--746},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/1467-9868.00201},
  abstract = {The paper describes Bayesian analysis for agricultural field experiments, a topic that has received very little previous attention, despite a vast frequentist literature. Adoption of the Bayesian paradigm simplifies the interpretation of the results, especially in ranking and selection. Also, complex formulations can be analysed with comparative ease, by using Markov chain Monte Carlo methods. A key ingredient in the approach is the need for spatial representations of the unobserved fertility patterns. This is discussed in detail. Problems caused by outliers and by jumps in fertility are tackled via hierarchical-t formulations that may find use in other contexts. The paper includes three analyses of variety trials for yield and one example involving binary data; none is entirely straightforward. Some numerical comparisons with frequentist analyses are made.},
  annotation = {ZSCC: 0000249},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesTechnique\\Bayesian Analysis of Agricultural Field Experiments.pdf},
  journal = {J Royal Statistical Soc B},
  keywords = {agricultural field trials,bayesian computation,bayesian inference,binary data,combining information,crop experiments,intrinsic autoregressions,markov chain monte carlo,markov random fields,methods,prior distributions,ranking and selection,spatial statistics,variety},
  language = {en},
  number = {4}
}

@article{Betancourt2017Conceptual,
  ids = {Betancourt2017,Betancourt2018Conceptual,betancourt2017conceptual},
  title = {A Conceptual Introduction to {{Hamiltonian Monte Carlo}}},
  author = {Betancourt, M.},
  year = {2017},
  volume = {arXiv:1701.02434},
  annotation = {ZSCC: 0000589},
  archiveprefix = {arXiv},
  arxivid = {1701.02434},
  eprint = {1701.02434},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\666TAFRI\\1701.html},
  journal = {arXiv preprint},
  keywords = {⛔ No DOI found,Statistics - Methodology}
}

@book{Brooks2011Handbook,
  title = {Handbook of Markov Chain Monte Carlo},
  author = {Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year = {2011},
  publisher = {{CRC press}},
  annotation = {ZSCC: 0001719},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\LNAKALPB\\books.html}
}

@article{Browne2006Comparison,
  title = {A Comparison of {{Bayesian}} and Likelihood-Based Methods for Fitting Multilevel Models},
  author = {Browne, William J. and Draper, David},
  year = {2006},
  volume = {1},
  pages = {473--514},
  issn = {19360975},
  doi = {10.1214/06-BA117},
  abstract = {We use simulation studies, whose design is realistic for educational and medical research (as well as other fields of inquiry), to compare Bayesian and likelihood-based methods for fitting variance-components (VC) and random-effects logistic regression (RELR) models. The likelihood (and approximate likelihood) approaches we examine are based on the methods most widely used in current applied multilevel (hierarchical) analyses: maximum likelihood (ML) and restricted ML (REML) for Gaussian outcomes, and marginal and penalized quasi-likelihood (MQL and PQL) for Bernoulli outcomes. Our Bayesian methods use Markov chain Monte Carlo (MCMC) estimation, with adaptive hybrid Metropolis-Gibbs sampling for RELR models, and several diffuse prior distributions ({$\Gamma$} 1({$\epsilon$}, {$\epsilon$})U (0,1/{$\epsilon$}) priors for variance components). For evaluation criteria we consider bias of point estimates and nominal versus actual coverage of interval estimates in repeated sampling. In two-level VC models we find that (a) both likelihood-based and Bayesian approaches can be made to produce approximately unbiased estimates, although the automatic manner in which REML accomplishes this is an advantage, but (b) both approaches had difficulty achieving nominal coverage in small samples and with small values of the intraclass correlation. With the threelevel RELR models we examine we find that (c) quasi-likelihood methods for estimating random-effects variances perform badly with respect to bias and coverage in the example we simulated, and (d) Bayesian diffuse-prior methods lead to wellcalibrated point and interval RELR estimates. While it is true that the likelihoodbased methods we study are considerably faster computationally than MCMC, (i) steady improvements in recent years in both hardware speed and efficiency of Monte Carlo algorithms and (ii) the lack of calibration of likelihood-based methods in some common hierarchical settings combine to make MCMC-based Bayesian fitting of multilevel models an attractive approach, even with rather large data sets. Other analytic strategies based on less approximate likelihood methods are also possible but would benefit from further study of the type summarized here. \textcopyright{} 2006 International Society for Bayesian Analysis.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\A comparison of Bayesian and likelihood-based methods for fitting multilevel models.pdf},
  journal = {Bayesian Anal.},
  keywords = {Adaptive MCMC,Bias,Calibration,Diffuse priors,Hierarchical modeling,Hybrid Metropolis-Gibbs sampling,IGLS,Interval coverage,Intraclass correlation,Mixed models,MQL,PQL,Random-effects logistic regression,REML,RIGLS,Variance-components models},
  number = {3}
}

@article{Brunsdon1999Notes,
  title = {Some {{Notes}} on {{Parametric Significance Tests}} for {{Geographically Weighted Regression}}},
  author = {Brunsdon, Chris and Fotheringham, A. Stewart and Charlton, Martin},
  year = {1999},
  month = aug,
  volume = {39},
  pages = {497--524},
  issn = {0022-4146, 1467-9787},
  doi = {10.1111/0022-4146.00146},
  abstract = {The technique of geographically weighted regression (GWR) is used to model spatial `drift' in linear model coefficients. In this paper we extend the ideas of GWR in a number of ways. First, we introduce a set of analytically derived significance tests allowing a null hypothesis of no spatial parameter drift to be investigated. Second, we discuss `mixed' GWR models where some parameters are fixed globally but others vary geographically. Again, models of this type may be assessed using significance tests. Finally, we consider a means of deciding the degree of parameter smoothing used in GWR based on the Mallows Cp statistic. To complete the paper, we analyze an example data set based on house prices in Kent in the U.K. using the techniques introduced.},
  annotation = {ZSCC: 0000498},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\3WZ583YQ\\Brunsdon et al. - 1999 - Some Notes on Parametric Significance Tests for Ge.pdf},
  journal = {Journal of Regional Science},
  language = {en},
  number = {3}
}

@article{Burkner2017Brms,
  title = {Brms: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul Christian},
  year = {2017},
  month = aug,
  volume = {80},
  pages = {1--28},
  publisher = {{American Statistical Association}},
  issn = {15487660},
  doi = {10.18637/jss.v080.i01},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit \textendash{} among others \textendash{} linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
  annotation = {ZSCC: 0002427},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\brms An R Package for Bayesian Multilevel Models Using Stan.pdf},
  journal = {Journal of Statistical Software},
  keywords = {Bayesian inference,MCMC,Multilevel model,Ordinal data,R,Stan},
  number = {1}
}

@article{Burkner2018Advanced,
  ids = {burknerAdvancedBayesianMultilevel2018},
  title = {Advanced {{Bayesian}} Multilevel Modeling with the {{R}} Package Brms},
  author = {B{\"u}rkner, Paul-Christian Christian},
  year = {2018},
  volume = {10},
  pages = {395--411},
  issn = {20734859},
  doi = {10.32614/rj-2018-017},
  abstract = {The brms package allows R users to easily specify a wide range of Bayesian single-level and multilevel models which are fit with the probabilistic programming language Stan behind the scenes. Several response distributions are supported, of which all parameters (e.g., location, scale, and shape) can be predicted. Non-linear relationships may be specified using non-linear predictor terms or semi-parametric approaches such as splines or Gaussian processes. Multivariate models can be fit as well. To make all of these modeling options possible in a multilevel framework, brms provides an intuitive and powerful formula syntax, which extends the well known formula syntax of lme4. The purpose of the present paper is to introduce this syntax in detail and to demonstrate its usefulness with four examples, each showing relevant aspects of the syntax.},
  annotation = {ZSCC: 0000040},
  archiveprefix = {arXiv},
  arxivid = {1705.11123},
  eprint = {1705.11123},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Advanced Bayesian Multilevel Modeling with the R Package brms.pdf},
  journal = {R Journal},
  keywords = {bayesian inference,distributional regression,mcmc,multilevel models,r,stan},
  number = {1}
}

@article{Burkner2020Efficient,
  title = {Efficient Leave-One-out Cross-Validation for {{Bayesian}} Non-Factorized Normal and {{Student}}-t Models},
  author = {B{\"u}rkner, Paul-Christian and Gabry, Jonah and Vehtari, Aki},
  year = {2020},
  month = mar,
  abstract = {Cross-validation can be used to measure a model's predictive accuracy for the purpose of model comparison, averaging, or selection. Standard leave-one-out cross-validation (LOO-CV) requires that the observation model can be factorized into simple terms, but a lot of important models in temporal and spatial statistics do not have this property or are inefficient or unstable when forced into a factorized form. We derive how to efficiently compute and validate both exact and approximate LOO-CV for any Bayesian non-factorized model with a multivariate normal or Student-\textbackslash (t\textbackslash ) distribution on the outcome values. We demonstrate the method using lagged simultaneously autoregressive (SAR) models as a case study.},
  annotation = {ZSCC: NoCitationData[s0]},
  archiveprefix = {arXiv},
  eprint = {1810.10559},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Bürkner et al_2020_Efficient leave-one-out cross-validation for Bayesian non-factorized normal and.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\L7RSPAES\\1810.html},
  journal = {arXiv:1810.10559 [stat]},
  keywords = {Statistics - Methodology},
  primaryclass = {stat}
}

@article{Burkner2021Efficient,
  title = {Efficient Leave-One-out Cross-Validation for {{Bayesian}} Non-Factorized Normal and {{Student}}-t Models},
  author = {B{\"u}rkner, Paul-Christian and Gabry, Jonah and Vehtari, Aki},
  year = {2021},
  month = jun,
  journal = {Comput Stat},
  volume = {36},
  number = {2},
  pages = {1243--1261},
  issn = {1613-9658},
  doi = {10.1007/s00180-020-01045-4}
 }

@misc{Butler2017ASRemlR,
  title = {{{ASReml}}-{{R Reference Manual Version}} 4},
  author = {Butler, D.G. and Cullis, B.R. and Gilmour, A.R. and Gogel, B.G. and Thompson, R.},
  year = {2017},
  publisher = {{VSN International Ltd, Hemel Hempstead, HP1 1ES, UK.}},
  annotation = {ZSCC: 0000003},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\MLandREML\\asreml4-R_manual.pdf}
}

@misc{Cao2021Bayesian,
  title = {Bayesian {{Inference}} of {{Spatially Correlated Random Parameters}} for {{On}}-Farm {{Experiment}}},
  author = {Cao, Zhanglong and Stefanova, Katia and Gibberd, Mark and Rakshit, Suman},
  year = {2021},
  language = {English}
}

@article{Carpenter2017Stan,
  title = {Stan : {{A Probabilistic Programming Language}}},
  shorttitle = {Stan},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  month = jan,
  volume = {76},
  publisher = {{Columbia Univ., New York, NY (United States); Harvard Univ., Cambridge, MA (United States)}},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i01},
  abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
  annotation = {ZSCC: 0004125},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Carpenter et al_2017_Stan.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\AQM237SX\\1430202.html},
  journal = {Journal of Statistical Software},
  language = {English},
  number = {1}
}

@unpublished{Chauveau2018Testing,
  title = {Testing for Univariate Two-Component {{Gaussian}} Mixture in Practice},
  author = {Chauveau, Didier and Garel, Bernard and Mercier, Sabine},
  year = {2018},
  month = dec,
  abstract = {We consider univariate Gaussian mixtures theory and applications, and particularly the problem of testing the null hypothesis of homogeneity (one component) against two components. Several approaches have been proposed in the literature during the last decades. We focus on two different techniques, one based on the Likelihood-Ratio Test (LRT), and another one based on estimation of the parameters of the mixture grounded on some specific adaptation of the well-known EM algorithm often called the EM-test. We propose in particular a novel methodology allowing application of the LRT in actual situations, by plugging-in estimates that are assumed known in asymptotic setup. We aim to provide useful comparisons between different techniques, together with  guidelines for practitioners in order to enable them to use theoretical advances for analysing actual data of realistic sample sizes. We finally illustrate these methods in an application to real data corresponding to the number of days between two events concerning ovarian response and lambing for ewes.},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MixtureGaussian\\Chauveau et al_2018_Testing for univariate two-component Gaussian mixture in practice.pdf},
  keywords = {EM tests,Gaussian process,likelihood ratio test,Mixture models}
}

@article{Che2010Bayesian,
  ids = {Che2010},
  title = {Bayesian Data Analysis for Agricultural Experiments},
  author = {Che, X. and Xu, S.},
  year = {2010},
  month = sep,
  volume = {90},
  pages = {575--603},
  publisher = {{NRC Research Press}},
  issn = {0008-4220},
  doi = {10.4141/cjps10004},
  abstract = {Data collected in agricultural experiments can be analyzed in many different ways using different models. The most commonly used models are the linear model and the generalized linear model. The ma..., Les donn\'ees issues des exp\'eriences agricoles peuvent \^etre analys\'ees de nombreuses mani\`eres avec diff\'erents mod\`eles. Les plus couramment employ\'es sont le mod\`ele lin\'eaire et le mod\`ele lin\'eaire g\'en\'era...},
  annotation = {ZSCC: 0000013},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Che_Xu_2010_Bayesian data analysis for agricultural experiments.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\HPUNDK39\\CJPS10004.html},
  journal = {Can. J. Plant Sci.},
  keywords = {2010,analyse baye,bayesian method,che,et xu,generalized linear model,markov chain monte carlo,s,sas,winbugs,x},
  number = {5}
}

@article{Chen2012Robust,
  title = {A Robust Method of Thin Plate Spline and Its Application to {{DEM}} Construction},
  author = {Chen, Chuanfa and Li, Yanyan},
  year = {2012},
  month = nov,
  volume = {48},
  pages = {9--16},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2012.05.018},
  abstract = {In order to avoid the ill-conditioning problem of thin plate spline (TPS), the orthogonal least squares (OLS) method was introduced, and a modified OLS (MOLS) was developed. The MOLS of TPS (TPS-M) can not only select significant points, termed knots, from large and dense sampling data sets, but also easily compute the weights of the knots in terms of back-substitution. For interpolating large sampling points, we developed a local TPS-M, where some neighbor sampling points around the point being estimated are selected for computation. Numerical tests indicate that irrespective of sampling noise level, the average performance of TPS-M can advantage with smoothing TPS. Under the same simulation accuracy, the computational time of TPS-M decreases with the increase of the number of sampling points. The smooth fitting results on lidar-derived noise data indicate that TPS-M has an obvious smoothing effect, which is on par with smoothing TPS. The example of constructing a series of large scale DEMs, located in Shandong province, China, was employed to comparatively analyze the estimation accuracies of the two versions of TPS and the classical interpolation methods including inverse distance weighting (IDW), ordinary kriging (OK) and universal kriging with the second-order drift function (UK). Results show that regardless of sampling interval and spatial resolution, TPS-M is more accurate than the classical interpolation methods, except for the smoothing TPS at the finest sampling interval of 20m, and the two versions of kriging at the spatial resolution of 15m. In conclusion, TPS-M, which avoids the ill-conditioning problem, is considered as a robust method for DEM construction.},
  annotation = {ZSCC: 0000043},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Chen_Li_2012_A robust method of thin plate spline and its application to DEM construction.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\JV2KPV4G\\S0098300412001744.html},
  journal = {Computers \& Geosciences},
  keywords = {DEM,Interpolation,Kriging,Orthogonal least squares,Thin plate spline},
  language = {en}
}

@article{Chen2019Simple,
  title = {A Simple and Parsimonious Generalised Additive Model for Predicting Wheat Yield in a Decision Support Tool},
  author = {Chen, Kefei and O'Leary, Rebecca A. and Evans, Fiona H.},
  year = {2019},
  volume = {173},
  pages = {140--150},
  publisher = {{Elsevier}},
  issn = {0308521X},
  doi = {10.1016/j.agsy.2019.02.009},
  abstract = {Yield prediction is a major determinant of many management decisions for crop production. Farmers and their advisors want user-friendly decision support tools for predicting yield. Simulation models can be used to accurately predict yield, but they are complex and difficult to parameterise. The goal of this study is to build a simple and parsimonious model for predicting wheat yields that can be implemented in a decision tool to be used by farmers at a paddock level. A large yield data set accumulated from trials on commonly grown varieties in Western Australia is used to build and validate a generalised additive model (GAM) for predicting wheat yield. Explanatory variables tested included weather data and derivatives, geolocation, soil type, land capability, and wheat varieties. Model selection followed a forward stepwise approach in combination with cross-validation to select the smallest set of explanatory variables. The predictive performance is also evaluated using independent data. The final model uses seasonal water availability, location and year to predict wheat yield. Because the GAM model has minimal inputs, it can be easily employed in a decision tool to predict yield throughout the growing season using rainfall data up to the prediction date and either climatological averages or seasonal forecasts of rainfall for the remainder of the growing season. It also has the potential to be used as an input to agronomic models that predict the effect on yield of various management choices for fertiliser, pest, weed and disease management.},
  annotation = {ZSCC: 0000016},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Chen et al_2019_A simple and parsimonious generalised additive model for predicting wheat yield.pdf},
  journal = {Agricultural Systems},
  keywords = {Crop modelling,Crop water relations,Decision support,Precision farming,Waterlogging,Yield prediction},
  number = {August 2018}
}

@article{Cheng2019Additive,
  title = {An Additive {{Gaussian}} Process Regression Model for Interpretable Non-Parametric Analysis of Longitudinal Data},
  author = {Cheng, Lu and Ramchandran, Siddharth and Vatanen, Tommi and Lietz{\'e}n, Niina and Lahesmaa, Riitta and Vehtari, Aki and L{\"a}hdesm{\"a}ki, Harri},
  year = {2019},
  month = dec,
  volume = {10},
  pages = {1--11},
  publisher = {{Springer US}},
  issn = {20411723},
  doi = {10.1038/s41467-019-09785-8},
  abstract = {Biomedical research typically involves longitudinal study designs where samples from individuals are measured repeatedly over time and the goal is to identify risk factors (covariates) that are associated with an outcome value. General linear mixed effect models are the standard workhorse for statistical analysis of longitudinal data. However, analysis of longitudinal data can be complicated for reasons such as difficulties in modelling correlated outcome values, functional (time-varying) covariates, nonlinear and non-stationary effects, and model inference. We present LonGP, an additive Gaussian process regression model that is specifically designed for statistical analysis of longitudinal data, which solves these commonly faced challenges. LonGP can model time-varying random effects and non-stationary signals, incorporate multiple kernel learning, and provide interpretable results for the effects of individual covariates and their interactions. We demonstrate LonGP's performance and accuracy by analysing various simulated and real longitudinal -omics datasets.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\GPR\\An additive Gaussian process regression model for interpretable non-parametric analysis of longitudinal data.pdf},
  journal = {Nat. Commun.},
  number = {1}
}

@book{Congdon2019Bayesian,
  title = {Bayesian {{Hierarchical Models}}: {{With Applications Using R}}, {{Second Edition}}},
  shorttitle = {Bayesian {{Hierarchical Models}}},
  author = {Congdon, Peter D.},
  year = {2019},
  month = sep,
  edition = {Second},
  publisher = {{CRC Press}},
  abstract = {An intermediate-level treatment of Bayesian hierarchical models and their applications, this book demonstrates the advantages of a Bayesian approach to data sets involving inferences for collections of related units or variables, and in methods where parameters can be treated as random collections. Through illustrative data analysis and attention to statistical computing, this book facilitates practical implementation of Bayesian hierarchical methods.  The new edition is a revision of the book Applied Bayesian Hierarchical Methods. It maintains a focus on applied modelling and data analysis, but now using entirely R-based Bayesian computing options. It has been updated with a new chapter on regression for causal effects, and one on computing options and strategies. This latter chapter is particularly important, due to recent advances in Bayesian computing and estimation, including the development of rjags and rstan. It also features updates throughout with new examples.  The examples exploit and illustrate the broader advantages of the R computing environment, while allowing readers to explore alternative likelihood assumptions, regression structures, and assumptions on prior densities.  Features:   Provides a comprehensive and accessible overview of applied Bayesian hierarchical modelling   Includes many real data examples to illustrate different modelling topics   R code (based on rjags, jagsUI, R2OpenBUGS, and rstan) is integrated into the book, emphasizing implementation   Software options and coding principles are introduced in new chapter on computing   Programs and data sets available on the book's website},
  annotation = {ZSCC: NoCitationData[s1]},
  googlebooks = {NRGwDwAAQBAJ},
  isbn = {978-1-4987-8591-4},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {English}
}

@article{Cook1998Precision,
  title = {Precision Agriculture \textemdash{} Opportunities, Benefits and Pitfalls of Site-Specific Crop Management in {{Australia}}},
  author = {Cook, S. E. and Bramley, R. G. V.},
  year = {1998},
  volume = {38},
  pages = {753--763},
  publisher = {{CSIRO PUBLISHING}},
  issn = {1446-5574},
  doi = {10.1071/ea97156},
  abstract = {Summary. Precision agriculture is the term given to crop management methods which recognise and manage within-paddock spatial and temporal variations in the soil\textendash plant\textendash atmosphere system. This paper reviews the principles, practice and perceived benefits of precision agriculture. The objective of precision agriculture is to improve the control of input variables such as fertiliser, seed, chemicals or water with respect to the desired outcomes of increased profitability, reduced environmental risk or better product quality. The practice can be viewed as comprising 4 stages: information acquisition; interpretation; evaluation; and control. Much of the technology to acquire information and control machinery is available or at a late stage of development. However, methods of interpretation are less well developed.},
  annotation = {ZSCC: 0000191},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\AXMGKIKX\\ea97156.html},
  journal = {Aust. J. Exp. Agric.},
  language = {en},
  number = {7}
}

@incollection{Cook1999OnFarm,
  title = {On-{{Farm Experimentation}} to {{Determine Site}}-{{Specific Responses}} to {{Variable Inputs}}},
  booktitle = {Proceedings of the {{Fourth International Conference}} on {{Precision Agriculture}}},
  author = {Cook, S. E. and Adams, M. L. and Corner, R. J.},
  year = {1999},
  pages = {611--621},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.2134/1999.precisionagproc4.c60},
  abstract = {Empirical experiments are used in manufacturing industries to improve control of complex or poorly understood processes. Precision agriculture technology enables farmers to mimic this approach, by providing technology to vary inputs at field scale and measure the site-specific crop response. Using a field-scale example from the Western Australian wheatbelt, we describe the concept and how it can be applied. The practice comprises experimental design, analysis and inference. A hybrid approach, which combines the advantages of both empirical and deterministic predictive models is described.},
  annotation = {ZSCC: 0000021  \_eprint: https://acsess.onlinelibrary.wiley.com/doi/pdf/10.2134/1999.precisionagproc4.c60},
  copyright = {Copyright \textcopyright{} 1999 ASA-CSSA-SSSA},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Cook et al_1999_On-Farm Experimentation to Determine Site-Specific Responses to Variable Inputs.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\EBM2FLWG\\1999.precisionagproc4.html},
  isbn = {978-0-89118-258-0},
  keywords = {decision-making,fertilizer,on-farm experiments,precision agriculture,site-specific management,uncertainty,variable inputs,Western Australian wheatbelt},
  language = {en}
}

@article{Cook2013Onfarm,
  title = {On-Farm Experimentation},
  author = {Cook, Simon and Cock, James and Oberth{\"u}r, Thomas and Fisher, Myles},
  year = {2013},
  volume = {97},
  pages = {17--20},
  annotation = {ZSCC: 0000024},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\OFEandPA\\Simon Cook, James Cock - 2013 - On-Farm Experimentation.pdf},
  journal = {Better Crop. Plant Food},
  keywords = {⛔ No DOI found},
  series = {4}
}

@article{Cordero2019Spatial,
  title = {Spatial Management Strategies for Nitrogen in Maize Production Based on Soil and Crop Data},
  author = {Cordero, Eleonora and Longchamps, Louis and Khosla, Raj and Sacco, Dario},
  year = {2019},
  month = dec,
  volume = {697},
  pages = {133854},
  issn = {0048-9697},
  doi = {10.1016/j.scitotenv.2019.133854},
  abstract = {Nitrogen (N) fertilisation determines maize grain yield (MGY). Precision agriculture (PA) allows matching crop N requirements in both space and time. Two approaches have been suggested for precision N management, i.e. management zones (MZ) delineation and crop remote and proximal sensing (PS). Several studies have demonstrated separately the advantages of these approaches for precision N application. This study evaluated their convenient integration, considering the influence of different PA techniques on MGY, N use efficiency (NUE), and farmer's net return, then providing a practical tool for choosing the fertilisation strategy that best applies in each agro-environment. A multi-site-year experiment was conducted between 2014 and 2016 in Colorado, USA. The trial compared four N management practices: uniform N rate, variable N rate based on MZ (VR-MZ), variable N rate based on PS (VR-PS), and variable N rate based on both PS and MZ (VR-PSMZ), based on their effect on MGY, partial factor productivity (PFPN), and net return above N fertiliser cost (RANC). Maize grain yield and PFPN maximisation conflicted in several situations. Hence, a compromise between obtaining high yield and increasing NUE is needed to enhance the overall sustainability of maize cropping systems. Maximisation of RANC allowed defining the best N fertilisation practice in terms of profitability. The spatial range in MGY is a practical tool for identifying the best N management practice. Uniform N supply was suitable where no spatial pattern was detected. If a high spatial range ({$>$}100 m) existed, VR-MZ was the best approach. Conversely, VR-PS performed better when a shorter spatial range ({$<$}16 m) was detected, and when maximum variability in crop vigour was observed across the field (range of variation = 0.597) leading to a larger difference in MGY (range of variation = 13.9 Mg ha-1). Results indicated that VR-PSMZ can further improve maize fertilisation for intermediate spatial structures (43 m).},
  annotation = {ZSCC: 0000006},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Cordero et al_2019_Spatial management strategies for nitrogen in maize production based on soil.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\AJK44FAA\\S0048969719338021.html},
  journal = {Science of The Total Environment},
  keywords = {Data fusion,Management zones,Precision fertilisation,Proximal crop sensing,Variable rate N application},
  language = {en}
}

@incollection{Cressie1993Statistics,
  title = {Statistics for {{Spatial Data}}},
  booktitle = {Statistics for {{Spatial Data}}},
  author = {Cressie, Noel A. C.},
  year = {1993},
  pages = {1--26},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781119115151.ch1},
  abstract = {This chapter contains sections titled: Spatial Data and Spatial Models Introductory Examples Statistics for Spatial Data: Why?},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119115151.ch1},
  chapter = {1},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\Y3H73KKU\\9781119115151.html},
  isbn = {978-1-119-11515-1},
  keywords = {geostatistical data,lattice data,point patterns,spatial data,spatial models},
  language = {en}
}

@article{Cressie1999Classes,
  title = {Classes of {{Nonseparable}}, {{Spatio}}-{{Temporal Stationary Covariance Functions}}},
  author = {Cressie, Noel and Huang, Hsin-Cheng},
  year = {1999},
  month = dec,
  volume = {94},
  pages = {1330--1339},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.1999.10473885},
  abstract = {Suppose that a random process Z(s;t), indexed in space and time, has spatio-temporal stationary covariance C(h;u), where h {$\in$} {$\mathbb{R}$}d (d {$\geq$} 1) is a spatial lag and u {$\in$} {$\mathbb{R}$} is a temporal lag. Separable spatio-temporal covariances have the property that they can be written as a product of a purely spatial covariance and a purely temporal covariance. Their ease of definition is counterbalanced by the rather limited class of random processes to which they correspond. In this article we derive a new approach that allows one to obtain many classes of nonseparable, spatio-temporal stationary covariance functions and fit several such classes to spatio-temporal data on wind speed over a region in the tropical western Pacific ocean.},
  annotation = {ZSCC: 0000774  \_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1999.10473885},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Cressie_Huang_1999_Classes of Nonseparable, Spatio-Temporal Stationary Covariance Functions.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\L4DC2GX2\\01621459.1999.html},
  journal = {Journal of the American Statistical Association},
  keywords = {Bochner's theorem,Matern covariance,Positive definite,Simple kriging.},
  number = {448}
}

@article{Damian2001Bayesian,
  title = {Bayesian Estimation of Semi-Parametric Non-Stationary Spatial Covariance Structures},
  author = {Damian, Doris and Sampson, Paul D. and Guttorp, Peter},
  year = {2001},
  volume = {12},
  pages = {161--178},
  issn = {1099-095X},
  doi = {10.1002/1099-095X(200103)12:2<161::AID-ENV452>3.0.CO;2-G},
  abstract = {We use the Sampson and Guttorp approach to model the non-stationary correlation function r(x, x{${'}$}) of a Gaussian spatial process through a bijective space deformation, f, so that in the deformed space the spatial correlation function can be considered isotropic, namely r(x, x{${'}$}) = {$\rho$}({$\mid$} f(x)-f(x{${'}$}){$\mid$}), where {$\rho$} belongs to a known parametric family. Given the locations in the deformed space of a number of geographic sites at which data are available, we smoothly extrapolate the deformation to the whole region of interest. Using a Bayesian framework, we estimate jointly these locations, as well as the parameters of the correlation function and the variance parameters. The advantage of our Bayesian approach is that it allows us to obtain measures of uncertainty of all these parameters. As the parameter space is of a very high dimension, we implement an MCMC method for obtaining samples from the posterior distributions of interest. We demonstrate our method through a simulation study, and show an application to a real data set. Copyright \textcopyright{} 2001 John Wiley \& Sons, Ltd.},
  annotation = {ZSCC: 0000157  \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/1099-095X\%28200103\%2912\%3A2\%3C161\%3A\%3AAID-ENV452\%3E3.0.CO\%3B2-G},
  copyright = {Copyright \textcopyright{} 2001 John Wiley \& Sons, Ltd.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Damian et al_2001_Bayesian estimation of semi-parametric non-stationary spatial covariance.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\K4Z8V8PN\\1099-095X(200103)122161AID-ENV4523.0.html},
  journal = {Environmetrics},
  keywords = {Gaussian spatial processes,Markov Chain Monte Carlo,thin-plate splines},
  language = {en},
  number = {2}
}

@inproceedings{Damianou2013Deep,
  title = {Deep {{Gaussian Processes}}},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Damianou, Andreas and Lawrence, Neil},
  year = {2013},
  month = apr,
  pages = {207--215},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief network based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inpu...},
  annotation = {ZSCC: 0000622},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Damianou_Lawrence_2013_Deep Gaussian Processes.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\73JZ8264\\damianou13a.html},
  language = {en}
}

@article{Datta2016Hierarchical,
  title = {Hierarchical {{Nearest}}-{{Neighbor Gaussian Process Models}} for {{Large Geostatistical Datasets}}},
  author = {Datta, Abhirup and Banerjee, Sudipto and Finley, Andrew O. and Gelfand, Alan E.},
  year = {2016},
  month = apr,
  volume = {111},
  pages = {800--812},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2015.1044091},
  abstract = {Spatial process models for analyzing geostatistical data entail computations that become prohibitive as the number of spatial locations become large. This article develops a class of highly scalable nearest-neighbor Gaussian process (NNGP) models to provide fully model-based inference for large geostatistical datasets. We establish that the NNGP is a well-defined spatial process providing legitimate finite-dimensional Gaussian densities with sparse precision matrices. We embed the NNGP as a sparsity-inducing prior within a rich hierarchical modeling framework and outline how computationally efficient Markov chain Monte Carlo (MCMC) algorithms can be executed without storing or decomposing large matrices. The floating point operations (flops) per iteration of this algorithm is linear in the number of spatial locations, thereby rendering substantial scalability. We illustrate the computational and inferential benefits of the NNGP over competing methods using simulation studies and also analyze forest biomass from a massive U.S. Forest Inventory dataset at a scale that precludes alternative dimension-reducing methods. Supplementary materials for this article are available online.},
  annotation = {ZSCC: 0000277},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\P3UKE6C7\\Datta et al. - 2016 - Hierarchical Nearest-Neighbor Gaussian Process Mod.pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {514}
}

@book{DipakDey2005Bayesian,
  ids = {rao2005Bayesiana,rao2005Bayesianb},
  title = {Bayesian {{Thinking}}, {{Modeling}} and {{Computation}}},
  editor = {{Dipak Dey} and {C.R. Rao}},
  year = {2005},
  month = nov,
  edition = {1st},
  volume = {25},
  publisher = {{Elsevier}},
  abstract = {This volume describes how to develop Bayesian thinking, modelling and computation both from philosophical, methodological and application point of view. It further describes parametric and nonparametric Bayesian methods for modelling and how to use modern computational methods to summarize inferences using simulation. The book covers wide range of topics including objective and subjective Bayesian inferences with a variety of applications in modelling categorical, survival, spatial, spatiotemporal, Epidemiological, software reliability, small area and micro array data. The book concludes with a chapter on how to teach Bayesian thoughts to nonstatisticians.Critical thinking on causal effectsObjective Bayesian philosophyNonparametric Bayesian methodologySimulation based computing techniquesBioinformatics and Biostatistics},
  annotation = {ZSCC: 0000014},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\9IK8VIBB\\reader.html;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\KP3KTF59\\reader.html},
  googlebooks = {TAOL4NIkg1oC},
  isbn = {978-0-08-046117-5},
  keywords = {Mathematics / Probability \& Statistics / General,Nonparametric statistics},
  language = {en}
}

@article{Donald2011Bayesian,
  title = {A {{Bayesian}} Analysis of an Agricultural Field Trial with Three Spatial Dimensions},
  author = {Donald, Margaret and Alston, Clair L. and Young, Rick R. and Mengersen, Kerrie L.},
  year = {2011},
  month = dec,
  volume = {55},
  pages = {3320--3332},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2011.06.022},
  abstract = {Modern technology now has the ability to generate large datasets over space and time. Such data typically exhibit high autocorrelations over all dimensions. The field trial data motivating the methods of this paper were collected to examine the behaviour of traditional cropping and to determine a cropping system which could maximise water use for grain production while minimising leakage below the crop root zone. They consist of moisture measurements made at 15 depths across 3 rows and 18 columns, in the lattice framework of an agricultural field. Bayesian conditional autoregressive (CAR) models are used to account for local site correlations. Conditional autoregressive models have not been widely used in analyses of agricultural data. This paper serves to illustrate the usefulness of these models in this field, along with the ease of implementation in WinBUGS, a freely available software package. The innovation is the fitting of separate conditional autoregressive models for each depth layer, the `layered CAR model', while simultaneously estimating depth profile functions for each site treatment. Modelling interest also lies in how best to model the treatment effect depth profiles, and in the choice of neighbourhood structure for the spatial autocorrelation model. The favoured model fitted the treatment effects as splines over depth, and treated depth, the basis for the regression model, as measured with error, while fitting CAR neighbourhood models by depth layer. It is hierarchical, with separate conditional autoregressive spatial variance components at each depth, and the fixed terms which involve an errors-in-measurement model treat depth errors as interval-censored measurement error. The Bayesian framework permits transparent specification and easy comparison of the various complex models compared.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Donald et al_2011_A Bayesian analysis of an agricultural field trial with three spatial dimensions.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\QS3DMNNA\\S0167947311002398.html},
  journal = {Computational Statistics \& Data Analysis},
  keywords = {Bayesian,Conditional autoregressive (CAR) models,Cubic radial bases,Errors-in-variables,Field trial,Latent variables,Markov Chain Monte Carlo (MCMC),Markov random field (MRF),Orthogonal polynomials,Spatial autocorrelation,Splines,Variance components},
  language = {en},
  number = {12}
}

@article{Duane1987Hybrid,
  ids = {duane1987hybrid},
  title = {Hybrid {{Monte Carlo}}},
  author = {Duane, Simon and Kennedy, Anthony D. and Pendleton, Brian J. and Roweth, Duncan},
  year = {1987},
  volume = {195},
  pages = {216--222},
  publisher = {{Elsevier}},
  doi = {10.1016/0370-2693(87)91197-x},
  annotation = {ZSCC: 0004047},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Duane et al_1987_Hybrid Monte Carlo.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\ZLKRG82L\\037026938791197X.html},
  journal = {Physics letters B},
  number = {2}
}

@article{DunlopHow,
  title = {How {{Deep Are Deep Gaussian Processes}}?},
  author = {Dunlop, Matthew M and Girolami, Mark A and Stuart, Andrew M and Teckentrup, Aretha L},
  pages = {46},
  abstract = {Recent research has shown the potential utility of deep Gaussian processes. These deep structures are probability distributions, designed through hierarchical construction, which are conditionally Gaussian. In this paper, the current published body of work is placed in a common framework and, through recursion, several classes of deep Gaussian processes are defined. The resulting samples generated from a deep Gaussian process have a Markovian structure with respect to the depth parameter, and the effective depth of the resulting process is interpreted in terms of the ergodicity, or non-ergodicity, of the resulting Markov chain. For the classes of deep Gaussian processes introduced, we provide results concerning their ergodicity and hence their effective depth. We also demonstrate how these processes may be used for inference; in particular we show how a Metropolis-within-Gibbs construction across the levels of the hierarchy can be used to derive sampling tools which are robust to the level of resolution used to represent the functions on a computer. For illustration, we consider the effect of ergodicity in some simple numerical examples.},
  annotation = {ZSCC: 0000061},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CKH3C53R\\Dunlop et al. - How Deep Are Deep Gaussian Processes.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{DuvenaudAdditive,
  title = {Additive {{Gaussian Processes}}},
  author = {Duvenaud, David and Nickisch, Hannes and Rasmussen, Carl Edward},
  pages = {9},
  abstract = {We introduce a Gaussian process model of functions which are additive. An additive function is one which decomposes into a sum of low-dimensional functions, each depending on only a subset of the input variables. Additive GPs generalize both Generalized Additive Models, and the standard GP models which use squared-exponential kernels. Hyperparameter learning in this model can be seen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive but tractable parameterization of the kernel function, which allows efficient evaluation of all input interaction terms, whose number is exponential in the input dimension. The additional structure discoverable by this model results in increased interpretability, as well as state-of-the-art predictive power in regression tasks.},
  annotation = {ZSCC: 0000235},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\4IFT26CE\\Duvenaud et al. - Additive Gaussian Processes.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{Edmondson2014Agridat,
  title = {Agridat},
  author = {Edmondson, R. N.},
  year = {2014},
  month = feb,
  volume = {152},
  pages = {2--2},
  publisher = {{Cambridge University Press}},
  issn = {0021-8596, 1469-5146},
  doi = {10.1017/S0021859613000920},
  abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0021859613000920/resource/name/firstPage-S0021859613000920a.jpg},
  annotation = {ZSCC: 0000001},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Edmondson_2014_Agridat.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\LRW39TUP\\CD87ABAC864526B683587B762EFDDC2B.html},
  journal = {The Journal of Agricultural Science},
  language = {en},
  number = {1}
}

@article{Evans2020Assessment,
  title = {Assessment of the {{Use}} of {{Geographically Weighted Regression}} for {{Analysis}} of {{Large On}}-{{Farm Experiments}} and {{Implications}} for {{Practical Application}}},
  author = {Evans, Fiona H. and Recalde Salas, Angela and Rakshit, Suman and Scanlan, Craig A. and Cook, Simon E.},
  year = {2020},
  month = nov,
  volume = {10},
  pages = {1720},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/agronomy10111720},
  abstract = {On-farm experimentation (OFE) is a farmer-centric process that can enhance the adoption of digital agriculture technologies and improve farm profitability and sustainability. Farmers work with consultants or researchers to design and implement experiments using their own machinery to test management practices at the field or farm scale. Analysis of data from OFE is challenging because of the large spatial variation influenced by spatial autocorrelation that is not due to the treatment being tested and is often much larger than treatment effects. In addition, the relationship between treatment and yield response may also vary spatially. We investigate the use of geographically weighted regression (GWR) for analysis of data from large on-farm experiments. GWR estimates local regressions, where data are weighted by distance from the site using a distance-decay kernel. It is a simple approach that can be easily explained to farmers and their agronomic advisors. We use simulated data to test the ability of GWR to separate yield variation due to treatment from any underlying spatial variation in yield that is not due to treatment; show that GWR kernel bandwidth can be based on experimental design to accurately separate the underlying spatial variability from treatment effects; and demonstrate a step-wise model selection approach to determine when the response to treatment is global across the experiment or locally varying. We demonstrate our recommended approach on two large-scale experiments conducted on farms in Western Australia to investigate grain yield response to potassium fertiliser. We discuss the implications of our results for routine practical application to OFE and conclude that GWR has potential for wide application in a semi-automated manner to analyse OFE data, improve farm decision-making, and enhance the adoption of digital technologies.},
  annotation = {ZSCC: 0000002},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Evans et al_2020_Assessment of the Use of Geographically Weighted Regression for Analysis of.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\N2A9G45S\\1720.html},
  journal = {Agronomy},
  keywords = {digital agriculture,geographically weighted regression,on-farm experimentation,precision agriculture,spatial analysis},
  language = {en},
  number = {11}
}

@article{F.Dormann2007Methods,
  title = {Methods to Account for Spatial Autocorrelation in the Analysis of Species Distributional Data: {{A}} Review},
  author = {F. Dormann, Carsten and M. McPherson, Jana and B. Ara{\'u}jo, Miguel and Bivand, Roger and Bolliger, Janine and Carl, Gudrun and G. Davies, Richard and Hirzel, Alexandre and Jetz, Walter and Daniel Kissling, W. and K{\"u}hn, Ingolf and Ohlem{\"u}ller, Ralf and {R. Peres-Neto}, Pedro and Reineking, Bj{\"o}rn and Schr{\"o}der, Boris and M. Schurr, Frank and Wilson, Robert},
  year = {2007},
  volume = {30},
  pages = {609--628},
  issn = {09067590},
  doi = {10.1111/j.2007.0906-7590.05171.x},
  abstract = {Species distributional or trait data based on range map (extent-of-occurrence) or atlas survey data often display spatial autocorrelation, i.e. locations close to each other exhibit more similar values than those further apart. If this pattern remains present in the residuals of a statistical model based on such data, one of the key assumptions of standard statistical analyses, that residuals are independent and identically distributed (i.i.d), is violated. The violation of the assumption of i.i.d. residuals may bias parameter estimates and can increase type I error rates (falsely rejecting the null hypothesis of no effect). While this is increasingly recognised by researchers analysing species distribution data, there is, to our knowledge, no comprehensive overview of the many available spatial statistical methods to take spatial autocorrelation into account in tests of statistical significance. Here, we describe six different statistical approaches to infer correlates of species' distributions, for both presence/absence (binary response) and species abundance data (poisson or normally distributed response), while accounting for spatial autocorrelation in model residuals: autocovariate regression; spatial eigenvector mapping; generalised least squares; (conditional and simultaneous) autoregressive models and generalised estimating equations. A comprehensive comparison of the relative merits of these methods is beyond the scope of this paper. To demonstrate each method's implementation, however, we undertook preliminary tests based on simulated data. These preliminary tests verified that most of the spatial modeling techniques we examined showed good type I error control and precise parameter estimates, at least when confronted with simplistic simulated data containing spatial autocorrelation in the errors. However, we found that for presence/absence data the results and conclusions were very variable between the different methods. This is likely due to the low information content of binary maps. Also, in contrast with previous studies, we found that autocovariate methods consistently underestimated the effects of environmental controls of species distributions. Given their widespread use, in particular for the modelling of species presence/absence data (e.g. climate envelope models), we argue that this warrants further study and caution in their use. To aid other ecologists in making use of the methods described, code to implement them in freely available software is provided in an electronic appendix. \textcopyright{} Ecography.},
  annotation = {ZSCC: NoCitationData[s2]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\F. Dormann et al_2007_Methods to account for spatial autocorrelation in the analysis of species.pdf},
  journal = {Ecography},
  number = {5}
}

@book{Fisher1934Statistical,
  title = {Statistical Methods for Research Workers},
  author = {Fisher, Ronald Aylmer},
  year = {1934},
  edition = {fifth},
  publisher = {{Oliver and Boyd}},
  address = {{Edinburgh}},
  annotation = {ZSCC: 0000005  OCLC: 4972023},
  language = {English}
}

@article{Fotheringham2009Problem,
  title = {``{{The Problem}} of {{Spatial Autocorrelation}}'' and {{Local Spatial Statistics}}},
  author = {Fotheringham, A. Stewart},
  year = {2009},
  volume = {41},
  pages = {398--403},
  issn = {1538-4632},
  doi = {10.1111/j.1538-4632.2009.00767.x},
  abstract = {This article examines the relationship between spatial dependency and spatial heterogeneity, two properties unique to spatial data. The property of spatial dependence has led to a large body of research into spatial autocorrelation and also, largely independently, into geostatistics. The property of spatial heterogeneity has led to a growing awareness of the limitation of global statistics and the value of local statistics and local statistical models. The article concludes with a discussion of how the two properties can be accommodated within the same modelling framework.},
  annotation = {ZSCC: 0000094  \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1538-4632.2009.00767.x},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\8KCEDT9K\\j.1538-4632.2009.00767.html},
  journal = {Geographical Analysis},
  language = {en},
  number = {4}
}

@article{Gabry2016Rstanarm,
  title = {Rstanarm: {{Bayesian}} Applied Regression Modeling via Stan},
  booktitle = {R Package Version},
  author = {Gabry, Jonah and Goodrich, Ben},
  year = {2016},
  abstract = {Estimates pre-compiled regression models using the 'rstan' package, which provides the R interface to the Stan C++ library for Bayesian estimation. Users specify models via the customary R syntax with a formula and data.frame plus some additional arguments for priors.},
  annotation = {ZSCC: 0000080},
  keywords = {⛔ No DOI found}
}

@article{Gabry2019Visualization,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  volume = {182},
  pages = {389--402},
  issn = {1467-985X},
  doi = {10.1111/rssa.12378},
  abstract = {Bayesian data analysis is about more than just computing a posterior distribution, and Bayesian visualization is about more than trace plots of Markov chains. Practical Bayesian data analysis, like all data analysis, is an iterative process of model building, inference, model checking and evaluation, and model expansion. Visualization is helpful in each of these stages of the Bayesian workflow and it is indispensable when drawing inferences from the types of modern, high dimensional models that are used by applied researchers.},
  annotation = {ZSCC: 0000273  \_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssa.12378},
  copyright = {\textcopyright{} 2019 Royal Statistical Society},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Visualization in Bayesian workﬂow.pdf},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  keywords = {Bayesian data analysis,Statistical graphics,Statistical workflow},
  language = {en},
  number = {2}
}

@article{GardnerGPyTorch,
  title = {{{GPyTorch}}: {{Blackbox Matrix}}-{{Matrix Gaussian Process Inference}} with {{GPU Acceleration}}},
  author = {Gardner, Jacob and Pleiss, Geoff and Weinberger, Kilian Q and Bindel, David and Wilson, Andrew G},
  pages = {11},
  abstract = {Despite advances in scalable models, the inference tools used for Gaussian processes (GPs) have yet to fully capitalize on developments in computing hardware. We present an efficient and general approach to GP inference based on Blackbox Matrix-Matrix multiplication (BBMM). BBMM inference uses a modified batched version of the conjugate gradients algorithm to derive all terms for training and inference in a single call. BBMM reduces the asymptotic complexity of exact GP inference from O(n3) to O(n2). Adapting this algorithm to scalable approximations and complex GP models simply requires a routine for efficient matrix-matrix multiplication with the kernel and its derivative. In addition, BBMM uses a specialized preconditioner to substantially speed up convergence. In experiments we show that BBMM effectively uses GPU hardware to dramatically accelerate both exact GP inference and scalable approximations. Additionally, we provide GPyTorch, a software platform for scalable GP inference via BBMM, built on PyTorch.},
  annotation = {ZSCC: 0000244},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Gardner et al. - GPyTorch Blackbox Matrix-Matrix Gaussian Process .pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{Gelfand1990Samplingbased,
  title = {Sampling-Based Approaches to Calculating Marginal Densities},
  author = {Gelfand, Alan E. and Smith, Adrian FM},
  year = {1990},
  volume = {85},
  pages = {398--409},
  publisher = {{Taylor \& Francis Group}},
  doi = {10.1080/01621459.1990.10476213},
  annotation = {ZSCC: 0009072},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Gelfand_Smith_1990_Sampling-based approaches to calculating marginal densities.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\XKTEL3EN\\01621459.1990.html},
  journal = {Journal of the American statistical association},
  number = {410}
}

@article{Gelfand2005Bayesian,
  title = {Bayesian {{Nonparametric Spatial Modeling With Dirichlet Process Mixing}}},
  author = {Gelfand, Alan E. and Kottas, Athanasios and MacEachern, Steven N.},
  year = {2005},
  month = sep,
  volume = {100},
  pages = {1021--1035},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1198/016214504000002078},
  abstract = {Customary modeling for continuous point-referenced data assumes a Gaussian process that is often taken to be stationary. When such models are fitted within a Bayesian framework, the unknown parameters of the process are assumed to be random, so a random Gaussian process results. Here we propose a novel spatial Dirichlet process mixture model to produce a random spatial process that is neither Gaussian nor stationary. We first develop a spatial Dirichlet process model for spatial data and discuss its properties. Because of familiar limitations associated with direct use of Dirichlet process models, we introduce mixing by convolving this process with a pure error process. We then examine properties of models created through such Dirichlet process mixing. In the Bayesian framework, we implement posterior inference using Gibbs sampling. Spatial prediction raises interesting questions, but these can be handled. Finally, we illustrate the approach using simulated data, as well as a dataset involving precipitation measurements over the Languedoc-Roussillon region in southern France.},
  annotation = {ZSCC: 0000395  \_eprint: https://doi.org/10.1198/016214504000002078},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Gelfand et al_2005_Bayesian Nonparametric Spatial Modeling With Dirichlet Process Mixing.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\D34UC3IG\\016214504000002078.html},
  journal = {Journal of the American Statistical Association},
  keywords = {Dependent Dirichlet process,Dirichlet process mixture models,Gaussian process,Markov chain Monte Carlo,Nonstationarity,Point-referenced spatial data,Random distribution},
  number = {471}
}

@article{Gelfand2016Spatial,
  title = {Spatial Statistics and {{Gaussian}} Processes: {{A}} Beautiful Marriage},
  shorttitle = {Spatial Statistics and {{Gaussian}} Processes},
  author = {Gelfand, Alan E. and Schliep, Erin M.},
  year = {2016},
  month = nov,
  volume = {18},
  pages = {86--104},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2016.03.006},
  abstract = {Spatial analysis has grown at a remarkable rate over the past two decades. Fueled by sophisticated GIS software and inexpensive and fast computation, collection of data with spatially referenced information has increased. Recognizing that such information can improve data analysis has led to an explosion of modeling and model fitting. The contribution of this paper is to illustrate how Gaussian processes have emerged as, arguably, the most valuable tool in the toolkit for geostatistical modeling. Apart from the simplest versions, geostatistical modeling can be viewed as a hierarchical specification with Gaussian processes introduced appropriately at different levels of the specification. This naturally leads to adopting a Bayesian framework for inference and suitable Gibbs sampling/Markov chain Monte Carlo for model fitting. Here, we review twenty years of modeling work spanning multivariate spatial analysis, gradient analysis, Bayesian nonparametric spatial ideas, directional data, extremes, data fusion, and large spatial and spatio-temporal datasets. We demonstrate that Gaussian processes are the key ingredients in all of this work. Most of the content is focused on modeling with examples being limited due to length constraints for the article. Altogether, we are able to conclude that spatial statistics and Gaussian processes do, indeed, make a beautiful marriage.},
  annotation = {ZSCC: 0000053},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Gelfand_Schliep_2016_Spatial statistics and Gaussian processes.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\ELTFPLQA\\S2211675316300033.html},
  journal = {Spatial Statistics},
  keywords = {Data fusion,Directional data,Hierarchical model,Multivariate processes,Spatial Dirichlet processes,Spatial gradients},
  language = {en},
  series = {Spatial {{Statistics Avignon}}: {{Emerging Patterns}}}
}

@article{Gelman2003Bayesian,
  title = {A {{Bayesian Formulation}} of {{Exploratory Data Analysis}} and {{Goodness}}-of-Fit {{Testing}}},
  author = {Gelman, Andrew},
  year = {2003},
  volume = {71},
  pages = {369--382},
  issn = {1751-5823},
  doi = {10.1111/j.1751-5823.2003.tb00203.x},
  abstract = {Exploratory data analysis (EDA) and Bayesian inference (or, more generally, complex statistical modeling)\textemdash which are generally considered as unrelated statistical paradigms\textemdash can be particularly effective in combination. In this paper, we present a Bayesian framework for EDA based on posterior predictive checks. We explain how posterior predictive simulations can be used to create reference distributions for EDA graphs, and how this approach resolves some theoretical problems in Bayesian data analysis. We show how the generalization of Bayesian inference to include replicated data yrep and replicated parameters \texttheta rep follows a long tradition of generalizations in Bayesian theory. On the theoretical level, we present a predictive Bayesian formulation of goodness-of-fit testing, distinguishing between p-values (posterior probabilities that specified antisymmetric discrepancy measures will exceed 0) and u-values (data summaries with uniform sampling distributions). We explain that p-values, unlike u-values, are Bayesian probability statements in that they condition on observed data. Having reviewed the general theoretical framework, we discuss the implications for statistical graphics and exploratory data analysis, with the goal being to unify exploratory data analysis with more formal statistical methods based on probability models. We interpret various graphical displays as posterior predictive checks and discuss how Bayesian inference can be used to determine reference distributions. The goal of this work is not to downgrade descriptive statistics, or to suggest they be replaced by Bayesian modeling, but rather to suggest how exploratory data analysis fits into the probability-modeling paradigm. We conclude with a discussion of the implications for practical Bayesian inference. In particular, we anticipate that Bayesian software can be generalized to draw simulations of replicated data and parameters from their posterior predictive distribution, and these can in turn be used to calibrate EDA graphs.},
  annotation = {ZSCC: 0000245  \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1751-5823.2003.tb00203.x},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Gelman_2003_A Bayesian Formulation of Exploratory Data Analysis and Goodness-of-fit Testing.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\HB2UBAIX\\j.1751-5823.2003.tb00203.html},
  journal = {International Statistical Review},
  keywords = {“p-value”,“u-value”,Bootstrap,Fisher's exact test,Graphics,Graphiques,Mixture model,Model checking,Modéles de mèlange,Multiple imputation,p-value,Posterior predictive check,Prior predictive check,u-value,Vérification de modéle,Vérification prédictive a posteriori,Vérification prédictive antérieur},
  language = {en},
  number = {2}
}

@article{Gelman2004Exploratory,
  title = {Exploratory {{Data Analysis}} for {{Complex Models}}},
  author = {Gelman, Andrew},
  year = {2004},
  month = dec,
  volume = {13},
  pages = {755--779},
  issn = {1061-8600, 1537-2715},
  doi = {10.1198/106186004x11435},
  annotation = {ZSCC: 0000225},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\444BDVTV\\Gelman - 2004 - Exploratory Data Analysis for Complex Models.pdf},
  journal = {Journal of Computational and Graphical Statistics},
  language = {en},
  number = {4}
}

@article{Gelman2006Prior,
  ids = {Gelman2006,gelman2006prior,gelmanPriorDistributionsVariance2006},
  title = {Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by {{Browne}} and {{Draper}})},
  author = {Gelman, Andrew and others},
  year = {2006},
  volume = {1},
  pages = {515--534},
  publisher = {{International Society for \{B\}ayesian Analysis}},
  doi = {10.1214/06-BA117A},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Gelman - 2006 - Prior distributions for variance parameters in hierarchical models (Comment on Article by Browne and Draper).pdf},
  isbn = {9781139460934},
  journal = {Bayesian analysis},
  keywords = {Bayesian inference,Conditional conjugacy,Folded-noncentral-t distribution,Half-t distribution,Hierarchical model,Multilevel model,Noninformative prior distribution,Weakly informative prior distribution},
  number = {3},
  owner = {zcao},
  timestamp = {2017.10.27}
}

@book{Gelman2013Bayesian,
  ids = {Gelman2014},
  title = {Bayesian {{Data Analysis}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  year = {2013},
  month = nov,
  edition = {Third Edition},
  publisher = {{CRC Press}},
  abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors\textemdash all leaders in the statistics community\textemdash introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book's web page.},
  annotation = {ZSCC: 0030622},
  googlebooks = {ZXL6AQAAQBAJ},
  isbn = {978-1-4398-4095-5},
  keywords = {Computers / Mathematical \& Statistical Software,Mathematics / Probability \& Statistics / General,Psychology / Research \& Methodology},
  language = {English},
  series = {Chapman \& {{Hall CRC Texts}} in {{Statistical Science}}}
}

@article{Gelman2017Prior,
  title = {The {{Prior Can Often Only Be Understood}} in the {{Context}} of the {{Likelihood}}},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  year = {2017},
  month = oct,
  volume = {19},
  pages = {555},
  issn = {1099-4300},
  doi = {10.3390/e19100555},
  abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys' priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
  annotation = {ZSCC: 0000145},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\The Prior Can Often Only Be Understood in the Context of the Likelihood.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\XEPITSXJ\\Gelman et al. - 2017 - The Prior Can Often Only Be Understood in the Cont.pdf},
  journal = {Entropy},
  language = {en},
  number = {10}
}

@article{Gelman2019Rsquared,
  ids = {Gelman2019Rsquareda},
  title = {R-Squared for Bayesian Regression Models},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  year = {2019},
  volume = {73},
  pages = {307--309},
  publisher = {{Taylor \& Francis}},
  issn = {15372731},
  doi = {10.1080/00031305.2018.1549100},
  abstract = {The usual definition of R2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian fits, as the numerator can be larger than the denominator. We propose an alternative definition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the expected variance of the errors.},
  annotation = {ZSCC: 0000242},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\MG67EWR4\\R-squared for Bayesian Regression Models.pdf},
  journal = {American Statistician},
  keywords = {Bayesian methods,R-squared,Regression},
  number = {3}
}

@article{Geman1984Stochastic,
  ids = {geman1984stochastic},
  title = {Stochastic Relaxation, {{Gibbs}} Distributions, and the {{Bayesian}} Restoration of Images},
  author = {Geman, Stuart and Geman, Donald},
  year = {1984},
  volume = {6},
  pages = {721--741},
  publisher = {{IEEE}},
  doi = {10.1109/tpami.1984.4767596},
  annotation = {ZSCC: 0025080},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Geman_Geman_1984_Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\G9YJ32MT\\4767596.html},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {Additive noise,Annealing,Bayesian methods,Deformable models,Degradation,Energy states,Gibbs distribution,image restoration,Image restoration,line process,MAP estimate,Markov random field,Markov random fields,relaxation,scene modeling,spatial degradation,Stochastic processes,Temperature distribution},
  number = {6},
  owner = {zcao},
  timestamp = {2017.10.27}
}

@article{Gilmour1997Accounting,
  title = {Accounting for Natural and Extraneous Variation in the Analysis of Field Experiments},
  author = {Gilmour, Arthur R. and Cullis, Brian R. and Verbyla, Arunas P.},
  year = {1997},
  volume = {2},
  pages = {269--293},
  issn = {10857117},
  doi = {10.2307/1400446},
  abstract = {We identify three major components of spatial variation in plot errors from field experiments and extend the two-dimensional spatial procedures of Cullis and Gleeson (1991) to account for them. The components are nonstationary, large-scale (global) variation across the field, stationary variation within the trial (natural variation or local trend), and extraneous variation that is often induced by experimental procedures and is predominantly aligned with rows and columns. We present a strategy for identifying a model for the plot errors that uses a trellis plot of residuals, a perspective plot of the sample variogram and, where possible, likelihood ratio tests to identify which components are present We demonstrate the strategy using two illustrative examples. We conclude that although there is no one model that adequately fits all field experiments, the separable autoregressive model is dominant. However, there is often additional identifiable variation present.},
  annotation = {ZSCC: 0000641},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Gilmour et al_1997_Accounting for natural and extraneous variation in the analysis of field.pdf},
  journal = {Journal of Agricultural, Biological, and Environmental Statistics},
  keywords = {Field experiments,REML,Spatial analysis,Variogram},
  number = {3}
}

@article{Girolami2011Riemann,
  ids = {Girolami2011,girolami2011Riemann,girolami2011riemann},
  title = {Riemann Manifold Langevin and Hamiltonian {{Monte Carlo}} Methods},
  author = {Girolami, Mark and Calderhead, Ben},
  year = {2011},
  volume = {73},
  pages = {123--214},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/j.1467-9868.2010.00765.x},
  annotation = {ZSCC: 0001369},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Girolami_Calderhead_2011_Riemann manifold langevin and hamiltonian monte carlo methods.pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {Bayesian inference,Geometry in statistics,Hamiltonian Monte Carlo methods,Langevin diffusion,Markov chain Monte Carlo methods,Riemann manifolds},
  number = {2}
}

@article{Gneiting2002Nonseparable,
  title = {Nonseparable, {{Stationary Covariance Functions}} for {{Space}}\textendash{{Time Data}}},
  author = {Gneiting, Tilmann},
  year = {2002},
  month = jun,
  volume = {97},
  pages = {590--600},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1198/016214502760047113},
  abstract = {Geostatistical approaches to spatiotemporal prediction in environmental science, climatology, meteorology, and related fields rely on appropriate covariance models. This article proposes general classes of nonseparable, stationary covariance functions for spatiotemporal random processes. The constructions are directly in the space\textendash time domain and do not depend on closed-form Fourier inversions. The model parameters can be associated with the data's spatial and temporal structures, respectively; and a covariance model with a readily interpretable space\textendash time interaction parameter is fitted to wind data from Ireland.},
  annotation = {ZSCC: 0000741  \_eprint: https://doi.org/10.1198/016214502760047113},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Gneiting_2002_Nonseparable, Stationary Covariance Functions for Space–Time Data2.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\UPFYYEE7\\016214502760047113.html},
  journal = {Journal of the American Statistical Association},
  keywords = {Completely monotone,Correlation function,Geostatistics,Kriging,Positive definite,Separable,Spatiotemporal},
  number = {458}
}

@article{Gollini2015GWmodel,
  title = {{{GWmodel}}: {{An R Package}} for {{Exploring Spatial Heterogeneity Using Geographically Weighted Models}}},
  shorttitle = {{{GWmodel}}},
  author = {Gollini, Isabella and Lu, Binbin and Charlton, Martin and Brunsdon, Christopher and Harris, Paul},
  year = {2015},
  month = feb,
  volume = {63},
  pages = {1--50},
  issn = {1548-7660},
  doi = {10.18637/jss.v063.i17},
  annotation = {ZSCC: NoCitationData[s0]},
  copyright = {Copyright (c) 2013 Isabella Gollini, Binbin Lu, Martin Charlton, Christopher Brunsdon, Paul Harris},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Gollini et al_2015_GWmodel.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\FUP5VNZ2\\v063i17.html},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{Griffin2008Spatial,
  title = {Spatial Analysis of Yield Monitor Data: {{Case}} Studies of on-Farm Trials and Farm Management Decision Making},
  author = {Griffin, Terry W. and Dobbins, Craig L. and Vyn, Tony J. and Florax, Raymond J.G.M. G M and {Lowenberg-Deboer}, James M.},
  year = {2008},
  volume = {9},
  pages = {269--283},
  issn = {13852256},
  doi = {10.1007/s11119-008-9072-2},
  abstract = {A 3-year case study was undertaken of how North American farmers use yield monitors for on-farm trials in farm management decision making. Case study methods were used because relatively few farmers quantitatively analyze yield monitor data. At this early research stage, insufficient farm management information about the data was available to ask the right questions in a large-scale survey. In addition to the formal case study of farmers experienced at using yield monitors to collect on-farm trial data, the study evaluated the effect of yield monitor data quality on farm decisions. Two levels of yield data quality included standard output where the default settings of farm-level mapping software were accepted and where filtering of the data was undertaken. Results indicated that yield data quality affects farm management decisions. In addition, farmers receiving a spatial analysis of their on-farm trial data tended to use split-field designs instead of replicated split-planter designs. They were also more confident in their decisions than before participation in the spatial analysis project, and made decisions more quickly. \textcopyright 2008 Springer Science+Business Media, LLC.},
  annotation = {ZSCC: 0000055},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Griffin et al_2008_Spatial analysis of yield monitor data.pdf},
  journal = {Precis. Agric.},
  keywords = {Data quality,Decision-making,On-farm testing,Spatial analysis,Yield monitor}
}

@article{Guan2017Estimation,
  title = {Estimation of Genetic Parameters for Growth Trait of Turbot Using {{Bayesian}} and {{REML}} Approaches},
  author = {Guan, Jiantao and Wang, Weiji and Hu, Yulong and Wang, Mosang and Tian, Tao and Kong, Jie},
  year = {2017},
  month = jun,
  volume = {36},
  pages = {47--51},
  issn = {0253-505X, 1869-1099},
  doi = {10.1007/s13131-017-1034-y},
  abstract = {Bayesian and restricted maximum likelihood (REML) approaches were used to estimate the genetic parameters in a cultured turbot Scophthalmus maximus stock. The data set consisted of harvest body weight from 2 462 progenies (17 months old) from 28 families that were produced through artificial insemination using 39 parent fish. An animal model was applied to partition each weight value into a fixed effect, an additive genetic effect, and a residual effect. The average body weight of each family, which was measured at 110 days post-hatching, was considered as a covariate. For Bayesian analysis, heritability and breeding values were estimated using both the posterior mean and mode from the joint posterior conditional distribution. The results revealed that for additive genetic variance, the posterior mean estimate ({$\frac{3}{4}$}a2 =9 320) was highest but with the smallest residual variance, REML estimates ({$\frac{3}{4}$}a2 =8 088) came second and the posterior mode estimate ({$\frac{3}{4}$}a2 =7 849) was lowest. The corresponding three heritability estimates followed the same trend as additive genetic variance and they were all high. The Pearson correlations between each pair of the three estimates of breeding values were all high, particularly that between the posterior mean and REML estimates (0.996 9). These results reveal that the differences between Bayesian and REML methods in terms of estimation of heritability and breeding values were small. This study provides another feasible method of genetic parameter estimation in selective breeding programs of turbot.},
  annotation = {ZSCC: 0000004},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\DKEGH7RQ\\Guan et al. - 2017 - Estimation of genetic parameters for growth trait .pdf},
  journal = {Acta Oceanol. Sin.},
  language = {en},
  number = {6}
}

@article{Guttman1967Use,
  title = {The {{Use}} of the {{Concept}} of a {{Future Observation}} in {{Goodness}}-{{Of}}-{{Fit Problems}}},
  author = {Guttman, Irwin},
  year = {1967},
  volume = {29},
  pages = {83--100},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1967.tb00676.x},
  abstract = {An attack on the problem of goodness of fit is made by combining a Bayesian and sampling argument; the Bayesian part is effected by using the distribution of a future observation, while the sampling argument concerns itself with the distribution of a ``chi-squared like'' statistic, which measures discrepancies of observed frequencies from those predicted by the distribution of the future observation. Examples are given for the case of sampling from the binomial, Poisson and normal distributions. An interesting application arising from the above approach is a procedure for estimating the degree of a polynomial response function.},
  annotation = {ZSCC: 0000248  \_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1967.tb00676.x},
  copyright = {\textcopyright{} 1967 The Authors},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\39JHU33D\\j.2517-6161.1967.tb00676.html},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  language = {en},
  number = {1}
}

@article{Harris2019Simulation,
  title = {A {{Simulation Study}} on {{Specifying}} a {{Regression Model}} for {{Spatial Data}}: {{Choosing}} between {{Autocorrelation}} and {{Heterogeneity Effects}}},
  shorttitle = {A {{Simulation Study}} on {{Specifying}} a {{Regression Model}} for {{Spatial Data}}},
  author = {Harris, Paul},
  year = {2019},
  volume = {51},
  pages = {151--181},
  issn = {1538-4632},
  doi = {10.1111/gean.12163},
  abstract = {In this simulation study, regressions specified with autocorrelation effects are compared against those with relationship heterogeneity effects, and in doing so, provides guidance on their use. Regressions investigated are: (1) multiple linear regression, (2) a simultaneous autoregressive error model, and (3) geographically weighted regression. The first is nonspatial and acts as a control, the second accounts for stationary spatial autocorrelation via the error term, while the third captures spatial heterogeneity through the modeling of nonstationary relationships between the response and predictor variables. The geostatistical-based simulation experiment generates data and coefficients with known multivariate spatial properties, all within an area-unit spatial setting. Spatial autocorrelation and spatial heterogeneity effects are varied and accounted for. On fitting the regressions, that each have different assumptions and objectives, to very different geographical processes, valuable insights to their likely performance are uncovered. Results objectively confirm an inherent interrelationship between autocorrelation and heterogeneity, that results in an identification problem when choosing one regression over another. Given this, recommendations on the use and implementation of these spatial regressions are suggested, where knowledge of the properties of real study data and the analytical questions being posed are paramount.},
  annotation = {ZSCC: 0000015  \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/gean.12163},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Harris_2019_A Simulation Study on Specifying a Regression Model for Spatial Data.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CY4R78FC\\gean.html},
  journal = {Geographical Analysis},
  language = {en},
  number = {2}
}

@article{Hartman2008Fasta,
  ids = {Hartman2008Fast},
  title = {Fast Kriging of Large Data Sets with {{Gaussian Markov}} Random Fields},
  author = {Hartman, Linda and H{\"o}ssjer, Ola},
  year = {2008},
  volume = {52},
  pages = {2331--2349},
  issn = {01679473},
  doi = {10.1016/j.csda.2007.09.018},
  abstract = {Spatial data sets are analysed in many scientific disciplines. Kriging, i.e. minimum mean squared error linear prediction, is probably the most widely used method of spatial prediction. Computation time and memory requirement can be an obstacle for kriging for data sets with many observations. Calculations are accelerated and memory requirements decreased by using a Gaussian Markov random field on a lattice as an approximation of a Gaussian field. The algorithms are well suited also for nonlattice data when exploiting a bilinear interpolation at nonlattice locations. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Hartman_Hössjer_2008_Fast kriging of large data sets with Gaussian Markov random fields.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\PTYFBUC5\\S0167947307003568.html},
  journal = {Comput. Stat. Data Anal.},
  keywords = {Bilinear interpolation,Markov random field,Nonlattice data,Spatial interpolation},
  number = {5}
}

@article{Hastie1993Local,
  title = {Local {{Regression}}: {{Automatic Kernel Carpentry}}},
  shorttitle = {Local {{Regression}}},
  author = {Hastie, Trevor and Loader, Clive},
  year = {1993},
  volume = {8},
  pages = {120--129},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237},
  abstract = {A kernel smoother is an intuitive estimate of a regression function or conditional expectation; at each point \$x\_0\$ the estimate of \$E(Y\textbackslash mid x\_0)\$ is a weighted mean of the sample \$Y\_i\$, with observations close to \$x\_0\$ receiving the largest weights. Unfortunately this simplicity has flaws. At the boundary of the predictor space, the kernel neighborhood is asymmetric and the estimate may have substantial bias. Bias can be a problem in the interior as well if the predictors are nonuniform or if the regression function has substantial curvature. These problems are particularly severe when the predictors are multidimensional. A variety of kernel modifications have been proposed to provide approximate and asymptotic adjustment for these biases. Such methods generally place substantial restrictions on the regression problems that can be considered; in unfavorable situations, they can perform very poorly. Moreover, the necessary modifications are very difficult to implement in the multidimensional case. Local regression smoothers fit lower-order polynomials in \$x\$ locally at \$x\_0\$, and the estimate of \$f(x\_0)\$ is taken from the fitted polynomial at \$x\_0\$. They automatically, intuitively and simultaneously adjust for both the biases above to the given order and generalize naturally to the multidimensional case. They also provide natural estimates for the derivatives of \$f\$, an approach more attractive than using higher-order kernel functions for the same purpose.},
  annotation = {ZSCC: 0000601},
  journal = {Statistical Science},
  keywords = {❓ Multiple DOI},
  number = {2}
}

@article{Hastings1970Monte,
  ids = {hastings1970monte},
  title = {Monte {{Carlo}} Sampling Methods Using {{Markov}} Chains and Their Applications},
  author = {Hastings, W. Keith},
  year = {1970},
  volume = {57},
  pages = {97--109},
  publisher = {{Biometrika Trust}},
  doi = {10.1093/biomet/57.1.97},
  annotation = {ZSCC: 0016921},
  journal = {Biometrika},
  number = {1},
  owner = {zcao},
  timestamp = {2017.10.23}
}

@book{Hinkelmann2012Design,
  title = {Design and Analysis of Experiments},
  author = {Hinkelmann, Klaus},
  year = {2012},
  volume = {3},
  publisher = {{John Wiley \& Sons, Inc}},
  issn = {0964-1998},
  doi = {10.1002/9781118147634},
  abstract = {Design and Analysis of Experiments, Volume 3: Special Designs and Applications continues building upon the philosophical foundations of experimental design by providing important, modern applications of experimental design to the many fields that utilize them. The book also presents optimal and efficient designs for practice and covers key topics in current statistical research. Featuring contributions from leading researchers and academics, the book demonstrates how the presented concepts are used across various fields from genetics and medicinal and pharmaceutical research to manufacturing, engineering, and national security. Each chapter includes an introduction followed by the historical background as well as in-depth procedures that aid in the construction and analysis of the discussed designs. Topical coverage includes: \textbullet{} Genetic cross experiments, microarray experiments, and variety trials \textbullet{} Clinical trials, group-sequential designs, and adaptive designs \textbullet{} Fractional factorial and search, choice, and optimal designs for generalized linear models \textbullet{} Computer experiments with applications to homeland security \textbullet{} Robust parameter designs and split-plot type response surface designs \textbullet{} Analysis of directional data experiments. Throughout the book, illustrative and numerical examples utilize SAS\textregistered, JMP\textregistered, and R software programs to demonstrate the discussed techniques. Related data sets and software applications are available on the book's related FTP site. Design and Analysis of Experiments, Volume 3 is an ideal textbook for graduate courses in experimental design and also serves as a practical, hands-on reference for statisticians and researchers across a wide array of subject areas, including biological sciences, engineering, medicine, and business.},
  annotation = {ZSCC: 0000071},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Hinkelmann_2012_Design and analysis of experiments.pdf},
  isbn = {978-0-470-53068-9},
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}}
}

@article{Hoef2018Spatial,
  title = {Spatial Autoregressive Models for Statistical Inference from Ecological Data},
  author = {Hoef, Jay M. Ver and Peterson, Erin E. and Hooten, Mevin B. and Hanks, Ephraim M. and Fortin, Marie-Jos{\`e}e},
  year = {2018},
  month = feb,
  volume = {88},
  pages = {36--59},
  issn = {00129615},
  doi = {10.1002/ecm.1283},
  abstract = {Ecological data often exhibit spatial pattern, which can be modeled as autocorrelation. Conditional autoregressive (CAR) and simultaneous autoregressive (SAR) models are network-based models (also known as graphical models) specifically designed to model spatially autocorrelated data based on neighborhood relationships. We identify and discuss six different types of practical ecological inference using CAR and SAR models, including: (1) model selection, (2) spatial regression, (3) estimation of autocorrelation, (4) estimation of other connectivity parameters, (5) spatial prediction, and (6) spatial smoothing. We compare CAR and SAR models, showing their development and connection to partial correlations. Special cases, such as the intrinsic autoregressive model (IAR), are described. Conditional autoregressive and SAR models depend on weight matrices, whose practical development uses neighborhood definition and row-standardization. Weight matrices can also include ecological covariates and connectivity structures, which we emphasize, but have been rarely used. Trends in harbor seals (Phoca vitulina) in southeastern Alaska from 463 polygons, some with missing data, are used to illustrate the six inference types. We develop a variety of weight matrices and CAR and SAR spatial regression models are fit using maximum likelihood and Bayesian methods. Profile likelihood graphs illustrate inference for covariance parameters. The same data set is used for both prediction and smoothing, and the relative merits of each are discussed. We show the nonstationary variances and correlations of a CAR model and demonstrate the effect of row-standardization. We include several take-home messages for CAR and SAR models, including (1) choosing between CAR and IAR models, (2) modeling ecological effects in the covariance matrix, (3) the appeal of spatial smoothing, and (4) how to handle isolated neighbors. We highlight several reasons why ecologists will want to make use of autoregressive models, both directly and in hierarchical models, and not only in explicit spatial settings, but also for more general connectivity models.},
  annotation = {ZSCC: 0000097},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\86EAUYWK\\Spatial autoregressive models for statistical inference from ecological data.pdf},
  journal = {Ecol Monogr},
  language = {en},
  number = {1}
}

@article{Hoffman2014NoUTurn,
  ids = {Hoffman2014NoUturn},
  title = {The {{No}}-{{U}}-{{Turn}} Sampler: Adaptively Setting Path Lengths in {{Hamiltonian Monte Carlo}}.},
  shorttitle = {The {{No}}-{{U}}-{{Turn}} Sampler},
  author = {Hoffman, Matthew D. and Gelman, Andrew},
  year = {2014},
  volume = {15},
  pages = {1593--1623},
  annotation = {ZSCC: 0002560},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Hoffman_Gelman_2014_The No-U-Turn sampler.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Homan_Gelman_2014_The No-U-turn sampler.pdf},
  journal = {J. Mach. Learn. Res.},
  keywords = {⛔ No DOI found,adaptive Monte Carlo,Bayesian inference,dual averaging,Hamiltonian Monte Carlo,Markov chain Monte Carlo},
  number = {1}
}

@article{Hong2005Spatial,
  title = {Spatial Analysis of Precision Agriculture Treatments in Randomized Complete Blocks: {{Guidelines}} for Covariance Model Selection},
  author = {Hong, Nan and White, Jeffrey G. and Gumpertz, Marcia L. and Weisz, Randy},
  year = {2005},
  volume = {97},
  pages = {1082--1096},
  issn = {0002-1962},
  doi = {10.2134/agronj2004.0130},
  abstract = {Failure to account for spatially correlated errors when present in the classical randomized complete block (RCB) analysis may cause inefficient estimation of treatment significance. Covariance model selection is a necessary component for spatial adjustment to estimate treatment significance. We discuss methods for selecting a covariance model in RCB analyses in the presence of spatial correlation and demonstrate one procedure in detail. The procedure uses three models: the randomized complete block with independent and identically distributed errors (RCBiid), RCB with correlated errors, and models with correlated errors but no block effects. The semivariogram of the residuals from fitting a model with just fixed effects, the likelihood ratio test, and Akaike Information Criterion are used for model selection. To illustrate the procedure, we analyzed winter wheat (Triticum aestivum L.) forage and corn (Zea mays L.) grain yield in the presence of spatial heterogeneity within blocks from a site-specific N management study. We compared the selected covariance models to the RCBiid models and to other spatial models with respect to the estimation of treatment significance. The procedure can be extended to any experiment with fixed effects, or with both fixed and random effects, and which may potentially have spatially correlated errors. The procedure is systematic and readily implemented; however, it remains difficult to evaluate whether an adequate covariance model has been selected.},
  annotation = {ZSCC: 0000038},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Hong et al_2005_Spatial analysis of precision agriculture treatments in randomized complete.pdf},
  journal = {Agronomy Journal},
  number = {4}
}

@article{Hurley2004Estimating,
  title = {Estimating Site-Specific Nitrogen Crop Response Functions: {{A}} Conceptual Framework and Geostatistical Model},
  author = {Hurley, T. M. and Malzer, G. L. and Kilian, B.},
  year = {2004},
  volume = {96},
  pages = {1331--1343},
  issn = {00021962},
  doi = {10.2134/agronj2004.1331},
  abstract = {Confirming the precision agriculture hypothesis for variable-rate N applications (VRAs) is challenging. To confront this challenge, researchers have used increasingly sophisticated statistical models to estimate and compare site-specific crop response functions (SSCRFs). While progress has been made, it has been hampered by the lack of a conceptual framework to guide the development of appropriate statistical models. This paper provides such a framework and demonstrates its utility by developing a heteroscedastic, fixed and random effects, geostatistical model to test if VRA can increase N returns. The novelty of the model is the inclusion of site, spatial, treatment, and treatment strip heteroscedasticity and correlation. Applied to data collected in 1995 from two corn (Zea mays L.) N response experiments in south-central Minnesota, results demonstrate the importance of including site, spatial, treatment, and treatment strip effects in the estimation of SSCRFs. Results also indicate a significant potential for VRA to increase N returns and that these potential returns increase as the area of the management unit decreases. At one location, there was greater than a 95\% chance that VRA could have increased profitability if the cost of implementing VRA was less than \$14.5 ha -1. At the other location, if implementation costs were less than \$48.3 ha-1, there was greater than a 95\% chance of increased profitability.},
  annotation = {ZSCC: 0000063},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Hurley et al_2004_Estimating site-specific nitrogen crop response functions.pdf},
  journal = {Agronomy Journal},
  number = {5}
}

@article{Jadaliha2018Fully,
  title = {Fully {{Bayesian Prediction Algorithms}} for {{Mobile Robotic Sensors}} under {{Uncertain Localization Using Gaussian Markov Random Fields}}},
  author = {Jadaliha, Mahdi and Jeong, Jinho and Xu, Yunfei and Choi, Jongeun and Kim, Junghoon},
  year = {2018},
  month = aug,
  volume = {18},
  issn = {1424-8220},
  doi = {10.3390/s18092866},
  abstract = {In this paper, we present algorithms for predicting a spatio-temporal random field measured by mobile robotic sensors under uncertainties in localization and measurements. The spatio-temporal field of interest is modeled by a sum of a time-varying mean function and a Gaussian Markov random field (GMRF) with unknown hyperparameters. We first derive the exact Bayesian solution to the problem of computing the predictive inference of the random field, taking into account observations, uncertain hyperparameters, measurement noise, and uncertain localization in a fully Bayesian point of view. We show that the exact solution for uncertain localization is not scalable as the number of observations increases. To cope with this exponentially increasing complexity and to be usable for mobile sensor networks with limited resources, we propose a scalable approximation with a controllable trade-off between approximation error and complexity to the exact solution. The effectiveness of the proposed algorithms is demonstrated by simulation and experimental results.},
  annotation = {ZSCC: 0000001},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Jadaliha et al_2018_Fully Bayesian Prediction Algorithms for Mobile Robotic Sensors under Uncertain.pdf},
  journal = {Sensors (Basel)},
  number = {9},
  pmcid = {PMC6164902},
  pmid = {30200257}
}

@article{Jiang2009Bayesian,
  title = {Bayesian Analysis of Within-Field Variability of Corn Yield Using a Spatial Hierarchical Model},
  author = {Jiang, Pingping and He, Zhuoqiong and Kitchen, Newell R. and Sudduth, Kenneth A.},
  year = {2009},
  month = apr,
  volume = {10},
  pages = {111--127},
  issn = {1573-1618},
  doi = {10.1007/s11119-008-9070-4},
  abstract = {Understanding relationships of soil and field topography to crop yield within a field is critical in site-specific management systems. Challenges for efficiently assessing these relationships include spatially correlated yield data and interrelated soil and topographic properties. The objective of this analysis was to apply a spatial Bayesian hierarchical model to examine the effects of soil, topographic and climate variables on corn yield. The model included a mean structure of spatial and temporal co-variates and an explicit random spatial effect. The spatial co-variates included elevation, slope and apparent soil electrical conductivity, temporal co-variates included mean maximum daily temperature, mean daily temperature range and cumulative precipitation in July and August. A conditional auto-regressive (CAR) model was used to model the spatial association in yield. Mapped corn yield data from 1997, 1999, 2001 and 2003 for a 36-ha Missouri claypan soil field were used in the analysis. The model building and computation were performed using a free Bayesian modeling software package, WinBUGS. The relationships of co-variates to corn yield generally agreed with the literature. The CAR model successfully captured the spatial association in yield. Model standard deviation decreased about 50\% with spatial effect accounted for. Further, the approach was able to assess the effects of temporal climate co-variates on corn yield with a small number of site-years. The spatial Bayesian model appeared to be a useful tool to gain insights into yield spatial and temporal variability related to soil, topography and growing season weather conditions.},
  annotation = {ZSCC: 0000015},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Jiang et al_2009_Bayesian analysis of within-field variability of corn yield using a spatial.pdf},
  journal = {Precision Agric},
  language = {en},
  number = {2}
}

@article{Jin2021Efficient,
  title = {An Efficient Geostatistical Analysis Tool for On-Farm Experiments Targeted at Localised Treatment},
  author = {Jin, Huidong and Shuvo Bakar, K. and Henderson, Brent L. and Bramley, Robert G. V. and Gobbett, David L.},
  year = {2021},
  month = may,
  volume = {205},
  pages = {121--136},
  issn = {1537-5110},
  doi = {10.1016/j.biosystemseng.2021.02.009},
  abstract = {On farm experimentation (OFE) has been a long-standing method for farmers to assess alternative management at scales relevant to their farming practices. Through the use of spatially distributed designs, whether simple strips or other `whole-of-block' trials, OFE can provide information such as which treatment should be recommended at specific locations, and make important contributions to precision agriculture. However, when treatment response data sets become large, such as with tens of thousands of field observations that are readily collected using on-the-go sensors, existing geostatistical systems for analysing such experiments become computationally intensive, if not impossible. To enable farmers, or their consultants, to generate high-resolution treatment response and recommendation maps on their own computers within a reasonable time, we present a fast and adaptive local cokriging tool for non-colocated and non-stationary OFE data. It uses a spatially-varying neighbourhood radius. It has a graphical user interface accessible via QGIS, a free and open source software. The adaptive local cokriging is demonstrated on three OFE examples. It performs indistinguishably from global cokriging on a small data set, but for large data sets, for which global cokriging is impractical, it predicts significantly more accurately than spatial splines or sampling-based cokriging. It outperforms cokriging base on a fixed number of nearest neighbours when this fixed number is not carefully chosen.},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Jin et al_2021_An efficient geostatistical analysis tool for on-farm experiments targeted at.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\D6697ER9\\S1537511021000453.html},
  journal = {Biosystems Engineering},
  keywords = {Cokriging,Multivariate analysis tool,On-farm experimentation,Precision agriculture},
  language = {en}
}

@article{Juarez2010ModelBased,
  title = {Model-{{Based Clustering}} of {{Non}}-{{Gaussian Panel Data Based}} on {{Skew}}-t {{Distributions}}},
  author = {Ju{\'a}rez, Miguel A. and Steel, Mark F. J.},
  year = {2010},
  month = jan,
  volume = {28},
  pages = {52--66},
  issn = {0735-0015, 1537-2707},
  doi = {10.1198/jbes.2009.07145},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CVFIFKXK\\jbes.2009.pdf},
  journal = {Journal of Business \& Economic Statistics},
  language = {en},
  number = {1}
}

@article{Kass2006Default,
  title = {A Default Conjugate Prior for Variance Components in Generalized Linear Mixed Models ({{Comment}} on {{Article}} by {{Browne}} and {{Draper}})},
  author = {Kass, Robert E. and Natarajan, Ranjini},
  year = {2006},
  volume = {1},
  pages = {535--542},
  issn = {19360975},
  doi = {10.1214/06-ba117b},
  abstract = {For a scalar random-effect variance, Browne and Draper (2005) have found that the uniform prior works well. It would be valuable to know more about the vector case, in which a second-stage prior on the random effects variance matrix D is needed. We suggest consideration of an inverse Wishart prior for D where the scale matrix is determined from the first-stage variance. \textcopyright{} 2006 International Society for Bayesian Analysis ba0003.},
  annotation = {ZSCC: 0000073},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Kass_Natarajan_2006_A default conjugate prior for variance components in generalized linear mixed.pdf},
  journal = {Bayesian Analysis},
  keywords = {Choice of prior,Hierarchical models,Noninformative priors,Random effects},
  number = {3}
}

@article{Khaki2020CNNRNN,
  title = {A {{CNN}}-{{RNN Framework}} for {{Crop Yield Prediction}}},
  author = {Khaki, Saeed and Wang, Lizhi and Archontoulis, Sotirios V.},
  year = {2020},
  volume = {10},
  publisher = {{Frontiers}},
  issn = {1664-462X},
  doi = {10.3389/fpls.2019.01750},
  abstract = {Crop yield prediction is extremely challenging due to its dependence on multiple factors such as crop genotype, environmental factors, management practices, and their interactions. This paper presents a deep learning framework using convolutional neural networks (CNN) and recurrent neural networks (RNN) for crop yield prediction based on environmental data and management practices. The proposed CNN-RNN model, along with other popular methods such as random forest (RF), deep fully-connected neural networks (DFNN), and LASSO, was used to forecast corn and soybean yield across the entire Corn Belt (including 13 states) in the United States for years 2016, 2017, and 2018 using historical data. The new model achieved a root-mean-square-error (RMSE) 9\textbackslash\% and 8\textbackslash\% of their respective average yields, substantially outperforming all other methods that were tested. The CNN-RNN have three salient features that make it a potentially useful method for other crop yield prediction studies. (1) The CNN-RNN model was designed to capture the time dependencies of environmental factors and the genetic improvement of seeds over time without having their genotype information. (2) The model demonstrated the capability to generalize the yield prediction to untested environments without significant drop in the prediction accuracy. (3) Coupled with the backpropagation method, the model could reveal the extent to which weather conditions, accuracy of weather predictions, soil conditions, and management practices were able to explain the variation in the crop yields.},
  annotation = {ZSCC: 0000012},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Khaki et al_2020_A CNN-RNN Framework for Crop Yield Prediction.pdf},
  journal = {Front. Plant Sci.},
  keywords = {Convolutional Neural Networks,Crop yield prediction,deep learning,Feature Selection,recurrent neural networks},
  language = {English}
}

@article{Lado2013Increased,
  title = {Increased {{Genomic Prediction Accuracy}} in {{Wheat Breeding Through Spatial Adjustment}} of {{Field Trial Data}}},
  author = {Lado, Bettina and Matus, Ivan and Rodr{\'i}guez, Alejandra and Inostroza, Luis and Poland, Jesse and Belzile, Fran{\c c}ois and {del Pozo}, Alejandro and Quincke, Mart{\'i}n and Castro, Marina and {von Zitzewitz}, Jarislav},
  year = {2013},
  month = sep,
  volume = {3},
  pages = {2105--2114},
  issn = {2160-1836},
  doi = {10.1534/g3.113.007807},
  abstract = {In crop breeding, the interest of predicting the performance of candidate cultivars in the field has increased due to recent advances in molecular breeding technologies. However, the complexity of the wheat genome presents some challenges for applying new technologies in molecular marker identification with next-generation sequencing. We applied genotyping-by-sequencing, a recently developed method to identify single-nucleotide polymorphisms, in the genomes of 384 wheat (Triticum aestivum) genotypes that were field tested under three different water regimes in Mediterranean climatic conditions: rain-fed only, mild water stress, and fully irrigated. We identified 102,324 single-nucleotide polymorphisms in these genotypes, and the phenotypic data were used to train and test genomic selection models intended to predict yield, thousand-kernel weight, number of kernels per spike, and heading date. Phenotypic data showed marked spatial variation. Therefore, different models were tested to correct the trends observed in the field. A mixed-model using moving-means as a covariate was found to best fit the data. When we applied the genomic selection models, the accuracy of predicted traits increased with spatial adjustment. Multiple genomic selection models were tested, and a Gaussian kernel model was determined to give the highest accuracy. The best predictions between environments were obtained when data from different years were used to train the model. Our results confirm that genotyping-by-sequencing is an effective tool to obtain genome-wide information for crops with complex genomes, that these data are efficient for predicting traits, and that correction of spatial variation is a crucial ingredient to increase prediction accuracy in genomic selection models.},
  annotation = {ZSCC: 0000085},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Lado et al_2013_Increased Genomic Prediction Accuracy in Wheat Breeding Through Spatial.pdf},
  journal = {G3 (Bethesda)},
  number = {12},
  pmcid = {PMC3852373},
  pmid = {24082033}
}

@book{Lanczos1950Iteration,
  title = {An Iteration Method for the Solution of the Eigenvalue Problem of Linear Differential and Integral Operators},
  author = {Lanczos, Cornelius},
  year = {1950},
  publisher = {{United States Governm. Press Office Los Angeles, CA}},
  annotation = {ZSCC: 0005007},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Lanczos_1950_An iteration method for the solution of the eigenvalue problem of linear.pdf}
}

@article{Lark2003Methoda,
  title = {A {{Method}} to {{Investigate Within}}-{{Field Variation}} of the {{Response}} of {{Combinable Crops}} to an {{Input}}},
  author = {Lark, R. and Wheeler, H.},
  year = {2003},
  volume = {95},
  pages = {1093--1104},
  doi = {10.2134/AGRONJ2003.1093},
  abstract = {Precision agriculture is based on the hypothesis that the optimum rate of inputs to a crop varies spatially within fields. Evidence for this hypothesis is scarce due to the practical and theoretical difficulties of designing appropriate experiments. This paper proposes a procedure for testing the hypothesis of precision agriculture for crops that may be harvested with a combine harvester equipped with a yield monitor. An input is applied according to a randomized block design. Yield monitor data may be treated as a convolution of yield with a function that characterizes the smoothing effect of processes in the combine on the mass flow rate at the sensor. The input rates, determined by the experimental design, are transformed using the combine's smoothing function and a preselected yield response function. The parameters of the response function for the whole field or a local neighborhood can be estimated from these transformed rates and the yield monitor data. A null hypothesis, that the spatial variation in one of these parameters (that determines the local optimum rate) may be attributed to random yield variation about a uniform response function, may be tested. A wheat crop (Triticum aestivum cv. Consort) was treated with varying rates of N fertilizer in a case study in the south of England. Analysis of the yield data showed that the observed variation in the response could not be explained as random fluctuation around the field-scale response function. The economic optimum rate of N varied from zero to greater than 200 kg ha -1 .},
  annotation = {ZSCC: 0000054},
  journal = {Agronomy Journal},
  language = {English}
}

@article{Lawes2012Simple,
  title = {A {{Simple Method}} for the {{Analysis}} of {{On}}-{{Farm Strip Trials}}},
  author = {Lawes, R. A. and Bramley, R. G. V.},
  year = {2012},
  volume = {104},
  pages = {371--377},
  issn = {1435-0645},
  doi = {10.2134/agronj2011.0155},
  abstract = {The design and analysis of experiments in farmers' fields using commercial yield monitoring equipment has received considerable attention in the last decade. Complex design and analytical techniques have been developed to maximize the utility of the trial to the producer while retaining the potential for robust statistical analysis. However, implementation of such approaches requires access to specialists in spatial analysis, geostatistics, and geographic information systems (GIS) and so is rarely implemented by farmers and their advisors. Here we explore a new and simple approach to the analysis of farmer strip trials and the spatial variability of treatment response. Strip trials evaluating different fertilizer treatments were conducted in farmers' fields in South Australia and Western Australia. Yield data were subjected to analysis with a linear model that accounted for the spatial autocorrelation in the data, a linear model that did not account for the spatial correlation and a moving pairwise comparison of treatments. Results suggest the pairwise comparison adequately identified treatment differences and their significance. Since this method can be readily implemented in a simple spreadsheet, it offers an important advance in facilitating on-farm experimentation using precision agriculture technologies.},
  annotation = {ZSCC: 0000044  \_eprint: https://acsess.onlinelibrary.wiley.com/doi/pdf/10.2134/agronj2011.0155},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Lawes_Bramley_2012_A Simple Method for the Analysis of On-Farm Strip Trials.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\3HZJNJWC\\agronj2011.html},
  journal = {Agronomy Journal},
  language = {English},
  number = {2}
}

@book{Lawson2013Statistical,
  title = {Statistical {{Methods}} in {{Spatial Epidemiology}}},
  author = {Lawson, Andrew B.},
  year = {2013},
  publisher = {{John Wiley \& Sons}},
  annotation = {ZSCC: 0000846},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\BS2WWKGS\\books.html},
  isbn = {978-0-470-01484-4}
}

@article{Lee2019Bayesian,
  title = {Bayesian {{Inference}} for {{Mixed Model}}-{{Based Genome}}-{{Wide Analysis}} of {{Expression Quantitative Trait Loci}} by {{Gibbs Sampling}}},
  author = {Lee, Chaeyoung},
  year = {2019},
  volume = {10},
  publisher = {{Frontiers}},
  issn = {1664-8021},
  doi = {10.3389/fgene.2019.00199},
  abstract = {The importance of expression quantitative trait locus (eQTL) has been emphasized in understanding the genetic basis of cellular activities and complex phenotypes. Mixed models can be employed to effectively identify eQTLs by explaining polygenic effects. In the mixed models, the polygenic effects are considered random variables in the mixed models, and their variability is explained by the polygenic variance component. The polygenic and residual variance components are first estimated, and then eQTL effects are estimated depending on the variance component estimates within the frequentist mixed model framework. Also, the Bayesian approach to the mixed model-based genomewide eQTL analysis can be applied to estimating the parameters exhibiting various benefits. Bayesian inferences on the unknown parameters are based on their marginal posterior distributions, and the marginalization of the joint posterior distribution is a challenging task. This problem can be solved by employing a numerical algorithm of integrals called Gibbs sampling as a Markov chain Monte Carlo. This article reviews the mixed model-based Bayesian eQTL analysis by Gibbs sampling. Theoretical and practical issues of Bayesian inference are discussed using a concise description of Bayesian modelling and the corresponding Gibbs sampling. The strengths of Bayesian inference are also discussed. Posterior probability distribution in the Bayesian inference reflects uncertainty in unknown parameters, and this factor is useful in the context of eQTL analysis where a sample size is too small to apply the frequentist approach. Bayesian inference based on the posterior that reflects prior knowledge will be increasingly preferred with accumulation of eQTL data. Extensive use of the mixed model-based Bayesian eQTL analysis will accelerate understanding of eQTLs exhibiting various regulatory functions.},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Lee_2019_Bayesian Inference for Mixed Model-Based Genome-Wide Analysis of Expression.pdf},
  journal = {Front. Genet.},
  keywords = {expression quantitative trait locus,Genetic association,gibbs sampling,Markov chain Monte Carlo,Mixed model,polygenic variance component,Posterior,Random effect},
  language = {English}
}

@article{Leong2017Modification,
  title = {A Modification to Geographically Weighted Regression},
  author = {Leong, Yin Yee and Yue, Jack C.},
  year = {2017},
  volume = {16},
  pages = {1--18},
  publisher = {{BioMed Central}},
  issn = {1476072X},
  doi = {10.1186/s12942-017-0085-9},
  abstract = {Background: Geographically weighted regression (GWR) is a modelling technique designed to deal with spatial non-stationarity, e.g., the mean values vary by locations. It has been widely used as a visualization tool to explore the patterns of spatial data. However, the GWR tends to produce unsmooth surfaces when the mean parameters have considerable variations, partly due to that all parameter estimates are derived from a fixed- range (bandwidth) of observations. In order to deal with the varying bandwidth problem, this paper proposes an alternative approach, namely Conditional geographically weighted regression (CGWR). Methods: The estimation of CGWR is based on an iterative procedure, analogy to the numerical optimization problem. Computer simulation, under realistic settings, is used to compare the performance between the traditional GWR, CGWR, and a local linear modification of GWR. Furthermore, this study also applies the CGWR to two empirical datasets for evaluating the model performance. The first dataset consists of disability status of Taiwan's elderly, along with some social-economic variables and the other is Ohio's crime dataset. Results: Under the positively correlated scenario, we found that the CGWR produces a better fit for the response surface. Both the computer simulation and empirical analysis support the proposed approach since it significantly reduces the bias and variance of data fitting. In addition, the response surface from the CGWR reviews local spatial characteristics according to the corresponded variables. Conclusions: As an explanatory tool for spatial data, producing accurate surface is essential in order to provide a first look at the data. Any distorted outcomes would likely mislead the following analysis. Since the CGWR can generate more accurate surface, it is more appropriate to use it exploring data that contain suspicious variables with varying characteristics.},
  annotation = {ZSCC: 0000034},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Leong_Yue_2017_A modification to geographically weighted regression.pdf},
  isbn = {1294201700},
  journal = {International Journal of Health Geographics},
  keywords = {Computer simulation,Cross validation,Generalized additive model,Geographically weighted regression,Modifiable areal unit problem (MAUP)},
  number = {1}
}

@article{Leung2000Statistical,
  title = {Statistical {{Tests}} for {{Spatial Nonstationarity Based}} on the {{Geographically Weighted Regression Model}}},
  author = {Leung, Yee and Mei, Chang-Lin and Zhang, Wen-Xiu},
  year = {2000},
  month = jan,
  volume = {32},
  pages = {9--32},
  publisher = {{SAGE Publications Ltd}},
  issn = {0308-518X},
  doi = {10.1068/a3162},
  abstract = {Geographically weighted regression (GWR) is a way of exploring spatial nonstationarity by calibrating a multiple regression model which allows different relationships to exist at different points in space. Nevertheless, formal testing procedures for spatial nonstationarity have not been developed since the inception of the model. In this paper the authors focus mainly on the development of statistical testing methods relating to this model. Some appropriate statistics for testing the goodness of fit of the GWR model and for testing variation of the parameters in the model are proposed and their approximated distributions are investigated. The work makes it possible to test spatial nonstationarity in a conventional statistical manner. To substantiate the theoretical arguments, some simulations are run to examine the power of the statistics for exploring spatial nonstationarity and the results are encouraging. To streamline the model, a stepwise procedure for choosing important independent variables is also formulated. In the last section, a prediction problem based on the GWR model is studied, and a confidence interval for the true value of the dependent variable at a new location is also established. The study paves the path for formal analysis of spatial nonstationarity on the basis of the GWR model.},
  annotation = {ZSCC: 0000494},
  journal = {Environ Plan A},
  number = {1}
}

@article{Lin2007Bayesian,
  title = {Bayesian Analysis of Hierarchical Linear Mixed Modeling Using the Multivariate t Distribution},
  author = {Lin, Tsung I. and Lee, Jack C.},
  year = {2007},
  month = feb,
  volume = {137},
  pages = {484--495},
  issn = {0378-3758},
  doi = {10.1016/j.jspi.2005.12.010},
  abstract = {This article presents a fully Bayesian approach to modeling incomplete longitudinal data using the t linear mixed model with AR(p) dependence. Markov chain Monte Carlo (MCMC) techniques are implemented for computing posterior distributions of parameters. To facilitate the computation, two types of auxiliary indicator matrices are incorporated into the model. Meanwhile, the constraints on the parameter space arising from the stationarity conditions for the autoregressive parameters are handled by a reparametrization scheme. Bayesian predictive inferences for the future vector are also investigated. An application is illustrated through a real example from a multiple sclerosis clinical trial.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\REML\\Lin_Lee_2007_Bayesian analysis of hierarchical linear mixed modeling using the multivariate.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\T5NFTBK9\\S0378375806000358.html},
  journal = {Journal of Statistical Planning and Inference},
  keywords = {Autoregressive process,Bayesian prediction,linear mixed models,Markov chain Monte Carlo,Missing values,Random effects},
  language = {en},
  number = {2}
}

@article{Lindgren2011Explicit,
  ids = {Lindgren2011Explicita},
  title = {An Explicit Link between {{Gaussian}} Fields and {{Gaussian Markov}} Random Fields: The Stochastic Partial Differential Equation Approach},
  shorttitle = {An Explicit Link between {{Gaussian}} Fields and {{Gaussian Markov}} Random Fields},
  author = {Lindgren, Finn and Rue, H{\aa}vard and Lindstr{\"o}m, Johan},
  year = {2011},
  volume = {73},
  pages = {423--498},
  issn = {1467-9868},
  doi = {10.1111/j.1467-9868.2011.00777.x},
  abstract = {Summary. Continuously indexed Gaussian fields (GFs) are the most important ingredient in spatial statistical modelling and geostatistics. The specification through the covariance function gives an intuitive interpretation of the field properties. On the computational side, GFs are hampered with the big n problem, since the cost of factorizing dense matrices is cubic in the dimension. Although computational power today is at an all time high, this fact seems still to be a computational bottleneck in many applications. Along with GFs, there is the class of Gaussian Markov random fields (GMRFs) which are discretely indexed. The Markov property makes the precision matrix involved sparse, which enables the use of numerical algorithms for sparse matrices, that for fields in only use the square root of the time required by general algorithms. The specification of a GMRF is through its full conditional distributions but its marginal properties are not transparent in such a parameterization. We show that, using an approximate stochastic weak solution to (linear) stochastic partial differential equations, we can, for some GFs in the Mat\'ern class, provide an explicit link, for any triangulation of , between GFs and GMRFs, formulated as a basis function representation. The consequence is that we can take the best from the two worlds and do the modelling by using GFs but do the computations by using GMRFs. Perhaps more importantly, our approach generalizes to other covariance functions generated by SPDEs, including oscillating and non-stationary GFs, as well as GFs on manifolds. We illustrate our approach by analysing global temperature data with a non-stationary model defined on a sphere.},
  annotation = {ZSCC: 0000002  \_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2011.00777.x},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Lindgren et al_2011_An explicit link between Gaussian fields and Gaussian Markov random fields.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Lindgren et al_2011_An explicit link between Gaussian fields and Gaussian Markov random fields.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\QZWMIGEG\\j.1467-9868.2011.00777.html;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\VFXDGYQR\\j.1467-9868.2011.00777.html},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {Approximate Bayesian inference,Covariance functions,Gaussian fields,Gaussian Markov random fields,Latent Gaussian models,Sparse matrices,Stochastic partial differential equations},
  language = {en},
  number = {4}
}

@article{Loecke2017Weather,
  title = {Weather Whiplash in Agricultural Regions Drives Deterioration of Water Quality},
  author = {Loecke, Terrance D. and Burgin, Amy J. and {Riveros-Iregui}, Diego A. and Ward, Adam S. and Thomas, Steven A. and Davis, Caroline A. and Clair, Martin A. St.},
  year = {2017},
  month = mar,
  volume = {133},
  pages = {7--15},
  issn = {1573-515X},
  doi = {10.1007/s10533-017-0315-z},
  abstract = {Excess nitrogen (N) impairs inland water quality and creates hypoxia in coastal ecosystems. Agriculture is the primary source of N; agricultural management and hydrology together control aquatic ecosystem N loading. Future N loading will be determined by how agriculture and hydrology intersect with climate change, yet the interactions between changing climate and water quality remain poorly understood. Here, we show that changing precipitation patterns, resulting from climate change, interact with agricultural land use to deteriorate water quality. We focus on the 2012\textendash 2013 Midwestern U.S. drought as a ``natural experiment''. The transition from drought conditions in 2012 to a wet spring in 2013 was abrupt; the media dubbed this ``weather whiplash''. We use recent (2010\textendash 2015) and historical data (1950\textendash 2015) to connect weather whiplash (drought-to-flood transitions) to increases in riverine N loads and concentrations. The drought likely created highly N-enriched soils; this excess N mobilized during heavy spring rains (2013), resulting in a 34\% increase (10.5 vs. 7.8~mg~N~L-1) in the flow-weighted mean annual nitrate concentration compared to recent years. Furthermore, we show that climate change will likely intensify weather whiplash. Increased weather whiplash will, in part, increase the frequency of riverine N exceeding E.P.A. drinking water standards. Thus, our observations suggest increased climatic variation will amplify negative trends in water quality in a region already grappling with severe impairments.},
  annotation = {ZSCC: 0000051},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Loecke et al_2017_Weather whiplash in agricultural regions drives deterioration of water quality.pdf},
  journal = {Biogeochemistry},
  language = {en},
  number = {1}
}

@article{Ludwig2020Splinebased,
  title = {On Spline-Based Approaches to Spatial Linear Regression for Geostatistical Data},
  author = {Ludwig, Guilherme and Zhu, Jun and Reyes, Perla and Chen, Chun-Shu and Conley, Shawn P.},
  year = {2020},
  month = jun,
  volume = {27},
  pages = {175--202},
  issn = {1352-8505, 1573-3009},
  doi = {10.1007/s10651-020-00441-9},
  abstract = {For spatial linear regression, the traditional approach to capture spatial dependence is to use a parametric linear mixed-effects model. Spline surfaces can be used as an alternative to capture spatial variability, giving rise to a semiparametric method that does not require the specification of a parametric covariance structure. The spline component in such a semiparametric method, however, impacts the estimation of the regression coefficients. In this paper, we investigate such an impact in spatial linear regression with spline-based spatial effects. Statistical properties of the regression coefficient estimators are established under the model assumptions of the traditional spatial linear regression. Further, we examine the empirical properties of the regression coefficient estimators under spatial confounding via a simulation study. A data example in precision agriculture research regarding soybean yield in relation to field conditions is presented for illustration.},
  annotation = {ZSCC: 0000002},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\YRI9EDIB\\On spline-based approaches to spatial linear regression for geostatistical data.pdf},
  journal = {Environ Ecol Stat},
  language = {en},
  number = {2}
}

@incollection{Luttinen2012Efficient,
  title = {Efficient {{Gaussian Process Inference}} for {{Short}}-{{Scale Spatio}}-{{Temporal Modeling}}},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Luttinen, Jaakko and Ilin, Alexander},
  year = {2012},
  pages = {741--750},
  abstract = {This paper presents an efficient Gaussian process inference scheme for modeling shortscale phenomena in spatio-temporal datasets. Our model uses a sum of separable, compactly supported covariance functions, which yields a full covariance matrix represented in terms of small sparse matrices operating either on the spatial or temporal domain. The proposed inference procedure is based on Gibbs sampling, in which samples from the conditional distribution of the latent function values are obtained by applying a simple linear transformation to samples drawn from the joint distribution of the function values and the observations. We make use of the proposed model structure and the conjugate gradient method to compute the required transformation. In the experimental part, the proposed algorithm is compared to the standard approach using the sparse Cholesky decomposition and it is shown to be much faster and computationally feasible for 100\textendash 1000 times larger datasets. We demonstrate the advantages of the proposed method in the problem of reconstructing sea surface temperature, which requires processing of a real-world dataset with 106 observations.},
  annotation = {ZSCC: 0000030},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\APQLA22A\\Luttinen and Ilin - Eﬃcient Gaussian Process Inference for Short-Scale.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{Ma2019Additive,
  title = {An Additive Approximate {{Gaussian}} Process Model for Large Spatio-Temporal Data},
  author = {Ma, Pulong and Konomi, Bledar A. and Kang, Emily L.},
  year = {2019},
  volume = {30},
  pages = {e2569},
  issn = {1099-095X},
  doi = {10.1002/env.2569},
  abstract = {Motivated by a large ground-level ozone data set, we propose a new computationally efficient additive approximate Gaussian process. The proposed method incorporates a computational-complexity-reduction method and a separable covariance function, which can flexibly capture various spatio-temporal dependence structures. The first component is able to capture nonseparable spatio-temporal variability, whereas the second component captures the separable variation. Based on a hierarchical formulation of the model, we are able to utilize the computational advantages of both components and perform efficient Bayesian inference. To demonstrate the inferential and computational benefits of the proposed method, we carry out extensive simulation studies assuming various scenarios of an underlying spatio-temporal covariance structure. The proposed method is also applied to analyze large spatio-temporal measurements of ground-level ozone in the Eastern United States.},
  annotation = {ZSCC: 0000000  \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/env.2569},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Ma et al_2019_An additive approximate Gaussian process model for large spatio-temporal data.pdf},
  journal = {Environmetrics},
  keywords = {additive model,Bayesian inference,Gaussian process,Metropolis-within-Gibbs sampler,nonseparable covariance function,spatio-temporal data},
  language = {en},
  number = {8}
}

@book{MacKay2003Information,
  ids = {mackay2003information,mackayInformationTheoryInference2003a},
  title = {Information Theory, Inference and Learning Algorithms},
  author = {MacKay, David JC},
  year = {2003},
  publisher = {{Cambridge university press}},
  annotation = {ZSCC: 0011974},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MacKay_Mac Kay_2003_Information theory, inference and learning algorithms.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\6YXA4MTK\\books.html}
}

@article{Madar2015Direct,
  title = {Direct Formulation to {{Cholesky}} Decomposition of a General Nonsingular Correlation Matrix},
  author = {Madar, Vered},
  year = {2015},
  volume = {103},
  pages = {142--147},
  publisher = {{Elsevier B.V.}},
  issn = {01677152},
  doi = {10.1016/j.spl.2015.03.014},
  abstract = {We present two novel and explicit parametrizations of Cholesky factor of a nonsingular correlation matrix. One that uses semi-partial correlation coefficients, and a second that utilizes differences between the successive ratios of two determinants. To each, we offer a useful application.},
  annotation = {ZSCC: 0000017},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Madar_2015_Direct formulation to Cholesky decomposition of a general nonsingular.pdf},
  isbn = {2163684814},
  journal = {Statistics and Probability Letters},
  keywords = {Cholesky factor,Correlation matrix,Generating random correlation matrix,Partial and semi-partial correlation coefficient},
  number = {1},
  pmid = {28363838}
}

@article{Marchant2019Establishinga,
  title = {Establishing the Precision and Robustness of Farmers' Crop Experiments},
  author = {Marchant, Ben and Rudolph, Sebastian and Roques, Susie and Kindred, Daniel and Gillingham, Vincent and Welham, Sue and Coleman, Colin and {Sylvester-Bradley}, Roger},
  year = {2019},
  month = jan,
  volume = {230},
  pages = {31--45},
  issn = {0378-4290},
  doi = {10.1016/j.fcr.2018.10.006},
  abstract = {Precision farming technologies such as global positioning, input placement technologies and on-the-go yield monitoring now provide farmers with the means to conduct their own experiments at scales relevant to their decisions with minimal disruption. However, these experiments are generally incompatible with conventional statistical methods and alternative models of response variables (e.g. yield) must be estimated if the effect of the management decision is to be distinguished from other sources of variation. We explore the precision and robustness of such experiments using four sources of data and experimental designs of different degrees of complexity. We see that there is a trade-off between the precision of the experiment and its complexity and hence implementation cost. In yield experiments with small-grain cereals, standard errors of treatment effects in yield of less than 0.05\,t/ha can potentially be achieved when the treatment is varied along the field traffic row and standard errors of less than 0.1\,t/ha can potentially be achieved when single treatments are applied in each row but the experiment includes multiple disconnected repetitions of each treatment. Simpler split-field designs are less robust since it can be difficult to distinguish treatment effects from independent spatial trends and discontinuities in the response variable. In some instances, the potential precision is not realised because the data include noise or artefacts that are unrelated to crop performance. Further yield sensor developments are required to minimise these occurrences. The model-based statistical analyses of these experiments require assumptions regarding the variation of the response variable. We see that when these assumptions are inappropriate (e.g. if the correlation between response variable measurements is poorly modelled) then the inferences from the experiments can be unreliable. In particular, we see that the spatial correlation amongst yield measurements tends to be greater along the farm traffic row than perpendicular to it. Standard isotropic models of spatial correlation do not accommodate this feature and led to substantial under-estimation of the standard errors.},
  annotation = {ZSCC: 0000017},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Marchant et al_2019_Establishing the precision and robustness of farmers’ crop experiments.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\EVQ6E56X\\S0378429017318312.html},
  journal = {Field Crops Research},
  keywords = {Field-scale trials,Geostatistics,NDVI,Yield monitor},
  language = {en}
}

@article{Mariel2018More,
  title = {A {{More Flexible Model}} or {{Simply More Effort}}? {{On}} the {{Use}} of {{Correlated Random Parameters}} in {{Applied Choice Studies}}},
  shorttitle = {A {{More Flexible Model}} or {{Simply More Effort}}?},
  author = {Mariel, Petr and Meyerhoff, J{\"u}rgen},
  year = {2018},
  month = dec,
  volume = {154},
  pages = {419--429},
  issn = {0921-8009},
  doi = {10.1016/j.ecolecon.2018.08.020},
  abstract = {The random parameter logit model has become the dominating model for analyzing stated choice data in environmental valuation. The unrestricted version of the model with correlated random parameters, however, is rarely applied. An important advantage of this specification is that the correlations between the parameters are not restricted to zero. These correlations can arise due to a behavioural phenomena or scale heterogeneity. One consequence of this might be that derived willingness-to-pay or to-accept estimates are under- or overestimated, providing decision makers with incorrect estimates. We compare both model specifications using data from a study about farmers' willingness to accept compensation for implementing agri-environmental measures in Brandenburg, Germany. For this data both model specifications - with and without correlated random parameters - provide similar willing-to-accept estimates, but the model with correlations performs better despite the higher number of parameters. As our findings could be case study specific, we want to encourage especially applied researchers to estimate also specifications with correlated random parameters. Applying only models with uncorrelated random parameters can result in biased estimates and thus provide incorrect information to decision makers.},
  annotation = {ZSCC: 0000010},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Mariel_Meyerhoff_2018_A More Flexible Model or Simply More Effort.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\S76LP9IU\\S0921800918306189.html},
  journal = {Ecological Economics},
  keywords = {Agri-environmental measures,Choice experiment,Correlated parameters,Random parameter logit model},
  language = {en}
}

@article{Martinez-Casasnovas2018Use,
  title = {Use of {{Farmer Knowledge}} in the {{Delineation}} of {{Potential Management Zones}} in {{Precision Agriculture}}: {{A Case Study}} in {{Maize}} ({{Zea}} Mays {{L}}.)},
  shorttitle = {Use of {{Farmer Knowledge}} in the {{Delineation}} of {{Potential Management Zones}} in {{Precision Agriculture}}},
  author = {{Mart{\'i}nez-Casasnovas}, Jos{\'e} and Escol{\`a}, Alexandre and Arn{\'o}, Jaume},
  year = {2018},
  month = jun,
  volume = {8},
  pages = {84},
  issn = {2077-0472},
  doi = {10.3390/agriculture8060084},
  abstract = {One of the fields of research in precision agriculture (PA) is the delineation of potential management zones (PMZs, also known as site-specific management zones, or simply management zones). To delineate PMZs, cluster analysis is the main used and recommended methodology. For cluster analysis, mainly yield maps, remote sensing multispectral indices, apparent soil electrical conductivity (ECa), and topography data are used. Nevertheless, there is still no accepted protocol or guidelines for establishing PMZs, and different solutions exist. In addition, the farmer's expert knowledge is not usually taken into account in the delineation process. The objective of the present work was to propose a methodology to delineate potential management zones for differential crop management that expresses the productive potential of the soil within a field. The Management Zone Analyst (MZA) software, which implements a fuzzy c-means algorithm, was used to create different alternatives of PMZ that were validated with yield data in a maize (Zea mays L.) field. The farmers' expert knowledge was then taken into account to improve the resulting PMZs that best fitted to the yield spatial variability pattern. This knowledge was considered highly valuable information that could be also very useful for deciding management actions to be taken to reduce within-field variability.},
  annotation = {ZSCC: NoCitationData[s2]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\WXPXPXDR\\Martínez-Casasnovas et al. - 2018 - Use of Farmer Knowledge in the Delineation of Pote.pdf},
  journal = {Agriculture},
  language = {en},
  number = {6}
}

@book{McElreath2015Statistical,
  title = {Statistical Rethinking: {{A}} Bayesian Course with Examples in {{R}} and Stan},
  author = {McElreath, Richard},
  year = {2015},
  month = dec,
  edition = {First},
  volume = {122},
  publisher = {{CRC Press LLC}},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds readers' knowledge of and confidence in statistical modeling. Reflecting the need for even minor programming in today's model-based statistics, the book pushes readers to perform step-by-step calculations that are usually automated. This unique computational approach ensures that readers understand enough of the details to make reasonable choices and interpretations in their own modeling work. The text presents generalized linear multilevel models from a Bayesian perspective, relying on a simple logical interpretation of Bayesian probability and maximum entropy. It covers from the basics of regression to multilevel models. The author also discusses measurement error, missing data, and Gaussian process models for spatial and network autocorrelation. By using complete R code examples throughout, this book provides a practical foundation for performing statistical inference. Designed for both PhD students and seasoned professionals in the natural and social sciences, it prepares them for more advanced or specialized statistical modeling. Web Resource The book is accompanied by an R package (rethinking) that is available on the author's website and GitHub. The two core functions (map and map2stan) of this package allow a variety of statistical models to be constructed from standard model formulas.},
  annotation = {ZSCC: NoCitationData[s0]},
  isbn = {978-1-4822-5346-7},
  language = {English},
  series = {Chapman and {{Hall}}/{{CRC Texts}} in {{Statistical Science Ser}}.}
}

@article{Metropolis1953Equation,
  ids = {metropolis1953equation},
  title = {Equation of State Calculations by Fast Computing Machines},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  year = {1953},
  volume = {21},
  pages = {1087--1092},
  publisher = {{AIP}},
  doi = {10.1063/1.1699114},
  annotation = {ZSCC: 0042597},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\DSAM39UR\\Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing M.pdf},
  journal = {The Journal of Chemical Physics},
  number = {6},
  owner = {zcao},
  timestamp = {2017.10.23}
}

@article{Moeyaert2017Multilevel,
  title = {Multilevel Modeling of Single-Case Data: {{A}} Comparison of Maximum Likelihood and Bayesian Estimation},
  author = {Moeyaert, Mariola and Rindskopf, David and Onghena, Patrick and Noortgate, Wim Van Den},
  year = {2017},
  volume = {22},
  pages = {760--778},
  issn = {1082989X},
  doi = {10.1037/met0000136},
  abstract = {The focus of this article is to describe Bayesian estimation, including construction of prior distributions, and to compare parameter recovery under the Bayesian framework (using weakly informative priors) and the maximum likelihood (ML) framework in the context of multilevel modeling of single-case experimental data. Bayesian estimation results were found similar to ML estimation results in terms of the treatment effect estimates, regardless of the functional form and degree of information included in the prior specification in the Bayesian framework. In terms of the variance component estimates, both the ML and Bayesian estimation procedures result in biased and less precise variance estimates when the number of participants is small (i.e., 3). By increasing the number of participants to 5 or 7, the relative bias is close to 5\% and more precise estimates are obtained for all approaches, except for the inverse-Wishart prior using the identity matrix. When a more informative prior was added, more precise estimates for the fixed effects and random effects were obtained, even when only 3 participants were included.},
  journal = {Psychol. Methods},
  keywords = {2-level modeling,Bayesian statistics,maximum likelihood,single-case designs,weakly informative prior},
  number = {4}
}

@article{Monnahan2017Faster,
  title = {Faster Estimation of {{Bayesian}} Models in Ecology Using {{Hamiltonian Monte Carlo}}},
  author = {Monnahan, Cole C. and Thorson, James T. and Branch, Trevor A.},
  year = {2017},
  volume = {8},
  pages = {339--348},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12681},
  abstract = {Bayesian inference is a powerful tool to better understand ecological processes across varied subfields in ecology, and is often implemented in generic and flexible software packages such as the widely used BUGS family (BUGS, WinBUGS, OpenBUGS and JAGS). However, some models have prohibitively long run times when implemented in BUGS. A relatively new software platform called Stan uses Hamiltonian Monte Carlo (HMC), a family of Markov chain Monte Carlo (MCMC) algorithms which promise improved efficiency and faster inference relative to those used by BUGS. Stan is gaining traction in many fields as an alternative to BUGS, but adoption has been slow in ecology, likely due in part to the complex nature of HMC. Here, we provide an intuitive illustration of the principles of HMC on a set of simple models. We then compared the relative efficiency of BUGS and Stan using population ecology models that vary in size and complexity. For hierarchical models, we also investigated the effect of an alternative parameterization of random effects, known as non-centering. For small, simple models there is little practical difference between the two platforms, but Stan outperforms BUGS as model size and complexity grows. Stan also performs well for hierarchical models, but is more sensitive to model parameterization than BUGS. Stan may also be more robust to biased inference caused by pathologies, because it produces diagnostic warnings where BUGS provides none. Disadvantages of Stan include an inability to use discrete parameters, more complex diagnostics and a greater requirement for hands-on tuning. Given these results, Stan is a valuable tool for many ecologists utilizing Bayesian inference, particularly for problems where BUGS is prohibitively slow. As such, Stan can extend the boundaries of feasible models for applied problems, leading to better understanding of ecological processes. Fields that would likely benefit include estimation of individual and population growth rates, meta-analyses and cross-system comparisons and spatiotemporal models.},
  annotation = {ZSCC: 0000086  \_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12681},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Monnahan et al_2017_Faster estimation of Bayesian models in ecology using Hamiltonian Monte Carlo.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\LMMQXS5K\\2041-210X.html},
  journal = {Methods in Ecology and Evolution},
  keywords = {Bayesian inference,hierarchical modelling,Markov chain Monte Carlo,no-U-turn sampler,Stan},
  language = {en},
  number = {3}
}

@article{Montesinos-Lopez2018Multivariate,
  ids = {Montesinos-Lopez2019},
  title = {Multivariate {{Bayesian Analysis}} of {{On}}-{{Farm Trials}} with {{Multiple}}-{{Trait}} and {{Multiple}}-{{Environment Data}}},
  author = {Montesinos-L{\'o}pez, Osval A. and Montesinos-L{\'o}pez, Abelardo and Hern{\'a}ndez, Mateo Vargas and Ortiz-Monasterio, Iv{\'a}n and P{\'e}rez-Rodr{\'i}guez, Paulino and Burgue{\~n}o, Juan and Crossa, Jos{\'e}},
  year = {2018},
  month = nov,
  volume = {111},
  pages = {2658--2669},
  issn = {0002-1962, 1435-0645},
  doi = {10.2134/agronj2018.06.0362},
  abstract = {Multivariate analysis is preferred over univariate analysis in plant breeding studies because it can exploit correlated traits and environments, whereas Bayesian analysis provides a natural way to incorporate prior knowledge and inferences that are conditional on the observed data. The objective of this paper is to show how to use multivariate Bayesian analysis for estimating random effects of genotype \texttimes{} environment and genotype \texttimes{} environment \texttimes{} trait combinations, and for computing genotypic and phenotypic correlations among traits and environments. Data were collected from on-farm trials conducted by the International Maize and Wheat Improvement Center (CIMMYT) to evaluate bread and durum wheat lines in the Yaqui Valley of southern Sonora, M\'exico, during three crop seasons (2012, 2013, and 2015). The Bayesian multi-trait and multienvironment model with Gibbs sampler provides an analytic solution that can be used as an alternative for analyzing on-farm multiple-trait and multiple-environment data because it allows making parsimonious, precise and simultaneous estimations of random effects, genetic correlations (of traits and environments) and residual correlations of traits. The multivariate Bayesian model successfully fitted three of the four data sets (2012, 2015, and combined cropping seasons), but did not fit well the data of crop season 2013. For three out of five traits under study in this crop season, the correlations between the observed and predicted phenotypic values were lower than 0.6, suggesting that the predicted values were not very close to the observed values.},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\OFEandPA\\Montesinos‐López et al. - 2018 - Multivariate Bayesian Analysis of On‐Farm Trials w.pdf},
  journal = {Agron.j.},
  language = {en},
  number = {6}
}

@article{Ngombe2020Are,
  title = {``{{Are They Aware}}, and {{Why}}?'' {{Bayesian Analysis}} of {{Predictors}} of {{Smallholder Farmers}}' {{Awareness}} of {{Climate Change}} and {{Its Risks}} to {{Agriculture}}},
  shorttitle = {``{{Are They Aware}}, and {{Why}}?},
  author = {Ng'ombe, John N. and Tembo, Moses C. and Masasi, Blessing},
  year = {2020},
  month = mar,
  volume = {10},
  pages = {376},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/agronomy10030376},
  abstract = {While climate change threatens global food security, health, and nutrition outcomes, Africa is more vulnerable because its economies largely depend on rain-fed agriculture. Thus, there is need for agricultural producers in Africa to employ robust adaptive measures that withstand the risks of climate change. However, the success of adaptation measures to climate change primarily depends on the communities' knowledge or awareness of climate change and its risks. Nonetheless, existing empirical research is still limited to illuminate farmers' awareness of the climate change problem. This study employs a Bayesian hierarchical logistic model, estimated using Hamiltonian Monte Carlo (HMC) methods, to empirically determine drivers of smallholder farmers' awareness of climate change and its risks to agriculture in Zambia. The results suggest that on average, 77\% of farmers in Zambia are aware of climate change and its risks to agriculture. We find socio-demographics, climate change information sources, climate change adaptive factors, and climate change impact-related shocks as predictors of the expression of climate change awareness. We suggest that farmers should be given all the necessary information about climate change and its risks to agriculture. Most importantly, the drivers identified can assist policymakers to provide the effective extension and advisory services that would enhance the understanding of climate change among farmers in synergy with appropriate farm-level climate-smart agricultural practices.},
  annotation = {ZSCC: NoCitationData[s1]},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Ng’ombe et al_2020_“Are They Aware, and Why.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\DI2TH9ED\\376.html},
  journal = {Agronomy},
  keywords = {climate change,climate change awareness,climate-smart technologies,Hamiltonian Monte Carlo,Zambia},
  language = {en},
  number = {3}
}

@article{Nishio2019Performance,
  title = {Performance of {{Hamiltonian Monte Carlo}} and {{No}}-{{U}}-{{Turn Sampler}} for Estimating Genetic Parameters and Breeding Values},
  author = {Nishio, Motohide and Arakawa, Aisaku},
  year = {2019},
  month = dec,
  volume = {51},
  pages = {73},
  issn = {1297-9686},
  doi = {10.1186/s12711-019-0515-1},
  abstract = {Background:\hspace{0.6em} Hamiltonian Monte Carlo is one of the algorithms of the Markov chain Monte Carlo method that uses Hamiltonian dynamics to propose samples that follow a target distribution. The method can avoid the random walk behavior to achieve a more effective and consistent exploration of the probability space and sensitivity to correlated parameters, which are shortcomings that plague many Markov chain Monte Carlo methods. However, the performance of Hamiltonian Monte Carlo is highly sensitive to two hyperparameters. The No-U-Turn Sampler, an extension of Hamiltonian Monte Carlo, was recently introduced to automate the tuning of these hyperparameters. Thus, this study compared the performances of Gibbs sampling, Hamiltonian Monte Carlo, and the No-U-Turn Sampler for estimating genetic parameters and breeding values as well as sampling qualities in both simulated and real pig data. For all datasets, we used a pedigree-based univariate linear mixed model. Results:\hspace{0.6em} For all datasets, the No-U-Turn Sampler and Gibbs sampling performed comparably regarding the estimation of heritabilities and accuracies of breeding values. Compared with Gibbs sampling, the estimates of effective sample sizes for simulated and pig data with the No-U-Turn Sampler were 3.2 to 22.6 and 3.5 to 5.9 times larger, respectively. Autocorrelations decreased more quickly with the No-U-Turn Sampler than with Gibbs sampling. When true heritability was low in the simulated data, the skewness of the marginal posterior distributions with the No-UTurn Sampler was smaller than that with Gibbs sampling. The performance of Hamiltonian Monte Carlo for sampling quality was inferior to that of No-U-Turn Sampler in the simulated data. Moreover, Hamiltonian Monte Carlo could not estimate genetic parameters because of difficulties with the hyperparameter settings with pig data. Conclusions:\hspace{0.6em} The No-U-Turn Sampler is a promising sampling method for animal breeding because of its good sampling qualities: large effective sample sizes, low autocorrelations, and low skewness of marginal posterior distributions, particularly when heritability is low. Meanwhile, Hamiltonian Monte Carlo failed to converge with a simple univariate model for pig data. Thus, it might be difficult to use Hamiltonian Monte Carlo for usual complex models in animal breeding.},
  annotation = {ZSCC: 0000003},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Performance of Hamiltonian Monte Carlo and No-U-Turn Sampler for estimating genetic parameters and breeding values.pdf},
  journal = {Genet Sel Evol},
  language = {en},
  number = {1}
}

@article{Omer2015Bayesian,
  title = {Bayesian Estimation of Genotype-by-Environment Interaction in Sorghum Variety Trials},
  author = {Omer, Siraj Osman and Abdalla, Abdel Wahab Hassan and Mohammed, Mohammed Hamza and Singh, Murari},
  year = {2015},
  volume = {10},
  pages = {82--95},
  annotation = {ZSCC: 0000013},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Omer et al_2015_Bayesian estimation of genotype-by-environment interaction in sorghum variety.pdf},
  journal = {Communications in Biometry and Crop Science},
  keywords = {⛔ No DOI found}
}

@article{Omer2017Comparing,
  title = {Comparing {{Bayesian}} and {{Frequentist Approaches}} for {{GGE Bi}}-Plot {{Analysis}} in {{Multi}}-{{Environment Trials}} in {{Sorghum}}},
  author = {Omer, S. O. and Singh, M.},
  year = {2017},
  volume = {7},
  pages = {40},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Omer_Singh_2017_Comparing Bayesian and Frequentist Approaches for GGE Bi-plot Analysis in.pdf},
  journal = {Eur Exp Biol},
  keywords = {⛔ No DOI found},
  number = {6}
}

@article{Onofri2019Analysing,
  ids = {Onofri2019},
  title = {Analysing Censored Data in Agricultural Research: {{A}} Review with Examples and Software Tips},
  shorttitle = {Analysing Censored Data in Agricultural Research},
  author = {Onofri, Andrea and Piepho, Hans-Peter and Kozak, Marcin},
  year = {2019},
  volume = {174},
  pages = {3--13},
  issn = {1744-7348},
  doi = {10.1111/aab.12477},
  abstract = {Metric data are usually assessed on a continuous scale with good precision, but sometimes agricultural researchers cannot obtain precise measurements of a variable. Values of such a variable cannot then be expressed as real numbers (e.g., 1.51 or 2.56), but often can be represented by intervals into which the values fall (e.g., from 1 to 2 or from 2 to 3). In this situation, statisticians talk about censoring and censored data, as opposed to missing data, where no information is available at all. Traditionally, in agriculture and biology, three methods have been used to analyse such data: (a) when intervals are narrow, some form of imputation (e.g., mid-point imputation) is used to replace the interval and traditional methods for continuous data are employed (such as analyses of variance [ANOVA] and regression); (b) for time-to-event data, the cumulative proportions of individuals that experienced the event of interest are analysed, instead of the individual observed times-to-event; (c) when intervals are wide and many individuals are collected, non-parametric methods of data analysis are favoured, where counts are considered instead of the individual observed value for each sample element. In this paper, we show that these methods may be suboptimal: The first one does not respect the process of data collection, the second leads to unreliable standard errors (SEs), while the third does not make full use of all the available information. As an alternative, methods of survival analysis for censored data can be useful, leading to reliable inferences and sound hypotheses testing. These methods are illustrated using three examples from plant and crop sciences.},
  annotation = {ZSCC: 0000013  \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/aab.12477},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Onofri et al_2019_Analysing censored data in agricultural research.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\FLWD2KQ8\\aab.html},
  journal = {Annals of Applied Biology},
  keywords = {Bayesian model,censored data,interval data,R,SAS,survival analysis,time-to-event data},
  language = {en},
  number = {1}
}

@article{OSullivan2003Geographically,
  title = {Geographically Weighted Regression: {{The}} Analysis of Spatially Varying Relationships (Review)},
  author = {O'Sullivan, David},
  year = {2003},
  volume = {35},
  pages = {272--275},
  issn = {1538-4632},
  doi = {10.1353/geo.2003.0008},
  abstract = {applicability for this approach.},
  annotation = {ZSCC: NoCitationData[s2]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\O'Sullivan_2003_Geographically weighted regression.pdf},
  journal = {Geographical Analysis},
  number = {3}
}

@incollection{Paciorek2004Nonstationary,
  title = {Nonstationary {{Covariance Functions}} for {{Gaussian Process Regression}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 16},
  author = {Paciorek, Christopher J. and Schervish, Mark J.},
  editor = {Thrun, S. and Saul, L. K. and Sch{\"o}lkopf, B.},
  year = {2004},
  pages = {273--280},
  publisher = {{MIT Press}},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Paciorek_Schervish_2004_Nonstationary Covariance Functions for Gaussian Process Regression.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\RRVXC85H\\2350-nonstationary-covariance-functions-for-gaussian-process-regression.html}
}

@article{Paez2002General,
  title = {A {{General Framework}} for {{Estimation}} and {{Inference}} of {{Geographically Weighted Regression Models}}: 1. {{Location}}-{{Specific Kernel Bandwidths}} and a {{Test}} for {{Locational Heterogeneity}}},
  shorttitle = {A {{General Framework}} for {{Estimation}} and {{Inference}} of {{Geographically Weighted Regression Models}}},
  author = {P{\'a}ez, Antonio and Uchida, Takashi and Miyamoto, Kazuaki},
  year = {2002},
  month = apr,
  volume = {34},
  pages = {733--754},
  publisher = {{SAGE Publications Ltd}},
  issn = {0308-518X},
  doi = {10.1068/a34110},
  abstract = {Geographically weighted regression (GWR) has been proposed as a technique to explore spatial parametric nonstationarity. The method has been developed mainly along the lines of local regression and smoothing techniques, a strategy that has led to a number of difficult questions about the regularity conditions of the likelihood function, the effective number of degrees of freedom, and in general the relevance of extending the method to derive inference and model specification tests. In this paper we argue that placing GWR within a different statistical context, as a spatial model of error variance heterogeneity, or what might be termed locational heterogeneity, solves these difficulties. A maximum-likelihood-based framework for estimation and inference of a general geographically weighted regression model is presented that leads to a method to estimate location-specific kernel bandwidths. Moreover, a test for locational heterogeneity is derived and its use exemplified with a case study.},
  annotation = {ZSCC: 0000218},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Páez et al_2002_A General Framework for Estimation and Inference of Geographically Weighted.pdf},
  journal = {Environ Plan A},
  number = {4}
}

@article{Pandit2019Comparative,
  title = {Comparative Analysis of {{Gaussian Process}} Power Curve Models Based on Different Stationary Covariance Functions for the Purpose of Improving Model Accuracy},
  author = {Pandit, Ravi Kumar and Infield, David},
  year = {2019},
  month = sep,
  volume = {140},
  pages = {190--202},
  issn = {0960-1481},
  doi = {10.1016/j.renene.2019.03.047},
  abstract = {Gaussian Process (GP) models are increasingly finding application in wind turbine condition monitoring and in particular early fault detection. GP model accuracy is greatly influenced by the choice and type of the covariance functions (used to described the similarity between two given data points). Hence, the appropriate selection and composition of covariance functions is essential for accurate GP modelling. In this study, an in-depth analysis of commonly used stationary covariance functions is presented in which wind turbine power curve used where GP based power curve has been constructed using different stationary covariance functions, and after that, a comparative analysis has been carried out in order to identify the most effective covariance function. The commonly used squared exponential covariance function is taken as the benchmark, against which other covariance functions are assessed. The results show that the performance (in terms of model accuracy and uncertainty) of GP fitted power curve models based on rational quadratic covariance functions is almost the same as for the most commonly used squared exponential function. Thus, rational quadratic covariance functions can be used instead of squared exponential covariance functions. In this paper, strength and weakness of stationary covariance functions would be highlighted for effective condition monitoring.},
  annotation = {ZSCC: 0000012},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Pandit_Infield_2019_Comparative analysis of Gaussian Process power curve models based on different.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\DCLQH9PY\\S0960148119303520.html},
  journal = {Renewable Energy},
  keywords = {Condition monitoring,Covariance functions,Gaussian process,Power curve},
  language = {en}
}

@article{Panten2010Enhancing,
  title = {Enhancing the Value of Field Experimentation through Whole-of-Block Designs},
  author = {Panten, K. and Bramley, R. G. V. and Lark, R. M. and Bishop, T. F. A.},
  year = {2010},
  month = apr,
  volume = {11},
  pages = {198--213},
  issn = {1573-1618},
  doi = {10.1007/s11119-009-9128-y},
  abstract = {Precision agriculture (PA) offers opportunities for the development of new approaches to on-farm experimentation to assist farmers with site-specific management decisions. Traditional agricultural experiments are usually implemented in fields with the least possible soil heterogeneity under the assumption that responses to inputs and inherent variation of the soil are additive components of yield variation. However, because the soil in typical fields is not homogeneous, PA has much to offer. Farmers faced with variable conditions need to optimize their management to the variation over space and time on their farm, a problem that is not solved by conventional approaches to experimentation. New designs for on-farm experiments were developed in the 1990s for cereal production in which the whole field was used for the experiment rather than small plots. We explore the extension of this type of experiment to a vineyard in the Clare Valley of South Australia aiming to evaluate options to increase grape yield and vine vigour. Manually sampled indices of vine performance measured on georeferenced `target' grapevines were analysed geostatistically. The major advantage of such an approach is that the spatial variation in response to experimental treatments can be examined. Linear models of coregionalization, pseudo cross-variograms and standardized ordinary cokriging are used to map treatment responses over the experimental area and also the differences between them. The results indicate that both treatment responses and the significance of differences between them are spatially variable. Thus, we conclude that whole-of-block on-farm trials are useful in vineyards.},
  annotation = {ZSCC: 0000035},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Panten et al_2010_Enhancing the value of field experimentation through whole-of-block designs.pdf},
  journal = {Precision Agric},
  language = {en},
  number = {2}
}

@article{Patterson1971Recovery,
  ids = {Patterson1971Recoverya},
  title = {Recovery of {{Inter}}-{{Block Information}} When {{Block Sizes}} Are {{Unequal}}},
  author = {Patterson, H. D. and Thompson, R.},
  year = {1971},
  volume = {58},
  pages = {545--554},
  publisher = {{[Oxford University Press, Biometrika Trust]}},
  issn = {0006-3444},
  doi = {10.2307/2334389},
  abstract = {A method is proposed for estimating intra-block and inter-block weights in the analysis of incomplete block designs with block sizes not necessarily equal. The method consists of maximizing the likelihood, not of all the data, but of a set of selected error contrasts. When block sizes are equal results are identical with those obtained by the method of Nelder (1968) for generally balanced designs. Although mainly concerned with incomplete block designs the paper also gives in outline an extension of the modified maximum likelihood procedure to designs with a more complicated block structure.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\REML\\Patterson_Thompson_1971_Recovery of Inter-Block Information when Block Sizes are Unequal.pdf},
  journal = {Biometrika},
  number = {3}
}

@book{Petersen1994Agricultural,
  title = {Agricultural {{Field Experiments}}: {{Design}} and {{Analysis}}},
  author = {Petersen, Roger G},
  year = {1994},
  edition = {1st},
  publisher = {{CRC Press}},
  address = {{Boca Raton}},
  annotation = {ZSCC: 0000442},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\Books\\Agricultural field experiments design and analysis.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\4L78BHX9\\Petersen - Agricultural Field Experiments.pdf},
  isbn = {978-0-429-07849-1},
  language = {en}
}

@article{Piepho2008Nearest,
  title = {Nearest Neighbour Adjustment and Linear Variance Models in Plant Breeding Trials},
  booktitle = {Biometrical Journal},
  author = {Piepho, Hans-Peter and Richter, Christel and Williams, Emlyn},
  year = {2008},
  volume = {50},
  pages = {164--189},
  issn = {03233847},
  doi = {10.1002/bimj.200710414},
  abstract = {This paper reviews methods for nearest neighbour analysis that adjust for local trend in one dimension. Such methods are commonly used in plant breeding and variety testing. The focus is on simple differencing methods, including first differences and the Papadakis method. We discuss mixed model representations of these methods on the scale of the observed data. Modelling observed data has a number of practical advantages compared to differencing, for example the facility to conveniently compute adjusted cultivar means. Most models considered involve a linear variance-covariance structure and can be represented as state-space models. The reviewed methods and models are exemplified using three datasets. \textcopyright 2008 Wiley-VCH Verlag GmbH \& Co. KGaA.},
  annotation = {ZSCC: 0000060},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Piepho et al_2008_Nearest neighbour adjustment and linear variance models in plant breeding trials.pdf},
  journal = {Biometrical Journal},
  keywords = {Field trials,Geostatistics,Linear variance,Mixed model,Spatial model,Statespace model},
  number = {2}
}

@article{Piepho2011Estimation,
  title = {On Estimation of Genotypic Correlations and Their Standard Errors by Multivariate {{REML}} Using the {{MIXED}} Procedure of the {{SAS System}}},
  author = {Piepho, Hans-Peter and M{\"o}hring, Jens},
  year = {2011},
  volume = {51},
  pages = {2449--2454},
  issn = {0011183X},
  doi = {10.2135/cropsci2011.02.0088},
  abstract = {This paper explains a simple strategy to develop code for multivariate (multitrait) mixed-model analysis using the MIXED procedure of the SAS System, when the corresponding univariate model has a simple variance components form. Such models are needed for estimating genotypic and phenotypic correlation among traits in plant breeding experiments, and they provide best linear unbiased predictions (BLUP) of genetic effects which may be more accurate than univariate BLUP. We give some hints how to speed up computations, and it is shown how to obtain asymptotic standard errors of correlation estimates with little effort. \textcopyright{} Crop Science Society of America.},
  annotation = {ZSCC: 0000024},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Piepho_Möhring_2011_On estimation of genotypic correlations and their standard errors by.pdf},
  journal = {Crop Science},
  number = {6}
}

@article{Piepho2011Statistical,
  title = {Statistical Aspects of On-Farm Experimentation},
  author = {Piepho, Hans-Peter and Richter, Christel and Spilke, Joachim and Hartung, Karin and Kunick, Arndt},
  year = {2011},
  volume = {62},
  pages = {721--735},
  doi = {10.1071/cp11175},
  annotation = {ZSCC: 0000040},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Piepho et al_2011_Statistical aspects of on-farm experimentation.pdf},
  journal = {Crop \& Pasture Science}
}

@article{Piepho2013Why,
  title = {Why Randomize Agricultural Experiments?},
  author = {Piepho, H. P. and M{\"o}hring, J. and Williams, E. R.},
  year = {2013},
  volume = {199},
  pages = {374--383},
  issn = {09312250},
  doi = {10.1111/jac.12026},
  abstract = {This study illustrates the importance of randomization using two hypothetical field trials, one with a marked systematic trend and the other with a more erratic spatial pattern. The insights from these two examples are reinforced by analysis of a uniformity trial and a small simulation study. Results illustrate that both model-based spatial analysis and randomization-based analysis assuming independent errors are valid with full randomization but may be invalidated when randomization is lacking. It is concluded that randomization provides protection against different forms of spatial trend. The examples given in the study serve as a general reminder that agricultural experiments should be randomized whenever possible. \textcopyright{} 2013 Blackwell Verlag GmbH.},
  annotation = {ZSCC: 0000016},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\ExperimentalDesign\\Piepho et al_2013_Why Randomize Agricultural Experiments.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\4TR5V2FI\\jac.html},
  journal = {J. Agron. Crop Sci.},
  keywords = {experimental design,Experimental design,field trial,Field trial,linear model,Linear model,randomization,Randomization,statistics,Statistics,uniformity trial,Uniformity trial},
  number = {5}
}

@article{Piepho2015Problems,
  title = {Problems in Parameter Estimation for Power and {{AR}}(1) Models of Spatial Correlation in Designed Field Experiments},
  author = {Piepho, Hans-Peter and M{\"o}hring, Jens and Pflugfelder, Markus and Hermann, Winfried and Williams, Emlyn R},
  year = {2015},
  volume = {10},
  pages = {3--16},
  annotation = {ZSCC: 0000020},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\AF7KZC4S\\Piepho et al. - Problems in parameter estimation for power and AR(.pdf},
  journal = {Communications in Biometry \& Crop Science},
  keywords = {⛔ No DOI found},
  language = {en},
  number = {1}
}

@article{Piepho2018Tutorial,
  ids = {Piepho2018a,Piepho2018b},
  title = {A Tutorial on the Statistical Analysis of Factorial Experiments with Qualitative and Quantitative Treatment Factor Levels},
  author = {Piepho, H. P. and Edmondson, R. N.},
  year = {2018},
  volume = {204},
  pages = {429--455},
  publisher = {{Wiley Online Library}},
  doi = {10/gd7x6g},
  annotation = {ZSCC: 0000029},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\A tutorial on the statistical analysis of factorial experiments with qualitative and quantitative treatment factor levels.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CX4T9LAT\\jac.html},
  journal = {Journal of Agronomy and Crop Science},
  keywords = {factorial analysis,linear mixed models,polynomial regression,R,repeated-measures analysis,response surface models,SAS,split-plot analysis},
  number = {5}
}

@article{Pringle2004FieldScale,
  title = {Field-{{Scale Experiments}} for {{Site}}-{{Specific Crop Management}}. {{Part I}}: {{Design Considerations}}},
  shorttitle = {Field-{{Scale Experiments}} for {{Site}}-{{Specific Crop Management}}. {{Part I}}},
  author = {Pringle, M. J. and Cook, S. E. and McBratney, A. B.},
  year = {2004},
  month = dec,
  volume = {5},
  pages = {617--624},
  issn = {1573-1618},
  doi = {10.1007/s11119-004-6346-1},
  abstract = {This is a two-part paper concerned with the role of field-scale experiments in site-specific crop management (SSCM). Part I is a general introduction to experimental design for SSCM, while Part II focuses on applied analysis. All references are listed at the end of Part II. In Part I, we list the goals of SSCM-experimentation, in addition to the classes of valid experimental designs. Three general approaches are proposed for choosing experimental designs: approach A is for experiments concerning management classes, while approaches B and C are alternatives for continuous management. Approaches A and B are comparative and can be analysed with an appropriately modified ANOVA.},
  annotation = {ZSCC: 0000020},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Pringle et al_2004_Field-Scale Experiments for Site-Specific Crop Management.pdf},
  journal = {Precision Agric},
  language = {en},
  number = {6}
}

@article{Pringle2004FieldScalea,
  title = {Field-{{Scale Experiments}} for {{Site}}-{{Specific Crop Management}}. {{Part II}}: {{A Geostatistical Analysis}}},
  shorttitle = {Field-{{Scale Experiments}} for {{Site}}-{{Specific Crop Management}}. {{Part II}}},
  author = {Pringle, M. J. and McBratney, A. B. and Cook, S. E.},
  year = {2004},
  month = dec,
  volume = {5},
  pages = {625--645},
  issn = {1573-1618},
  doi = {10.1007/s11119-004-6347-0},
  abstract = {Part II analyses approach C experiments. Field-scale experiments were applied to four wheat fields in the Western Australian wheat belt. Different experimental designs were used two two-dimensional sine-waves, a chequerboard, and a two-factor strip arrangement. In each experiment, the yield associated with a particular treatment was predicted by kriging to where the other treatments were located. Different forms of kriging were investigated. Co-located cokriging, using the previous-season yield map as a covariate, was the most promising. The kriged data were then modelled with polynomial yield response functions. The outcome was a map for each field that described the optimum application of experimental input. The requirements varied continuously across the field, and could justify future site-specific crop management. The two-factor strip experiment was the most successful of those presented; the field on which it was used showed relatively strong responses to the applied inputs. The other sites were affected by lack of rain and/or design flaws. The underlying philosophy is sound, but the method proposed is time-consuming and inefficient. We hope that this paper can stimulate further research on the subject.},
  annotation = {ZSCC: 0000039},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Pringle et al_2004_Field-Scale Experiments for Site-Specific Crop Management2.pdf},
  journal = {Precision Agric},
  language = {en},
  number = {6}
}

@incollection{Pringle2010Analysis,
  title = {The {{Analysis}} of {{Spatial Experiments}}},
  booktitle = {Geostatistical {{Applications}} for {{Precision Agriculture}}},
  author = {Pringle, M. J. and Bishop, T. F. A. and Lark, R. M. and Whelan, B. M. and McBratney, A. B.},
  editor = {Oliver, M.A.},
  year = {2010},
  pages = {243--267},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-90-481-9133-8_10},
  abstract = {Anyone with an interest in precision agriculture has already formed a hypothesis that the field is a sub-optimum management unit for cropping. The role of experimentation is to test this hypothesis. Geostatistics can play an important role in analysing experiments for site-specific crop management: put simply, spatial autocorrelation must be accounted for if one is to draw valid inferences. We provide here some background to the basic concepts of agronomic experimentation. We then consider two broad classes of experimental design for precision agriculture (management-class experiments and local-response experiments), and show, with the aid of case studies, how each may be analysed geostatistically. Ultimately though, if farmers are compelled to use relatively simple designs and less formal analyses, then researchers must follow and adapt their geostatistical analyses accordingly.},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Pringle et al_2010_The Analysis of Spatial Experiments.pdf},
  isbn = {978-90-481-9133-8},
  keywords = {Cokriging,Local-response experiments,Management-class experiments,Polynomial response function,Residual maximum likelihood (REML),Trend comparison},
  language = {en}
}

@article{Rakshit2020Novel,
  ids = {Rakshit2020Novela},
  title = {Novel Approach to the Analysis of Spatially-Varying Treatment Effects in on-Farm Experiments},
  author = {Rakshit, Suman and Baddeley, Adrian and Stefanova, Katia and Reeves, Karyn and Chen, Kefei and Cao, Zhanglong and Evans, Fiona and Gibberd, Mark},
  year = {2020},
  volume = {255},
  pages = {107783},
  publisher = {{Elsevier}},
  issn = {0378-4290},
  doi = {10/gg2vv7},
  abstract = {{$<$}p{$>$}With increasing interest in on-farm experiments, there is a pressing need to develop rigorous statistical methods for analysing these experiments. The adoption of advanced technologies such as yield monitors and variable-rate fertilizer applicators has enabled farmers and researchers to collect biophysical data linked to spatial information at a scale which allows them to investigate the role of spatial variability in the development of optimum management practices. A relevant topic for investigation could be: "what are the optimum rates of nitrogen and how/why do these differ across the field"? Although it has been recently understood that traditional statistical methods that are appropriate for analysing small-plot experiments are inappropriate for answering these questions, a unifying approach to inference for on-farm experiments is still missing and this limits the adoption of the technique. In this paper we propose a unifying approach to the analysis of on-farm strip experiments adapting the core ideas of local likelihood or geographically weighted regression. We propose a statistical model that allows spatial nonstationarity in modelled relationships and estimates spatially-varying parameters governing these relationships. A crucial step is bandwidth selection in implementing these models, and we develop bandwidth selection methods for two important scenarios relevant to the modelling of yield monitor data in on-farm experiments. Local {$<$}em{$>$}t{$<$}/em{$>$}-scores have been introduced for inferential purposes and the associated problem of multiple testing has been described in the context of analysing on-farm experiments. We demonstrate in this paper how local {$<$}em{$>$}p{$<$}/em{$>$}-values can be adjusted to overcome this problem. To illustrate the applicability of our proposed method, we analysed two publicly available datasets. Graphical displays are created to guide practitioners to make informed decisions on optimal management practices.{$<$}/p{$>$}},
  annotation = {ZSCC: 0000004},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Rakshit et al_2020_Novel approach to the analysis of spatially-varying treatment effects in on-farm experiments.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\6USWQ45W\\S0378429019317368.html},
  journal = {Field Crops Research},
  keywords = {Bandwidth selection,Contour maps,Geographically weighted regression,Local likelihood,Precision agriculture,Spatial nonstationarity},
  number = {October 2019}
}

@article{Ransom2019Statistical,
  title = {Statistical and Machine Learning Methods Evaluated for Incorporating Soil and Weather into Corn Nitrogen Recommendations},
  author = {Ransom, Curtis J. and Kitchen, Newell R. and Camberato, James J. and Carter, Paul R. and Ferguson, Richard B. and Fern{\'a}ndez, Fabi{\'a}n G. and Franzen, David W. and Laboski, Carrie A. M. and Myers, D. Brenton and Nafziger, Emerson D. and Sawyer, John E. and Shanahan, John F.},
  year = {2019},
  month = sep,
  volume = {164},
  pages = {104872},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2019.104872},
  abstract = {Nitrogen (N) fertilizer recommendation tools could be improved for estimating corn (Zea mays L.) N needs by incorporating site-specific soil and weather information. However, an evaluation of analytical methods is needed to determine the success of incorporating this information. The objectives of this research were to evaluate statistical and machine learning (ML) algorithms for utilizing soil and weather information for improving corn N recommendation tools. Eight algorithms [stepwise, ridge regression, least absolute shrinkage and selection operator (Lasso), elastic net regression, principal component regression (PCR), partial least squares regression (PLSR), decision tree, and random forest] were evaluated using a dataset containing measured soil and weather variables from a regional database. The performance was evaluated based on how well these algorithms predicted corn economically optimal N rates (EONR) from 49 sites in the U.S. Midwest. Multiple algorithm modeling scenarios were examined with and without adjustment for multicollinearity and inclusion of two-way interaction terms to identify the soil and weather variables that could improve three dissimilar N recommendation tools. Results showed the out-of-sample root-mean-square error (RMSE) for the decision tree and some random forest modeling scenarios were better than the stepwise or ridge regression, but not significantly different than any other algorithm. The best ML algorithm for adjusting N recommendation tools was the random forest approach (r2 increased between 0.72 and 0.84 and the RMSE decreased between 41 and 94 kg N ha-1). However, the ML algorithm that best adjusted tools while using a minimal amount of variables was the decision tree. This method was simple, needing only one or two variables (regardless of modeling scenario) and provided moderate improvement as r2 values increased between 0.15 and 0.51 and RMSE decreased between 16 and 66 kg N ha-1. Using ML algorithms to adjust N recommendation tools with soil and weather information shows promising results for better N management in the U.S. Midwest.},
  annotation = {ZSCC: 0000008},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Ransom et al_2019_Statistical and machine learning methods evaluated for incorporating soil and.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\8EQZ6LTA\\S0168169919304107.html},
  journal = {Computers and Electronics in Agriculture},
  keywords = {Corn,Machine learning,Nitrogen fertilizer recommendations,Soil,Weather},
  language = {en}
}

@book{Rasmussen2006Gaussian,
  ids = {Rasmussen2006Gaussiana,rasmussen2006gaussian,rasmussenGaussianProcessesMachine2006a},
  title = {Gaussian {{Processes}} for {{Machine Learning}}},
  author = {Rasmussen, C. E. and Williams, C. K. I.},
  year = {2006},
  publisher = {{The MIT Press}},
  annotation = {ZSCC: 0001507},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\2CXL8XEB\\Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf},
  keywords = {Data processing,Gaussian processes,Machine learning,Mathematical models}
}

@article{Ritter2008Onfarm,
  title = {An On-Farm Approach to Quantify Yield Variation and to Derive Decision Rules for Site-Specific Weed Management},
  author = {Ritter, C. and Dicke, D. and Weis, M. and Oebel, H. and Piepho, H. P. and B{\"u}chse, A. and Gerhards, R.},
  year = {2008},
  issn = {13852256},
  doi = {10.1007/s11119-008-9061-5},
  abstract = {Grain yield often varies within agricultural fields as a result of the variation in soil characteristics, competition from weeds, management practices and their causal interactions. To implement appropriate management decisions, yield variability needs to be explained and quantified. A new experimental design was established and tested in a field experiment to detect yield variation in relation to the variation in soil quality, the heterogeneity of weed distribution and weed control within a field. Weed seedling distribution and density, apparent soil electrical conductivity (ECa) and grain yield were recorded and mapped in a 3.5 ha winter wheat field during 2005 and 2006. A linear mixed model with an anisotropic spatial correlation structure was used to estimate the effect of soil characteristics, weed competition and herbicide treatment on crop yield. The results showed that all properties had a strong effect on grain yield. By adding herbicide costs and current grain price into the model, thresholds of weed density were derived for site-specific weed control. This experimental approach enables the variation of yield within agricultural fields to be explained, and an understanding of the effects on yield of the factors that affect it and their causal interactions to be gained. The approach can be applied to improve decision algorithms for the patch spraying of weeds. \textcopyright{} 2008 Springer Science+Business Media, LLC.},
  annotation = {ZSCC: 0000048},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Ritter et al_2008_An on-farm approach to quantify yield variation and to derive decision rules.pdf},
  journal = {Precision Agriculture},
  keywords = {Geostatistics,Herbicide injury,Soil variation,Weed control thresholds,Weed distribution}
}

@article{Rodriguez-Alvarez2018Correcting,
  title = {Correcting for Spatial Heterogeneity in Plant Breeding Experiments with {{P}}-Splines},
  author = {{Rodr{\'i}guez-{\'A}lvarez}, Mar{\'i}a Xos{\'e} and Boer, Martin P. and {van Eeuwijk}, Fred A. and Eilers, Paul H. C.},
  year = {2018},
  month = mar,
  volume = {23},
  pages = {52--71},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2017.10.003},
  abstract = {An important aim of the analysis of agricultural field experiments is to obtain good predictions for genotypic performance, by correcting for spatial effects. In practice these corrections turn out to be complicated, since there can be different types of spatial effects; those due to management interventions applied to the field plots and those due to various kinds of erratic spatial trends. This paper explores the use of two-dimensional smooth surfaces to model random spatial variation. We propose the use of anisotropic tensor product P-splines to explicitly model large-scale (global trend) and small-scale (local trend) spatial dependence. On top of this spatial field, effects of genotypes, blocks, replicates, and/or other sources of spatial variation are described by a mixed model in a standard way. Each component in the model is shown to have an effective dimension. They are closely related to variance estimation, and helpful for characterising the importance of model components. An important result of this paper is the formal proof of the relation between several definitions of heritability and the effective dimension associated with the genetic component. The practical value of our approach is illustrated by simulations and analyses of large-scale plant breeding experiments. An R-package, SpATS, is provided.},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Rodríguez-Álvarez et al_2018_Correcting for spatial heterogeneity in plant breeding experiments with.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\YYUMMDEJ\\S2211675317301070.html},
  journal = {Spatial Statistics},
  keywords = {Effective dimension,Field trials,Heritability,Linear mixed model,Spatial analysis,Tensor product P-splines},
  language = {en}
}

@article{Roth1934Direct,
  title = {On Direct Product Matrices},
  author = {Roth, William E.},
  year = {1934},
  volume = {40},
  pages = {461--468},
  publisher = {{American Mathematical Society}},
  doi = {10.1090/S0002-9904-1934-05899-3},
  annotation = {ZSCC: 0000159},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Roth_1934_On direct product matrices.pdf},
  journal = {Bulletin of the American Mathematical Society},
  number = {6}
}

@article{Roy2020Convergence,
  title = {Convergence {{Diagnostics}} for {{Markov Chain Monte Carlo}}},
  author = {Roy, Vivekananda},
  year = {2020},
  volume = {7},
  pages = {387--412},
  doi = {10.1146/annurev-statistics-031219-041300},
  abstract = {Markov chain Monte Carlo (MCMC) is one of the most useful approaches to scientific computing because of its flexible construction, ease of use, and generality. Indeed, MCMC is indispensable for performing Bayesian analysis. Two critical questions that MCMC practitioners need to address are where to start and when to stop the simulation. Although a great amount of research has gone into establishing convergence criteria and stopping rules with sound theoretical foundation, in practice, MCMC users often decide convergence by applying empirical diagnostic tools. This review article discusses the most widely used MCMC convergence diagnostic tools. Some recently proposed stopping rules with firm theoretical footing are also presented. The convergence diagnostics and stopping rules are illustrated using three detailed examples.},
  annotation = {ZSCC: 0000004  \_eprint: https://doi.org/10.1146/annurev-statistics-031219-041300},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Roy_2020_Convergence Diagnostics for Markov Chain Monte Carlo.pdf},
  journal = {Annual Review of Statistics and Its Application},
  number = {1}
}

@article{rushing2019Modeling,
  title = {Modeling Spatially and Temporally Complex Range Dynamics When Detection Is Imperfect},
  author = {Rushing, Clark S. and Royle, J. Andrew and Ziolkowski, David J. and Pardieck, Keith L.},
  year = {2019},
  month = sep,
  volume = {9},
  pages = {12805},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-48851-5},
  abstract = {Species distributions are determined by the interaction of multiple biotic and abiotic factors, which produces complex spatial and temporal patterns of occurrence. As habitats and climate change due to anthropogenic activities, there is a need to develop species distribution models that can quantify these complex range dynamics. In this paper, we develop a dynamic occupancy model that uses a spatial generalized additive model to estimate non-linear spatial variation in occupancy not accounted for by environmental covariates. The model is flexible and can accommodate data from a range of sampling designs that provide information about both occupancy and detection probability. Output from the model can be used to create distribution maps and to estimate indices of temporal range dynamics. We demonstrate the utility of this approach by modeling long-term range dynamics of 10 eastern North American birds using data from the North American Breeding Bird Survey. We anticipate this framework will be particularly useful for modeling species' distributions over large spatial scales and for quantifying range dynamics over long temporal scales.},
  annotation = {ZSCC: 0000003},
  copyright = {2019 The Author(s)},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Rushing et al_2019_Modeling spatially and temporally complex range dynamics when detection is.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\NAR7H5PD\\s41598-019-48851-5.html},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{Sarkka2013Spatiotemporal,
  title = {Spatiotemporal {{Learning}} via {{Infinite}}-{{Dimensional Bayesian Filtering}} and {{Smoothing}}: {{A Look}} at {{Gaussian Process Regression Through Kalman Filtering}}},
  shorttitle = {Spatiotemporal {{Learning}} via {{Infinite}}-{{Dimensional Bayesian Filtering}} and {{Smoothing}}},
  author = {Sarkka, Simo and Solin, Arno and Hartikainen, Jouni},
  year = {2013},
  month = jul,
  volume = {30},
  pages = {51--61},
  issn = {1558-0792},
  doi = {10.1109/MSP.2013.2246292},
  abstract = {Gaussian process-based machine learning is a powerful Bayesian paradigm for nonparametric nonlinear regression and classification. In this article, we discuss connections of Gaussian process regression with Kalman filtering and present methods for converting spatiotemporal Gaussian process regression problems into infinite-dimensional state-space models. This formulation allows for use of computationally efficient infinite-dimensional Kalman filtering and smoothing methods, or more general Bayesian filtering and smoothing methods, which reduces the problematic cubic complexity of Gaussian process regression in the number of time steps into linear time complexity. The implication of this is that the use of machine-learning models in signal processing becomes computationally feasible, and it opens the possibility to combine machine-learning techniques with signal processing methods.},
  annotation = {ZSCC: 0000090},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Sarkka et al_2013_Spatiotemporal Learning via Infinite-Dimensional Bayesian Filtering and.pdf},
  journal = {IEEE Signal Processing Magazine},
  keywords = {Bayes methods,Gaussian process regression problems,Gaussian process-based machine learning,Gaussian processes,infinite-dimensional Bayesian filtering,infinite-dimensional Kalman filtering,infinite-dimensional smoothing methods,infinite-dimensional state-space models,Kalman filters,Kernel,learning (artificial intelligence),Learning systems,Linear regression analysis,linear time complexity,Machine learning,nonparametric nonlinear classification,nonparametric nonlinear regression,Parametric statistics,problematic cubic complexity,regression analysis,signal classification,signal processing methods,Smoothing methods,spatiotemporal learning,Spatiotemporal phenomena},
  number = {4}
}

@article{Schmidt2018More,
  ids = {Schmidt2018,Schmidt2018a},
  title = {More, Larger, Simpler: {{How}} Comparable Are on-Farm and on-Station Trials for Cultivar Evaluation?},
  author = {Schmidt, P. and M{\"o}hring, J. and Koch, R. J. and Piepho, H. P.},
  year = {2018},
  volume = {58},
  pages = {1508--1518},
  publisher = {{Routledge}},
  issn = {14350653},
  doi = {10.2135/cropsci2017.09.0555},
  abstract = {Traditionally, cultivar evaluation trials have been conducted as replicated small-plot, on-station trials at multiple locations and years. To this day, this is the method of choice for cultivar registration trials conducted by official federal institutes. Given a different purpose (e.g., marketing), cultivar evaluation may also be done as on-farm trials with single replicates and fewer plots laid out as large strips. Such trials are often conducted at a larger number of locations. It is not clear how comparable these two trial systems are. Our objective therefore was to compare the precision and accuracy of these two systems using yield data from both on-farm trials and from official on-station trials for winter oilseed rape (Brassica napus L.) across 8 yr. We set up multivariate mixed models to analyze the combined dataset of both trial systems and estimate heterogeneous variance components. Furthermore, based on 23 hybrid genotypes common to both datasets, we investigated the genetic correlation between systems and tested for genotype \texttimes{} system interaction effects. The results suggest that on-farm trials are comparable with on-station trials in terms of precision of a single plot, but that there are genotype \texttimes{} system interaction effects prohibiting the comparison of yield estimates for genotypes between systems. One potential explanation for this difference was identified as the system-specific group effect of semidwarf vs. long-strawed genotypes. \textcopyright{} Crop Science Society of America | 5585 Guilford Rd., Madison, WI 53711 USA All rights reserved.},
  annotation = {ZSCC: 0000006},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Schmidt et al_2018_More, larger, simpler.pdf},
  journal = {Crop Science},
  keywords = {2-level modeling,Bayesian confirmatory factor analysis,Bayesian estimation,Bayesian statistics,Challenges,estimation method,Iran,maximum likelihood,multilevel modeling,noninformative priors,Precision agriculture (PA),restricted maximum likelihood,single-case designs,single-case research,Sustainable agriculture,weakly informative prior},
  number = {4}
}

@article{Selle2019Flexible,
  title = {Flexible Modelling of Spatial Variation in Agricultural Field Trials with the {{R}} Package {{INLA}}},
  author = {Selle, Maria Lie and Steinsland, Ingelin and Hickey, John M. and Gorjanc, Gregor},
  year = {2019},
  volume = {132},
  pages = {3277--3293},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {14322242},
  doi = {10.1007/s00122-019-03424-y},
  abstract = {Key message: Established spatial models improve the analysis of agricultural field trials with or without genomic data and can be fitted with the open-source R package INLA. Abstract: The objective of this paper was to fit different established spatial models for analysing agricultural field trials using the open-source R package INLA. Spatial variation is common in field trials, and accounting for it increases the accuracy of estimated genetic effects. However, this is still hindered by the lack of available software implementations. We compare some established spatial models and show possibilities for flexible modelling with respect to field trial design and joint modelling over multiple years and locations. We use a Bayesian framework and for statistical inference the integrated nested Laplace approximations (INLA) implemented in the R package INLA. The spatial models we use are the well-known independent row and column effects, separable first-order autoregressive (AR 1 {$\otimes$} AR 1) models and a Gaussian random field (Mat\'ern) model that is approximated via the stochastic partial differential equation approach. The Mat\'ern model can accommodate flexible field trial designs and yields interpretable parameters. We test the models in a simulation study imitating a wheat breeding programme with different levels of spatial variation, with and without genome-wide markers and with combining data over two locations, modelling spatial and genetic effects jointly. The results show comparable predictive performance for both the AR 1 {$\otimes$} AR 1 and the Mat\'ern models. We also present an example of fitting the models to a real wheat breeding data and simulated tree breeding data with the Nelder wheel design to show the flexibility of the Mat\'ern model and the R package INLA.},
  annotation = {ZSCC: 0000011},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Flexible modelling of spatial variation in agricultural feld trials with the R package INLA.pdf},
  isbn = {0012201903424},
  journal = {Theoretical and Applied Genetics},
  number = {12}
}

@article{Shirley2020Empirical,
  title = {An Empirical, {{Bayesian}} Approach to Modelling Crop Yield: {{Maize}} in {{USA}}},
  shorttitle = {An Empirical, {{Bayesian}} Approach to Modelling Crop Yield},
  author = {Shirley, Raphael and Pope, Edward and Bartlett, Myles and Oliver, Seb and Quadrianto, Novi and Hurley, Peter and Duivenvoorden, Steven and Rooney, Phil and Barrett, Adam B. and Kent, Chris and Bacon, James},
  year = {2020},
  month = jan,
  volume = {2},
  pages = {025002},
  publisher = {{IOP Publishing}},
  issn = {2515-7620},
  doi = {10.1088/2515-7620/ab67f0},
  abstract = {We apply an empirical, data-driven approach for describing crop yield as a function of monthly temperature and precipitation by employing generative probabilistic models with parameters determined through Bayesian inference. Our approach is applied to state-scale maize yield and meteorological data for the US Corn Belt from 1981 to 2014 as an exemplar, but would be readily transferable to other crops, locations and spatial scales. Experimentation with a number of models shows that maize growth rates can be characterised by a two-dimensional Gaussian function of temperature and precipitation with monthly contributions accumulated over the growing period. This approach accounts for non-linear growth responses to the individual meteorological variables, and allows for interactions between them. Our models correctly identify that temperature and precipitation have the largest impact on yield in the six months prior to the harvest, in agreement with the typical growing season for US maize (April to September). Maximal growth rates occur for monthly mean temperature 18 \textdegree C\textendash 19 \textdegree C, corresponding to a daily maximum temperature of 24 \textdegree C\textendash 25 \textdegree C (in broad agreement with previous work) and monthly total precipitation 115 mm. Our approach also provides a self-consistent way of investigating climate change impacts on current US maize varieties in the absence of adaptation measures. Keeping precipitation and growing area fixed, a temperature increase of 2 \textdegree C, relative to 1981\textendash 2014, results in the mean yield decreasing by 8\%, while the yield variance increases by a factor of around 3. We thus provide a flexible, data-driven framework for exploring the impacts of natural climate variability and climate change on globally significant crops based on their observed behaviour. In concert with other approaches, this can help inform the development of adaptation strategies that will ensure food security under a changing climate.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Shirley et al_2020_An empirical, Bayesian approach to modelling crop yield.pdf},
  journal = {Environ. Res. Commun.},
  language = {en},
  number = {2}
}

@article{Smid2020Bayesian,
  title = {Bayesian {{Versus Frequentist Estimation}} for {{Structural Equation Models}} in {{Small Sample Contexts}}: {{A Systematic Review}}},
  shorttitle = {Bayesian {{Versus Frequentist Estimation}} for {{Structural Equation Models}} in {{Small Sample Contexts}}},
  author = {Smid, Sanne C. and McNeish, Daniel and Mio{\v c}evi{\'c}, Milica and van de Schoot, Rens},
  year = {2020},
  month = jan,
  volume = {27},
  pages = {131--161},
  publisher = {{Routledge}},
  issn = {1070-5511},
  doi = {10.1080/10705511.2019.1577140},
  abstract = {In small sample contexts, Bayesian estimation is often suggested as a viable alternative to frequentist estimation, such as maximum likelihood estimation. Our systematic literature review is the first study aggregating information from numerous simulation studies to present an overview of the performance of Bayesian and frequentist estimation for structural equation models with small sample sizes. We conclude that with small samples, the use of Bayesian estimation with diffuse default priors can result in severely biased estimates \textendash{} the levels of bias are often even higher than when frequentist methods are used. This bias can only be decreased by incorporating prior information. We therefore recommend against naively using Bayesian estimation when samples are small, and encourage researchers to make well-considered decisions about all priors. For this purpose, we provide recommendations on how to construct thoughtful priors.},
  annotation = {\_eprint: https://doi.org/10.1080/10705511.2019.1577140},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Smid et al_2020_Bayesian Versus Frequentist Estimation for Structural Equation Models in Small.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\CXU685IH\\10705511.2019.html},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  keywords = {informative priors,Small samples,structural equation models,systematic review},
  number = {1}
}

@article{Solin2020Hilbert,
  title = {Hilbert Space Methods for Reduced-Rank {{Gaussian}} Process Regression},
  author = {Solin, Arno and S{\"a}rkk{\"a}, Simo},
  year = {2020},
  month = mar,
  volume = {30},
  pages = {419--446},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-019-09886-w},
  abstract = {This paper proposes a novel scheme for reduced-rank Gaussian process regression. The method is based on an approximate series expansion of the covariance function in terms of an eigenfunction expansion of the Laplace operator in a compact subset of Rd . On this approximate eigenbasis, the eigenvalues of the covariance function can be expressed as simple functions of the spectral density of the Gaussian process, which allows the GP inference to be solved under a computational cost scaling as O(nm2) (initial) and O(m3) (hyperparameter learning) with m basis functions and n data points. Furthermore, the basis functions are independent of the parameters of the covariance function, which allows for very fast hyperparameter learning. The approach also allows for rigorous error analysis with Hilbert space theory, and we show that the approximation becomes exact when the size of the compact subset and the number of eigenfunctions go to infinity. We also show that the convergence rate of the truncation error is independent of the input dimensionality provided that the differentiability order of the covariance function increases appropriately, and for the squared exponential covariance function it is always bounded by {$\sim$}1/m regardless of the input dimensionality. The expansion generalizes to Hilbert spaces with an inner product which is defined as an integral over a specified input density. The method is compared to previously proposed methods theoretically and through empirical tests with simulated and real data.},
  annotation = {ZSCC: 0000096},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MGaussianP\\Solin and Särkkä - 2020 - Hilbert space methods for reduced-rank Gaussian pr.pdf},
  journal = {Stat Comput},
  language = {en},
  number = {2}
}

@book{Sorensen2007Likelihood,
  ids = {sorensen2007likelihood},
  title = {Likelihood, {{Bayesian}}, and {{MCMC}} Methods in Quantitative Genetics},
  author = {Sorensen, Daniel and Gianola, Daniel},
  year = {2007},
  publisher = {{Springer Science \& Business Media}},
  annotation = {ZSCC: 0001048[s0]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\7SJPNXTD\\books.html}
}

@article{Sorensen2016Bayesian,
  ids = {Sorensen2016},
  title = {Bayesian Linear Mixed Models Using {{Stan}}: {{A}} Tutorial for Psychologists, Linguists, and Cognitive Scientists},
  author = {Sorensen, Tanner and Hohenstein, Sven and Vasishth, Shravan},
  year = {2016},
  volume = {12},
  pages = {175--200},
  issn = {2292-1354},
  doi = {10.20982/tqmp.12.3.p175},
  abstract = {With the arrival of the R packages nlme and lme4, linear mixed models (LMMs) have come to be widely used in experimentally-driven areas like psychology, linguistics, and cognitive science. This tutorial provides a practical introduction to fitting LMMs in a Bayesian framework using the probabilistic programming language Stan. We choose Stan (rather than WinBUGS or JAGS) because it provides an elegant and scalable framework for fitting models in most of the standard applications of LMMs. We ease the reader into fitting increasingly complex LMMs, first using a two-condition repeated measures self-paced reading study, followed by a more complex \$22\$ repeated measures factorial design that can be generalized to much more complex designs.},
  annotation = {ZSCC: NoCitationData[s2]},
  archiveprefix = {arXiv},
  arxivid = {1506.06201},
  eprint = {1506.06201},
  eprinttype = {arxiv},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Sorensen et al_2016_Bayesian linear mixed models using Stan.pdf},
  journal = {The Quantitative Methods for Psychology},
  keywords = {bayesian data analysis,bayesian linear mixed models,jags,linear mixed models,stan,tools},
  number = {3}
}

@book{Stan2019Stan,
  title = {Stan {{Modeling Language}}: {{User}}'s {{Guide}} and {{Reference Manual}}},
  author = {Stan, Development Team},
  year = {2019},
  edition = {2.23},
  abstract = {Stan reference manual specifying the syntax and semantics of the Stan programming language.},
  annotation = {ZSCC: 0000028},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\3AVDPGG5\\reference-manual.html}
}

@article{Stefanova2009Enhanced,
  title = {Enhanced Diagnostics for the Spatial Analysis of Field Trials},
  author = {Stefanova, Katia T. and Smith, Alison B. and Cullis, Brian R.},
  year = {2009},
  month = dec,
  volume = {14},
  pages = {392},
  issn = {1537-2693},
  doi = {10.1198/jabes.2009.07098},
  abstract = {We report an analysis of a series of uniformity field trials using the technique proposed by Gilmour, Cullis, and Verbyla. In particular, we clarify the role of the sample variogram and present a range of enhanced graphical diagnostics to aid the spatial modeling process. We highlight the implications of the presence of extraneous variation related to commonly used agronomic practices, such as serpentine harvesting.},
  annotation = {ZSCC: 0000073},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\EMPTY_COLLECTION_NAME\\Stefanova et al_2009_Enhanced diagnostics for the spatial analysis of field trials.pdf},
  journal = {JABES},
  language = {en},
  number = {4}
}

@article{Sun2015Thin,
  title = {Thin Plate Spline Regression Model Used at Early Stages of Soybean Breeding to Control Field Spatial Variation},
  author = {Sun, M. and Goggi, S. A. and Matson, K. and Palmer, R. G. and Moore, K. and Cianzio, S. R.},
  year = {2015},
  volume = {29},
  pages = {333--352},
  publisher = {{Taylor \& Francis}},
  issn = {15427536},
  doi = {10.1080/15427528.2015.1026623},
  abstract = {Yield variation observed in soybean (Glycine max) progeny-row yield trial (PRYT) is the final result of line genotypic merit, field spatial pattern, and experimental error. The spatial variation in field tests could confound the estimates of genetic merits. The objectives of this research were to: i) quantify non-genetic yield variation in a soybean breeding PRYT, and ii) determine efficiency of the thin plate spline regression (TPSR) model in adjusting yield because of variation caused by field spatial pattern. The third objective was to evaluate if the use of TPSR model could improve the selection accuracy of PRYT un-replicated yield tests. Uniformity study, early generation test, and confirmation study were conducted. Our results indicated that large spatial variations in soybean PRYT field could be present as evaluated by the Uniformity Study conducted with two commercial lines. In this experiment, the use of the TPSR proved to be effective in reducing the error variance and the coefficient of variability, with an improvement in relative efficiency (IRE) of 37.9\%. In early generation tests, 2565 lines were evaluated within test-sets along with three checks. The TPSR model also was effective in the early-generation tests; the IRE was 40.4\%. The correlation coefficients calculated between yield estimates obtained in two-year early generation tests and confirmation study improved by 0.21 points compared with results from non-TPSR experiments. The results indicated that use of TPSR model was effective in accounting for some of the spatial variation in field tests.},
  annotation = {ZSCC: 0000004},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Sun et al_2015_Thin plate spline regression model used at early stages of soybean breeding to.pdf},
  journal = {Journal of Crop Improvement},
  keywords = {best linear unbiased prediction,genetic gain,Progeny-row yield trial,soybean breeding,two-dimensional thin plate spline regression},
  number = {3}
}

@article{Sundararajan2001Predictive,
  title = {Predictive {{Approaches}} for {{Choosing Hyperparameters}} in {{Gaussian Processes}}},
  author = {Sundararajan, S. and Keerthi, S. S.},
  year = {2001},
  month = may,
  volume = {13},
  pages = {1103--1118},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/08997660151134343},
  abstract = {Gaussian Processes are powerful regression models specified by parametrized mean and covariance functions. Standard approaches to estimate these parameters (known by the name Hyperparameters) are Maximum Likelihood (ML) and Maximum APosterior (MAP) approaches. In this paper, we propose and investigate predictive approaches, namely, maximization of Geisser's Surrogate Predictive Probability (GPP) and minimization of mean square error with respect to GPP (referred to as Geisser's Predictive mean square Error (GPE)) to estimate the hyperparameters. We also derive results for the standard Cross-Validation (CV) error and make a comparison. These approaches are tested on a number of problems and experimental results show that these approaches are strongly competitive to existing approaches.},
  annotation = {ZSCC: 0000123},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\F7GVDJXT\\Sundararajan and Keerthi - 2001 - Predictive Approaches for Choosing Hyperparameters.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {5}
}

@article{Theobald2002Bayesian,
  title = {A Bayesian Approach to Regional and Local-Area Prediction from Crop Variety Trials},
  author = {Theobald, Chris M. and Talbot, Mike and Nabugoomu, Fabian},
  year = {2002},
  month = sep,
  volume = {7},
  pages = {403--419},
  issn = {1085-7117, 1537-2693},
  doi = {10.1198/108571102230},
  annotation = {ZSCC: 0000037},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesTechnique\\A bayesian approach to regional and local-area prediction from crop variety trials.pdf},
  journal = {JABES},
  language = {en},
  number = {3}
}

@article{Tobler1970Computer,
  title = {A Computer Movie Simulating Urban Growth in the Detroit Region},
  author = {Tobler, W R},
  year = {1970},
  volume = {46},
  pages = {234},
  issn = {00130095},
  doi = {10.2307/143141},
  abstract = {Work units, called danwei, are one of the principal territorial forms used to organize China's urban population. These enclosed spaces are the socio-spatial units in which the livelihood and domestic and social activities of its members are carried out. The danwei are described by considering: (1) the origins of the concept, (2) phenomenological meanings in contemporary society, (3) socio- economic-political characteristics, and (4) their spatial implications in the trans- formation of Chinese society. How},
  annotation = {ZSCC: 0009046},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Tobler_1970_A computer movie simulating urban growth in the detroit region.pdf},
  journal = {Econ. Geogr.}
}

@article{Troyer2009Heterosis,
  title = {Heterosis Decreasing in Hybrids: {{Yield}} Test Inbreds},
  author = {Troyer, A. Forrest and Wellin, Eric J.},
  year = {2009},
  volume = {49},
  pages = {1969--1976},
  issn = {0011183X},
  doi = {10.2135/cropsci2009.04.0170},
  abstract = {Yield testing fi nished inbreds to replace preliminary single-cross corn (Zea mays L.) yield tests will increase rate of commercial hybrid yield gains. Studies have shown that heterosis decreased 25\%/50 yr, 10\%/60 yr, and 35\%/100 yr. Natural selection and artifi cial selection by plant breeders for adaptedness have increased parental inbred and hybrid seed yields, whereas percentage heterosis decreased. Four studies have shown inbred yields increased 1.9 to 3.5 times faster than heterosis yields. Pioneer HiBred generates 700 new inbreds tested in 6000 single-cross hybrids at 15 to 20 locations annually. Predicted, untested, newer hybrids are then made and tested extensively with commercial hybrids. Parental inbred yield testing is the next to last of several steps in hybrid development. Commercial hybrid development costs have increased logarithmically, whereas performance has increased linearly. Replacing preliminary testcross trials with fi nished-inbred yield trials is more effi cient. About 12,000 new fi nished inbreds can be evaluated annually with no testers and at least 50\% fewer locations per inbred with the same testing effort as 700 new inbreds with testers. A calendar year per breeding cycle and annual production costs for 6000 hybrids will be saved. Corn yield trials detect stress susceptibility, which is more apparent in inbreds than in hybrids. Evaluation of more new inbreds will be conducive to increased genetic diversity that produces higher-yielding hybrids. \textcopyright{} Crop Science Society of America.},
  annotation = {ZSCC: 0000087},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Troyer_Wellin_2009_Heterosis decreasing in hybrids.pdf},
  journal = {Crop Science},
  number = {6}
}

@article{Tsionas2002Bayesian,
  title = {Bayesian {{Inference}} in the {{Noncentral Student}}-t {{Model}}},
  author = {Tsionas, Efthymios G.},
  year = {2002},
  volume = {11},
  pages = {208--221},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd., Institute of Mathematical Statistics, Interface Foundation of America]}},
  issn = {1061-8600},
  doi = {10.1198/106186002317375695},
  abstract = {This article takes up Bayesian inference in linear models with disturbances from a noncentral Student-t distribution. The distribution is useful when both long tails and asymmetry are features of the data. The distribution can be expressed as a location-scale mixture of normals with inverse weights distributed according to a chi-square distribution. The computations are performed using Gibbs sampling with data augmentation. An empirical application to Standard and Poor's stock returns indicates that posterior odds strongly favor a noncentral Student-t specification over its symmetric counterpart.},
  annotation = {ZSCC: 0000016},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\EMPTY_COLLECTION_NAME\\Tsionas_2002_Bayesian Inference in the Noncentral Student-t Model.pdf},
  journal = {Journal of Computational and Graphical Statistics},
  number = {1}
}

@article{Vasconcelos2020New,
  title = {A New Regression Model for Bimodal Data and Applications in Agriculture},
  author = {Vasconcelos, Julio Cezar Souza and Cordeiro, Gauss Moutinho and Ortega, Edwin Moises Marcos and de Rezende, {\'E}dila Maria},
  year = {2020},
  month = feb,
  volume = {0},
  pages = {1--24},
  publisher = {{Taylor \& Francis}},
  issn = {0266-4763},
  doi = {10.1080/02664763.2020.1723503},
  abstract = {We define the odd log-logistic exponential Gaussian regression with two systematic components, which extends the heteroscedastic Gaussian regression and it is suitable for bimodal data quite common in the agriculture area. We estimate the parameters by the method of maximum likelihood. Some simulations indicate that the maximum-likelihood estimators are accurate. The model assumptions are checked through case deletion and quantile residuals. The usefulness of the new regression model is illustrated by means of three real data sets in different areas of agriculture, where the data present bimodality.},
  annotation = {ZSCC: 0000001  \_eprint: https://doi.org/10.1080/02664763.2020.1723503},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MixtureGaussian\\Vasconcelos et al_2020_A new regression model for bimodal data and applications in agriculture.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\W43C9B6D\\02664763.2020.html},
  journal = {Journal of Applied Statistics},
  keywords = {Agriculture data,bimodal data,exponential Gaussian distribution,regression model,simulation study},
  number = {0}
}

@article{Vehtari2017Practical,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  volume = {27},
  pages = {1413--1432},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  annotation = {ZSCC: 0001232},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf},
  journal = {Stat Comput},
  language = {en},
  number = {5}
}

@article{Verbyla1999Analysis,
  title = {The Analysis of Designed Experiments and Longitudinal Data by Using Smoothing Splines},
  author = {Verbyla, Ar{\textbackslash}barunas P and Cullis, Brian R and Kenward, Michael G and Welham, Sue J},
  year = {1999},
  volume = {48},
  pages = {269--311},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/1467-9876.00154},
  annotation = {ZSCC: 0000724},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Verbyla et al_1999_The analysis of designed experiments and longitudinal data by using smoothing.pdf},
  journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  number = {3}
}

@article{Verdooren2020History,
  title = {History of the {{Statistical Design}} of {{Agricultural Experiments}}},
  author = {Verdooren, L. Rob},
  year = {2020},
  month = dec,
  volume = {25},
  pages = {457--486},
  issn = {1085-7117, 1537-2693},
  doi = {10.1007/s13253-020-00394-3},
  annotation = {ZSCC: 0000004},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Verdooren - 2020 - History of the Statistical Design of Agricultural .pdf},
  journal = {JABES},
  language = {en},
  number = {4}
}

@article{Vilasa2017Global,
  title = {Global Soil Moisture Bimodality in Satellite Observations and Climate Models},
  author = {Vilasa, L. and Miralles, D. G. and de Jeu, R. A. M. and Dolman, A. J.},
  year = {2017},
  volume = {122},
  pages = {4299--4311},
  issn = {2169-8996},
  doi = {10.1002/2016JD026099},
  abstract = {A new diagnostic metric based on soil moisture bimodality is developed in order to examine and compare soil moisture from satellite observations and Earth System Models. The methodology to derive this diagnostic is based on maximum likelihood estimator encoded into an iterative algorithm, which is applied to the soil moisture probability density function. This metric is applied to satellite data from the Advanced Microwave Scanning Radiometer for the Earth Observing System and global climate models data from the Coupled Model Intercomparison Project Phase 5 (CMIP5). Results show high soil moisture bimodality in transitional climate areas and high latitudes, potentially associated with land-atmosphere feedback processes. When comparing satellite versus climate models, a clear difference in their soil moisture bimodality is observed, with systematically higher values in the case of CMIP5 models. These differences appear related to areas where land-atmospheric feedback may be overestimated in current climate models.},
  annotation = {ZSCC: 0000007  \_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2016JD026099},
  copyright = {\textcopyright 2017. The Authors.},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MixtureGaussian\\Vilasa et al_2017_Global soil moisture bimodality in satellite observations and climate models.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\3F873TE4\\2016JD026099.html},
  journal = {Journal of Geophysical Research: Atmospheres},
  keywords = {bimodality,climate models,CMIP5,land-atmosphere interactions,satellite soil moisture,soil moisture},
  language = {en},
  number = {8}
}

@article{Vollert2019Robust,
  title = {Robust Additive {{Gaussian}} Process Models Using Reference Priors and Cut-off-Designs},
  author = {Vollert, Natalie and Ortner, Michael and Pilz, J{\"u}rgen},
  year = {2019},
  volume = {65},
  pages = {586--596},
  publisher = {{Elsevier Inc.}},
  issn = {0307904X},
  doi = {10.1016/j.apm.2018.07.050},
  abstract = {When powerful numerical tools like the finite element method encounter their limits for the evaluation of physical systems it is very common to use surrogate models as an approximation. There are many possible choices concerning the model approach, among which Gaussian process models are the most popular ones due to their clear statistical basis. A very desirable attribute of such surrogates is a high flexibility for making them applicable to a great class of underlying problems while obtaining interpretable results. To achieve this Gaussian processes are used as basis functions of an additive model in this work. Another important property of a surrogate is stability, which can be especially challenging when it comes to the estimation of the correlation parameters. To solve this we use a Bayesian approach where a reference prior is assigned to each component of the additive model assuring robust correlation matrices. Due to the additive structure of the model a simplified parameter estimation process is proposed that reduces the usually high-dimensional optimization problem to a few sub-routines of low dimension. Finally, we demonstrate this concept by modeling the magnetic field of a magnetic linear position detection system.},
  journal = {Appl. Math. Model.},
  keywords = {Additive models,Computer experiments,Gaussian process models,Reference prior,Robust estimation}
}

@article{Waldmann2006Comparison,
  title = {Comparison of {{REML}} and {{Gibbs}} Sampling Estimates of Multi-Trait Genetic Parameters in {{Scots}} Pine},
  author = {Waldmann, Patrik and Ericsson, Tore},
  year = {2006},
  volume = {112},
  pages = {1441--1451},
  issn = {00405752},
  doi = {10.1007/s00122-006-0246-x},
  abstract = {Multi-trait (co)variance estimation is an important topic in plant and animal breeding. In this study we compare estimates obtained with restricted maximum likelihood (REML) and Bayesian Gibbs sampling of simulated data and of three traits (diameter, height and branch angle) from a 26-year-old partial diallel progeny test of Scots pine (Pinus sylvestris L.). Based on the results from the simulated data we can conclude that the REML estimates are accurate but the mode of posterior distributions from the Gibbs sampling can be overestimated depending on the level of the heritability. The mean and median of the posteriors were considerably higher than the expected values of the heritabilities. The confidence intervals calculated with the delta method were biased downwardly. The highest probability density (HPD) interval provides a better interval estimate, but could be slightly biased at the lower level. Similar differences between REML and Gibbs sampling estimates were found for the Scots pine data. We conclude that further simulation studies are needed in order to evaluate the effect of different priors on (co)variance components in the genetic individual model. \textcopyright{} Springer-Verlag 2006.},
  annotation = {ZSCC: 0000044},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\HTC3JWWM\\Comparison of REML and Gibbs sampling estimates of multi-trait genetic parameters in Scots pine.pdf},
  journal = {Theor. Appl. Genet.},
  number = {8}
}

@article{Wall2004Close,
  title = {A Close Look at the Spatial Structure Implied by the {{CAR}} and {{SAR}} Models},
  author = {Wall, Melanie M.},
  year = {2004},
  volume = {121},
  pages = {311--324},
  issn = {03783758},
  doi = {10.1016/s0378-3758(03)00111-3},
  abstract = {Modeling spatial interactions that arise in spatially referenced data is commonly done by incorporating the spatial dependence into the covariance structure either explicitly or implicitly via an autoregressive model. In the case of lattice (regional summary) data, two common autoregressive models used are the conditional autoregressive model (CAR) and the simultaneously autoregressive model (SAR). Both of these models produce spatial dependence in the covariance structure as a function of a neighbor matrix W and often a fixed unknown spatial correlation parameter. This paper examines in detail the correlation structures implied by these models as applied to an irregular lattice in an attempt to demonstrate their many counterintuitive or impractical results. A data example is used for illustration where US statewide average SAT verbal scores are modeled and examined for spatial structure using different spatial models. \textcopyright{} 2003 Elsevier B.V. All rights reserved.},
  annotation = {ZSCC: 0000422},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\BayesTechOFE\\Reading\\A close look at the spatial structure implied by the CAR and SAR models.pdf},
  journal = {Journal of Statistical Planning and Inference},
  keywords = {Lattice data,Spatial autoregression,Spatial interaction},
  number = {2}
}

@article{Weiss1994Pediatric,
  title = {Pediatric {{Pain}}, {{Predictive Inference}}, and {{Sensitivity Analysis}}},
  shorttitle = {Pediatric {{Pain}}, {{Predictive Inference}}, and {{Sensitivity Analysis}}},
  author = {Weiss, Robert},
  year = {1994},
  month = dec,
  volume = {18},
  pages = {651--677},
  publisher = {{Sage PublicationsSage CA: Thousand Oaks, CA}},
  doi = {10.1177/0193841x9401800601},
  abstract = {The understanding, prevention, and treatment of pain is of great importance to medical science. Children were asked to immerse their hands in cold water until t...},
  annotation = {ZSCC: 0000016},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Weiss_2016_Pediatric Pain, Predictive Inference, and Sensitivity Analysis.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\XD737NHW\\0193841X9401800601.html},
  journal = {Evaluation Review},
  language = {en},
  number = {6}
}

@article{Wood2003Thin,
  title = {Thin Plate Regression Splines},
  author = {Wood, Simon N.},
  year = {2003},
  month = feb,
  volume = {65},
  pages = {95--114},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/1467-9868.00374},
  abstract = {I discuss the production of low rank smoothers for d {$>$} 1 dimensional data, which can be fitted by regression or penalized regression methods. The smoothers are constructed by a simple transformation and truncation of the basis that arises from the solution of the thin plate spline smoothing problem and are optimal in the sense that the truncation is designed to result in the minimum possible perturbation of the thin plate spline smoothing problem given the dimension of the basis used to construct the smoother. By making use of Lanczos iteration the basis change and truncation are computationally efficient. The smoothers allow the use of approximate thin plate spline models with large data sets, avoid the problems that are associated with 'knot placement' that usually complicate modelling with regression splines or penalized regression splines, provide a sensible way of modelling interaction terms in generalized additive models, provide low rank approximations to generalized smoothing spline models, appropriate for use with large data sets, provide a means for incorporating smooth functions of more than one variable into non-linear models and improve the computational efficiency of penalized likelihood models incorporating thin plate splines. Given that the approach produces spline-like models with a sparse basis, it also provides a natural way of incorporating unpenalized spline-like terms in linear and generalized linear models, and these can be treated just like any other model terms from the point of view of model selection, inference and diagnostics.},
  annotation = {ZSCC: 0001493},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\SX8CCDDT\\Wood - 2003 - Thin plate regression splines.pdf},
  journal = {J Royal Statistical Soc B},
  language = {en},
  number = {1}
}

@article{Wood2011Fast,
  ids = {Wood2011,wood2011fast},
  title = {Fast Stable Restricted Maximum Likelihood and Marginal Likelihood Estimation of Semiparametric Generalized Linear Models},
  author = {Wood, Simon N},
  year = {2011},
  volume = {73},
  pages = {3--36},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/j.1467-9868.2010.00749.x},
  annotation = {ZSCC: 0003829},
  file = {/Users/jeromecao/Library/Application Support/Mendeley Desktop/Downloaded/Wood - 2011 - Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models.pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {adaptive smoothing,computation,gam,gamm,gcv,marginal likelihood,model selection,penalized glm,penalized regression splines,reml,scalar on function regression,stable},
  number = {1}
}

@article{Wu2016Comparison,
  title = {A Comparison of Spatial Interpolation Methods for Soil Temperature over a Complex Topographical Region},
  author = {Wu, Wei and Tang, Xiao-Ping and Ma, Xue-Qing and Liu, Hong-Bin},
  year = {2016},
  month = aug,
  volume = {125},
  pages = {657--667},
  issn = {1434-4483},
  doi = {10.1007/s00704-015-1531-x},
  abstract = {Soil temperature variability data provide valuable information on understanding land-surface ecosystem processes and climate change. This study developed and analyzed a spatial dataset of monthly mean soil temperature at a depth of 10~cm over a complex topographical region in southwestern China. The records were measured at 83 stations during the period of 1961\textendash 2000. Nine approaches were compared for interpolating soil temperature. The accuracy indicators were root mean square error (RMSE), modelling efficiency (ME), and coefficient of residual mass (CRM). The results indicated that thin plate spline with latitude, longitude, and elevation gave the best performance with RMSE varying between 0.425 and 0.592~\textdegree C, ME between 0.895 and 0.947, and CRM between -0.007 and 0.001. A spatial database was developed based on the best model. The dataset showed that larger seasonal changes of soil temperature were from autumn to winter over the region. The northern and eastern areas with hilly and low-middle mountains experienced larger seasonal changes.},
  annotation = {ZSCC: 0000006},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Wu et al_2016_A comparison of spatial interpolation methods for soil temperature over a.pdf},
  journal = {Theor Appl Climatol},
  language = {en},
  number = {3}
}

@article{Xu2010Hypothesis,
  ids = {Xu2010Hypothesisa},
  title = {Hypothesis {{Tests}} on {{Mixture Model Components}} with {{Applications}} in {{Ecology}} and {{Agriculture}}},
  author = {Xu, Ling and Hanson, Timothy and Bedrick, Edward J. and Restrepo, Carla},
  year = {2010},
  volume = {15},
  pages = {308--326},
  publisher = {{[International Biometric Society, Springer]}},
  issn = {1085-7117},
  doi = {10.1007/s13253-010-0020-z},
  abstract = {Multiple comparisons are widely used to compare gross features of distributions across populations. However, often a scientific hypothesis is more easily couched in terms of more focused null and alternative statistical hypotheses. For example, among distributions exhibiting clusters of continuous measurements across strata, are there clusters of measurements similar in terms of location, spread, or weight? We propose testing such hypotheses using a sequence of nested finite mixture models. Reasonable, data-driven priors are suggested based on estimates of the sample spreads and mid-points. Formal hypothesis testing is carried out through the computation of Bayes factors. The method is illustrated on Holling's (Ecological Monographs 62:447-502, 1992) forest and prairie bird body mass data, and data on the time-to-abortion in dairy cows. Supplemental simulations are available online.},
  annotation = {ZSCC: 0000012},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\MixtureGaussian\\Xu et al_2010_Hypothesis Tests on Mixture Model Components with Applications in Ecology and.pdf},
  journal = {Journal of Agricultural, Biological, and Environmental Statistics},
  number = {3}
}

@article{Yan2002Onfarm,
  title = {On-Farm Strip Trials vs. Replicated Performance Trials for Cultivar Evaluation},
  author = {Yan, Weikai and Hunt, L. A. and Johnson, Peter and Stewart, Gregory and Lu, Xuewen},
  year = {2002},
  volume = {42},
  pages = {385--392},
  issn = {0011183X},
  doi = {10.2135/cropsci2002.0385},
  abstract = {A systematic comparison between two cultivar evaluation and recommendation systems, i.e., the balanced and replicated performance trials conducted in small plots at a small number of locations, and the unbalanced and non-replicated on-farm trials conducted in large strips on many farms, is lacking. This study was initiated to investigate the usefulness of the two contrasting systems in cultivar evaluation and the relationships between them. Yield data from Ontario winter wheat (Triticum aestivum L.) strip trials and performance trials for 1998 to 2000 were analyzed by mixed models. For all 3 yr, results from the two systems were highly correlated, both in terms of the best linear unbiased predictors (BLUP) and for the t-values of BLUP. Cultivars judged to be superior (or inferior) by one system were never judged to be inferior (or superior) by the other. Thus, both on-farm strip trials and replicated small-plot trials provide valid data for effective cultivar evaluation. On the basis of t-statistics, which measure cultivar reliability, cultivars can be classified into superior (t {$\geq$} 2), inferior (t {$\leq$} -2), and intermediate or inadequately tested (-2 {$<$} t {$<$} 2). Two cultivars can be regarded as different in reliability if their t-values differ by {$\geq$}3. The evaluation power of strip trials for a cultivar depends on the number of trials in which the cultivar is tested; a cultivar may not be adequately evaluated if it is tested in fewer than 20 trials.},
  annotation = {ZSCC: 0000055},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Yan et al_2002_On-farm strip trials vs.pdf},
  journal = {Crop Science},
  number = {2}
}

@article{YouDeep,
  ids = {You2017Deep},
  title = {Deep {{Gaussian Process}} for {{Crop Yield Prediction Based}} on {{Remote Sensing Data}}},
  author = {You, Jiaxuan and Li, Xiaocheng and Low, Melvin and Lobell, David and Ermon, Stefano},
  pages = {7},
  abstract = {Agricultural monitoring, especially in developing countries, can help prevent famine and support humanitarian efforts. A central challenge is yield estimation, i.e., predicting crop yields before harvest.},
  annotation = {ZSCC: 0000198},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\ML\\You et al. - Deep Gaussian Process for Crop Yield Prediction Ba.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\IMWJTWZG\\You et al. - Deep Gaussian Process for Crop Yield Prediction Ba.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{Zhang2006Sampling,
  title = {Sampling {{Correlation Matrices}} in {{Bayesian Models With Correlated Latent Variables}}},
  author = {Zhang, Xiao and Boscardin, W. John and Belin, Thomas R.},
  year = {2006},
  month = dec,
  volume = {15},
  pages = {880--896},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1198/106186006X160050},
  abstract = {Hierarchical model specifications using latent variables are frequently used to reflect correlation structure in data. Motivated by the structure of a Bayesian multivariate probit model, we demonstrate a parameter-extended Metropolis-Hastings algorithm for sampling from the posterior distribution of a correlation matrix. Our sampling algorithms lead directly to two readily interpretable families of prior distributions for a correlation matrix. The methodology is illustrated through a simulation study and through an application with repeated binary outcomes on individuals from a study of a suicide prevention intervention.},
  annotation = {ZSCC: 0000059  \_eprint: https://doi.org/10.1198/106186006X160050},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Zhang et al_2006_Sampling Correlation Matrices in Bayesian Models With Correlated Latent.pdf;C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\5I9ZHVYH\\106186006X160050.html},
  journal = {Journal of Computational and Graphical Statistics},
  keywords = {Metropolis-Hastings algorithm,Multivariate probit model},
  number = {4}
}

@article{Zhang2013Kronecker,
  title = {On the {{Kronecker Products}} and {{Their Applications}}},
  author = {Zhang, Huamin and Ding, Feng},
  year = {2013},
  volume = {2013},
  pages = {1--8},
  issn = {1110-757X, 1687-0042},
  doi = {10.1155/2013/296185},
  abstract = {This paper studies the properties of the Kronecker product related to the mixed matrix products, the vector operator, and the vec-permutation matrix and gives several theorems and their proofs. In addition, we establish the relations between the singular values of two matrices and their Kronecker product and the relations between the determinant, the trace, the rank, and the polynomial matrix of the Kronecker products.},
  annotation = {ZSCC: NoCitationData[s1]},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Zotero\\storage\\GAVVRPX2\\Zhang and Ding - 2013 - On the Kronecker Products and Their Applications.pdf},
  journal = {Journal of Applied Mathematics},
  language = {en}
}

@article{Zimmerman1991Randoma,
  title = {A {{Random Field Approach}} to the {{Analysis}} of {{Field}}-{{Plot Experiments}} and {{Other Spatial Experiments}}},
  author = {Zimmerman, Dale L. and Harville, David A.},
  year = {1991},
  volume = {47},
  pages = {223--239},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006-341X},
  doi = {10.2307/2532508},
  abstract = {Several "nearest-neighbor" methods for the analysis of data from spatial experiments (e.g., agricultural field experiments) have recently been proposed. These methods attempt to account for the effect of spatial heterogeneity on the estimation of treatment contrasts; typically, this is accomplished indirectly by differencing or by using residuals from neighboring plots to construct covariates. We examine an alternative approach in which the spatial heterogeneity is modeled directly. The model underlying our approach is similar to the model underlying a geostatistical kriging analysis and, as in the latter model, the observations are regarded collectively as a partial realization of a random field. A randomization study of uniformity trial data suggests that the random field approach often provides more accurate estimates of treatment contrasts than nearest-neighbor approaches. In addition, the random field approach is devoid of ambiguities as to the handling of border plots and is generally more flexible than nearest-neighbor approaches.},
  annotation = {ZSCC: 0000244},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Zimmerman_Harville_1991_A Random Field Approach to the Analysis of Field-Plot Experiments and Other.pdf},
  journal = {Biometrics},
  number = {1}
}


@article{Lewandowski2009Generating,
title = {Generating random correlation matrices based on vines and extended onion method},
journal = {Journal of Multivariate Analysis},
volume = {100},
number = {9},
pages = {1989-2001},
year = {2009},
issn = {0047-259X},
doi = {https://doi.org/10.1016/j.jmva.2009.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0047259X09000876},
author = {Daniel Lewandowski and Dorota Kurowicka and Harry Joe},
keywords = {Dependence vines, Correlation matrix, Partial correlation, Onion method}
}

@article{Piepho2019Coefficient,
  title = {A Coefficient of Determination ({{R2}}) for Generalized Linear Mixed Models},
  author = {Piepho, Hans Peter},
  year = {2019},
  journal = {Biometrical J.},
  volume = {61},
  number = {4},
  eprint = {1805.01124},
  eprinttype = {arxiv},
  pages = {860--872},
  issn = {15214036},
  doi = {10.1002/bimj.201800270},
  abstract = {Extensions of linear models are very commonly used in the analysis of biological data. Whereas goodness of fit measures such as the coefficient of determination (R2) or the adjusted R2 are well established for linear models, it is not obvious how such measures should be defined for generalized linear and mixed models. There are by now several proposals but no consensus has yet emerged as to the best unified approach in these settings. In particular, it is an open question how to best account for heteroscedasticity and for covariance among observations present in residual error or induced by random effects. This paper proposes a new approach that addresses this issue and is universally applicable for arbitrary variance-covariance structures including spatial models and repeated measures. It is exemplified using three biological examples.},
  archiveprefix = {arXiv},
  arxivid = {1805.01124},
  keywords = {generalized linear mixed models,generalized linear models,goodness-of-fit,linear mixed models,semivariogram,total variance},
  file = {C\:\\Users\\279302d\\OneDrive - Curtin\\Documents\\Curtin\\References\\BayesOFE\\Piepho_2019_A coefficient of determination (R2) for generalized linear mixed models.pdf}
}

